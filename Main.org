#+TITLE:    Informational Content of Geographical Indications
#+AUTHOR:   Jean-Sauveur Ay \and Mohamed Hilal 
#+DATE:     UMR CESAER, AgroSup Dijon, INRA, Univ. Bourgogne Franche Comté
#+OPTIONS:  LaTeX:t tags:nil toc:nil H:5
#+LANGUAGE: fr
#+STARTUP:  hideblocks
#+DRAWERS:  PROPERTIES BABEL BIND LATEX MACRO
:BABEL:
#+PROPERTY: header-args :session *R* :exports both :eval no :results output
:END:
:BIND:
#+BIND:         org-latex-image-default-width ""
#+BIND:         org-latex-tables-booktabs t
:END:
:LATEX:
#+LaTex_CLASS:  ManueStat
#+LaTeX_HEADER: \parindent 20pt \parskip 1ex  
#+COLUMNS:      %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
# LaTeX_HEADER: \usepackage[utf8]{inputenc} \usepackage[flushleft]{threeparttable}\renewcommand{\baselinestretch}{1.50} \newcommand\crule[3][black]{\textcolor{#1}{\rule{#2}{#3}}}
#+LaTeX_HEADER: \usepackage{tabularx, rotating, booktabs, lscape, tikz, dcolumn, amssymb, amsmath, amsthm, bbm, eurosym, threeparttable, pdflscape}
# LaTeX_HEADER: \usetikzlibrary{calc,trees,positioning,arrows,chains,shapes.geometric, decorations.pathreplacing,decorations.pathmorphing,shapes, matrix,shapes.symbols}
# LaTeX_HEADER: \newcolumntype{Y}{>{\raggedleft\arraybackslash}X} \usepackage{caption} \captionsetup{font={stretch=.7}, position=top} \newcommand{\indep}{\;\rotatebox[origin=c]{90}{$\models$}\;}
# LaTeX_HEADER: \newtheorem*{mydef*}{Definition} \newtheorem*{myrem*}{Remark}
# LaTeX_HEADER: \newtheorem{mydef}{Definition}[section]  \newcommand{\mydefautorefname}{Definition}
# LaTeX_HEADER: \newtheorem{myhyp}{Assumption}[section]  \newcommand{\myhypautorefname}{Assumption} 
# LaTeX_HEADER: \newtheorem{myprp}{Proposition}[section] \newcommand{\myintautorefname}{Proposition}
# LaTeX_HEADER: \newtheorem{mycor}{Corollary}[section]   \newcommand{\mycorautorefname}{Corollary}
# LaTeX_HEADER: \newtheorem{myrem}{Remark}[section]   \newcommand{\myremautorefname}{Remark}
:END:
:MACRO:
#+MACRO:         ffc @@latex: \superfullcite{$1}@@
#+MACRO:         flc @@latex: \alert{\ding{220}}@@
:END:

# https://www6.inra.fr/datapartage/Partager-Publier/Deposer-dans-Data-Inra2,
# https://www.sfedit.net
# https://www.comeetie.fr/

* README
  :PROPERTIES:
  :EXPORT_FILE_NAME: README
  :END:
** EN: The Informational Content of Geographical Indications 

   Relating Geographical Indications to biophysical characteristics of
   vineyards for the /Côte d'Or/ region (Burgundy, France).
   - Working paper XXX
   - Data: https://www6.inra.fr/datapartage/
   - Code: [[file:ReproPaper.pdf][PDF version]] or [[file:ReproPaper.md][Markdown]]
   - Dynamic carto:  [[https://site-a-determiner.fr]]

** FR: Le contenu Informationnel des Appellations d'Origine

   Relations entre les Appellations d'Origine Contrôlée et les
   caractéristiques biophysiques des vignobles de Côte d'Or
   (Bourgogne).
   - Présentation des données : [[file:DataPaper.pdf][PDF version]] or [[file:DataPaper.md][Markdown]]
   - Data : https://www6.inra.fr/datapartage/
   - Cartographie dynamique : [[https://site-a-determiner.fr]]

** Credits

   Made on =emacs= =org-mode=, to interect with =R=, =LaTex=,
   =Markdown=.

#+begin_export html
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
#+end_export

* Mail Jasper Morris

  Dear Jasper Morris,

  I am a French researcher in economics, working at the National
  Institute for Agricultural Research (INRA) at Dijon. 

  I have read with great interest some portions of your book "Inside
  Burgundy", in particular the references between the actual AOC and
  other historical classifications and some refinements that you
  propose.

  I would like to use these information in my researches on the
  evaluation of the AOC scheme in Côte d'Or.

  - Do you agree for an academic usage of your data, with quotation of
    the source (i.e., the book) ?
  - Do you have these data in tab-formatted files to avoid me to grasp
    them by hand ?
  - Does your tasting notes mentioned on your website could be
    available as well-formatted data bases?

  Thank you for your response and all your passion about Burgundy's
  wines.

  Best Regards, Jean-Sauveur Ay.

* Bibliography
  :PROPERTIES:
  :EXPORT_FILE_NAME:    Biblio.pdf
  :EXPORT_LATEX_CLASS:  ManueBibt
  :EXPORT_OPTIONS:      TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc toc:nil H:2
  :EXPORT_LATEX_HEADER: \usepackage{hyperref, xcolor} \hypersetup{colorlinks=true, linkcolor=red, urlcolor=blue, citecolor=gray} \usepackage[utf8]{inputenc} \usepackage[T1]{fontenc} 
  :EXPORT_AUTHOR:       \textsc{Bibliography}
  :END:
** Bourgogne specific
*** cite:Jull16 [[file:Biblio/Trie/Jull16.pdf][Book: Jullien 1816]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@BOOK{Jull16,
  TITLE = {Topographie de tous les vignobles connus},
  SUBTITLE = {Contenant leur position géographique, l'indication du
                  genre et de la qualité des produits de chaque cru,
                  les lieux ou se font les chargement et le principal
                  commerce des vins, le nom et la capacité des
                  tonneaux et des mesures en usage, les moyens de
                  transaport ordinairement employés, les tarifs des
                  douanes de France et des pays étrangers, etc.},
  AUTHOR = {Jullien, André},
  YEAR = {1816},
  PUBLISHER = {Colas, Paris},
}
#+end_src

- Partie Bourguignone [[pdfview:/home/jsay/geoIndic/Biblio/Trie/Jull16.pdf::133][ici]], distingue les départements.
- Rien sur Gigondas, se comprend avec la date.

*** cite:More31 [[file:Biblio/Trie/More31.pdf][Book: Morelot 1831]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@BOOK{More31,
  TITLE = {Statistique de la vigne dans le département de la Côte
                  d'Or},
  AUTHOR = {Morelot, Denis},
  YEAR = {1831},
  PUBLISHER = {Lagier, Dijon},
}
#+end_src

- Une autre proposition de désignation
- Des statistiques sur les surfaces et les productions communales et
  les revenus imposables

*** cite:Lava55 [[file:Biblio/Trie/Lava55.pdf][Book: Lavalle 1855]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@BOOK{Lava55,
  TITLE = {Histoire et statistique de la vigne et des grands vins de
                  la Côte d'Or},
  AUTHOR = {Lavalle, Jules},
  YEAR = {1855},
  PUBLISHER = {Daumier, Dijon},
}
#+end_src

    Il y a les dates de vendange sur longue période au début.

    Le Dr Jules Lavalle a rédigé ‘Histoire de la Statistique de la
    Vigne et des Grands Vins de la Côte d’Or’ en 1855. L’ouvrage est
    une référence majeure car il contient le premier essai de
    classement complet des climats de la Côte d’Or. Ce classement est
    réalisé par finage. Pour chacun, les climats sont catégorisés
    selon leur mérite en vertu d’un système comportant jusqu’à cinq
    classes: Tête de Cuvée (parfois ‘Hors Ligne’ selon le contexte,
    comme pour le Clos de Vougeot), Première/Seconde/Troisième/ et
    Quatrième Cuvée. Sur un aspect délicat de son classement, celui de
    l’éventuelle comparaison des classes identiques entre les communes
    par le lecteur, Jules Lavalle écrit "Je n’ai étudié les vins de
    chacune des communes de la Côte comme si les autres communes
    n’eussent pas existé et la classification que j’ai donnée n’est
    vrai que pour chacune d’elles prises isolément." (p.162) Le
    monumental travail de Jules Lavalle contient aussi le premier
    exercice, rigoureux, de cartographie de La Côte.  Il fut
    professeur à l’école de médecine de Dijon, directeur du Jardin
    botanique de cette ville, secrétaire de la Société d’Horticulture
    de la Côte d’Or et membre de la Société géologique de France.

*** cite:Dang92 [[file:Biblio/Trie/Dang92.pdf][Book: Danguy 1892]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@BOOK{Dang92,
  TITLE = {Les grands vins de Bourgogne (la Côte d'Or)},
  SUBTITLE = {Étude et classement par ordre de mérite},
  AUTHOR = {Danguy, René and Aubertin, Charles},
  YEAR = {1892},
  PUBLISHER = {Librairie H. Armand, Dijon},
}
#+end_src

- Quelques photos sur les bâtiments 
- Partie sur Marsannay [[pdfview:/home/jsay/geoIndic/Biblio/Trie/Dang92.pdf::677][ici]]
- Déjà l'idée d'une catégorisation mais semble moins central que dans
  les autres livres de l'époque. Ce sont surtout les noms des
  propriétaires qui sont importants.

*** cite:Chre00 [[file:Biblio/Trie/Chre00.pdf][Référentiel Pédo]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Chre00,
  title={R{\'e}f{\'e}rentiel p{\'e}dologique de Bourgogne {\`a}
                  1/250000(r{\'e}gions naturelles, p{\'e}dopaysages et
                  sols de la C{\^o}te-d'Or)},
  author={Chr{\'e}tien, Jean},
  year={2000},
  publisher={Institut national de la recherche agronomique, Centre de
                  recherche d'Orl{\'e}ans}
}
#+end_src

- Référentiel pédologique de Bourgogne
- Pas de pdf

*** cite:JLaf06 [[file:Biblio/Trie/JLaf06.pdf][AHSS: Équivalences au XIXe]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{JLaf06,
  title={Le contr{\^o}le r{\'e}publicain du march{\'e}: vignerons et
                  n{\'e}gociants sous la Troisi{\`e}me R{\'e}publique},
  author={Jacquet, Olivier and Lafert{\'e}, Gilles},
  journal={Annales. Histoire, sciences sociales},
  volume={61},
  number={5},
  pages={1147-1170},
  year={2006},
  publisher={Cambridge University Press}
}
#+end_src

- La liste des "communes porte drapeau" en note de bas de page mais
  assez "molle" selon Gilles

*** cite:Coat08 [[file:Biblio/Trie/Coat08.pdf][Book: Wines of Burgundy]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Coat08,
  title={The wines of Burgundy},
  author={Coates, Clive},
  year={2008},
  publisher={Univ of California Press}
}
#+end_src

- Bouquin précis sur les Grand crus Bourguignons.
- Pas de pdf

*** cite:Jacq09 [[file:Biblio/Trie/Jacq09.pdf][Book: Construction vignoble]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Jacq09,
  title={Un si{\`e}cle de construction du vignoble bourguignon. Les
                  organisations vitivinicoles de 1884 aux AOC},
  author={Jacquet, Olivier},
  year={2009},
  publisher={Editions Universitaires de Dijon}
}
#+end_src

- Le rôle des organisations syndicales, citation importante pour les
  biais communaux dans les désignations

*** cite:Norm10 [[file:Biblio/Trie/Norm10.pdf][Book: Grand crus]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Norm10,
  title={Grand Cru: The Great Wines of Burgundy Through the
                  Perspective of Its Finest Vineyards},
  author={Remington Norman},
  year={2010},
  publisher={Kyle Cathie},
  pages={p. 240}
}
#+end_src

- Bouquin précis sur les Grand crus Bourguignons.
- Pas de pdf

*** cite:Morr10 [[file:Biblio/Trie/Morr10.pdf][Book: Inside burgundy]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Morr10,
  title={Inside Burgundy: The Vineyards, the Wine \& the People},
  author={Morris, Jasper},
  year={2010},
  publisher={Berry Bros. \& Rudd Press}
}
#+end_src

- Bouquin précis sur les Grand crus Bourguignons.
- Pas de pdf

*** cite:WJac11 [[file:Biblio/Trie/Papier.pdf][Book: Wolikow et Jacquet]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@BOOK{WJac11,
  TITLE = {Territoires et terroirs du vin du XVIIIe au XXIe siècles},
  SUBTITLE = {Approche internationale d'une construction historique},
  AUTHOR = {Wolikow, Serge and Jacquet, Olivier},
  YEAR = {2011},
  PUBLISHER = {Éditions Universitaires de Dijon},
}
#+end_src

  Les chapitres qui concernent la Bourgogne et peuvent m'intéresser:

- Jules Guyot... de Christophe Lucand. Il situe l'apparition des AOC
  liée au commerce (XIXe) pour identifier des type de goût (il y a
  même preuve de retours de bouteilles si ça ne correspond pas). Il
  parle de passage du territoire commercial au terroir. Ce n'est que
  suite au Phylloxéra que la protection contre la fraude apparaît,
  arrive alors la réglementation.  
- La justification des usages... d'Olivier Jacquet. Il analyse le
  jugement de 1930, avec en particulier les apports du syndicat des
  producteurs qui ont a priori été écoutés. Les 3 auteurs les plus
  cités reviennent, et il y a en plus des données sur les prix, il
  faudrait que je parle avec Olivier de l'exploitation de ces données.
- Quand le cadastre... de Charlotte Fromont. Liste de bonne manière
  les principales utilisations qui pourraient être faites du cadastre
  Napoléonien et des matrices cadastrales sur les propriétaires en
  particulier. Seulement à partir de petites études de cas, il
  faudrait prendre des nouvelles sur la généralisation potentielle.
- De l'intérêt de spatialiser... Garcia et al. Le moulinage de données
  au travers d'un MNT quelques idées/ intuitions mais un travail qui
  n'est pas allé plus loin que la thèse il me semble. Voir les travaux
  qui suivent de Garcia.
- Délimitations AOC entre usage et milieu... Vincent et al. Un peu la
  position de l'INAO sur les délimitations, intéressant pour le
  discours officiel.

*** cite:LLPi14 [[file:Biblio/Trie/WJac11.pdf][Book: Climats et lieux-dits]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@BOOK{LLPi14,
  TITLE = {Climats et lieux-dits des grands vignobles de {B}ourgogne},
  SUBTITLE = {Atlas et histoire des noms de lieux},
  AUTHOR = {{Landrieu-Lussigny}, Marie-Hélène and Pitiot, Sylvain},
  YEAR = {2014},
  PUBLISHER = {Éditions de Monza et du Meurger},
}
#+end_src

*** cite:Bazi15 [[file:Biblio/Trie/Bazi15.pdf][Book: Vin de Bourgogne]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Bazi15,
  title={Le vin de Bourgogne},
  author={Bazin, Jean-Fran{\c{c}}ois},
  year={2015},
  publisher={Dunod Editions}
}
#+end_src

- Livre de référence sur les vins en Francais
- pas de pdf

*** Garcia 2010, [[file:Biblio/Trie/Garc10.pdf][lien avec Dion]] 

    Données nouvelles pour l’histoire de la construction des terroirs
    viticoles de Bourgogne, cinquante ans après l’oeuvre de Roger Dion
    
    Discussion entre déterminants naturels, histoire de pentes et de
    déplacement du vignoble. Même graphique qu'Olivier sur les
    organisations vini-viticoles en meilleure résolution.

*** cite:Garc14, [[file:Biblio/Trie/Garc14.pdf][ACRH: Climats moyen âge]] 

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Garc14,
  title={La construction des climats viticoles en {B}ourgogne, la
                  relation du vin au lieu au {M}oyen {Â}ge},
  author={Jean-Pierre Garcia},
  journal={Atelier du Centre de Recherches Historiques},
  volume={12},
  pages={22 p},
  year={2014},
  publisher={http://journals.openedition.org/acrh/5979}
}
#+end_src


    La construction des climats viticoles en Bourgogne, la relation du
    vin au lieu au Moyen Âge
    
    Publication un peu plus sérieuse que les autres.

*** Garcia 2018,  [[file:Biblio/Trie/Garc18.pdf][InBook: Construction noms]] 

    La pérennisation par la remotivation des lieux, des mots et des
    choses de la Bourgogne viticole, in : Bourgogne(s) viticole(s) –
    Enjeux et perspectives historiques d’un territoire (S. Wolikow et
    O. Jacquet, dir.), Dijon, EUD, 2018, p. 145-152.

    Le concept de climat au cours du temps. Proche de la publi GLGr17
    ci-dessous.

*** Garcia et Labbé 2017 [[file:Biblio/Trie/GLGr17.pdf][Concept de Climat]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{GGLa17,
  title={Terroirs, climats ... ou le vin et le lieu en Bourgogne},
  author={Jean-Pierre Garcia, Guillaume Grillon, Thomas Labbé},
  journal={HAL},
  volume={01574896},
  year={2017}
}
#+end_src

    proche de ce qui suit Garc16

*** cite:Garc11 [[file:Biblio/Trie/Garc11.pdf][Book: Patrimoine mondial]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Garc11,
  title={Les \emph{climats} du vignoble de {B}ourgogne comme
                  patrimoine mondial de l'humanit{\'e}},
  author={Garcia, Jean-Pierre},
  year={2011},
  publisher={Ed. Universitaires de Dijon}
}
#+end_src

    Les mêmes figures que précédemment. Diapos pour le dossier de
    classement: [[file:Biblio/Trie/diapo1.pdf][Diapo 1]] ; [[file:Biblio/Trie/diapo2.pdf][Diapo 2]] ; [[file:Biblio/Trie/diapo3.pdf][Diapo 3]] ; [[file:Biblio/Trie/diapo4.pdf][Diapo 4]].

*** cite:WJac18 [[file:Biblio/Trie/Papier.pdf][Book: Wolikow et Jacquet 2018]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{WJac18,
  title={Bourgogne(s) viticole(s) : Enjeux et perspectives historiques
                  d'un territoire},
  author={Wolikow, Serge and Jacquet, Olivier},
  year={2018},
  publisher={{\'E}ditions Universitaires de Dijon}
}
#+end_src

** Geographical Indications
*** cite:HMDO99 [[file:Biblio/Trie/HMDO99.pdf][AJAE: Choice of grade]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{HMDO99,
  title={Pleasures of cockaigne: Quality gaps, market structure, and
                  the amount of grading},
  author={Hollander, Abraham and Monier-Dilhan, Sylvette and Ossard,
                  Herve},
  journal={American Journal of Agricultural Economics},
  volume={81},
  number={3},
  pages={501--511},
  year={1999},
  publisher={Oxford University Press}
}
#+end_src

- Choix d'adoption des grade

*** cite:CLVi00 [[file:Biblio/Trie/CLVi00.pdf][AE: Hedonic Burgundy]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CLVi00,
  title={Estimation of a hedonic price equation for {B}urgundy wine},
  author={Combris, Pierre and Lecocq, S{\'e}bastien and Visser,
                  Michael},
  journal={Applied Economics},
  volume={32},
  number={8},
  pages={961--967},
  year={2000},
  publisher={Taylor \& Francis}
}
#+end_src

- Modele hedoniques sur le prix des bouteilles en Bourgogne.
- Des effets à la fois des caractéristiques objectives mais aussi des
  AOCs.
- Bonne citation pour localiser le Bourgogne

*** cite:CSex02 [[file:Biblio/Trie/CSex02.pdf][AJAE: Grading errors]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CSex02,
  title={Marketing orders, grading errors, and price discrimination},
  author={Chalfant, James A and Sexton, Richard J},
  journal={American Journal of Agricultural Economics},
  volume={84},
  number={1},
  pages={53--66},
  year={2002},
  publisher={Oxford University Press}
}
#+end_src

- Les erreurs de grading peuvent avoir les même conséquence que la
  régulation par les quantités.
- La qualité est endogène ici.

*** cite:Barh03 [[file:Biblio/Trie/Barh03.pdf][JRS: Translating terroir]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Barh03,
  title={Translating terroir: The global challenge of {F}rench {AOC}
                  labeling},
  author={Barham, Elizabeth},
  journal={Journal of rural studies},
  volume={19},
  number={1},
  pages={127--138},
  year={2003},
  publisher={Elsevier}
}
#+end_src

- Parle de la place du terroir dans les négociations
  internationales
- Il y a un bouquin écrit par la même auteur

*** cite:Mahe04 [[file:Biblio/Trie/Mahe04.pdf][AJAE: Informed buyers]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Mahe04,
  title={Influence of informed buyers in markets susceptible to the
                  lemons problem},
  author={Mahenc, Philippe},
  journal={American Journal of Agricultural Economics},
  volume={86},
  number={3},
  pages={649--659},
  year={2004},
  publisher={Oxford University Press}
}
#+end_src

- Modèle d'économie industrielle où les vins de Bordeaux sont cités en
  exemple d'une théorie plus générale.
- Les individus ne se différentient que sur une seule dimension et
  avec des utilités linéaires, les fonctions de demande sont très
  simples. Il n'y a que deux niveaux de qualité du bien.
- Dans un premier temps apparaît un équilibre /pooled/ où les prix ne
  permettent pas de signaler la qualité. La vrai raison est qu'il est
  trop peu coûteux pour les producteurs de basses qualités de se
  déclarer haut.
- Puis, s'il y a certains individus informés et "pessimistes" sur la
  qualité, on peut signaler la qualité et on sort du problème des
  lemons.

*** cite:Stan04 [[file:Biblio/Trie/Stan04.pdf][EJLE: Law AOC]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Stan04,
  title={Wine reputation and quality controls: The origin of the
                  {AOCs} in 19th century {F}rance},
  author={Stanziani, Alessandro},
  journal={European Journal of Law and Economics},
  volume={18},
  number={2},
  pages={149--167},
  year={2004},
  publisher={Springer}
}
#+end_src

- Papier non économique sur les processus historiques en jeu dans la
  création des AOC en france, et la possibilité d'avoir des rentes.
- Vision juridique

*** cite:Stor05 [[file:Biblio/Trie/Stor05.pdf][JWR: OP wine quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Stor05,
  title={English weather and {R}hine wine quality: An ordered probit
                  model},
  author={Storchmann, Karl},
  journal={Journal of Wine Research},
  volume={16},
  number={2},
  pages={105--120},
  year={2005},
  publisher={Taylor \& Francis}
}
#+end_src

- Exemple de probit ordonné
- Mais ce n'est pas sur les AOC, c'est sur les classement des
  millésimes
- Mais il y a un lien avec le climat

*** cite:WMCl05 [[file:Biblio/Trie/WMCl05.pdf][AJAE: Reputation]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{WMCl05,
  title={Collective reputation and quality},
  author={Winfree, Jason A and McCluskey, Jill J},
  journal={American Journal of Agricultural Economics},
  volume={87},
  number={1},
  pages={206--213},
  year={2005},
  publisher={Oxford University Press}
}
#+end_src

- L'application de Tirole 1996 sur la réputation collective, appliquée
  aux IG.

*** cite:Rame06 [[file:Biblio/Trie/Rame06.pdf][JES: Survey marks]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Rame06,
  title={What's in a sign? Trademark law and economic theory},
  author={Ramello, Giovanni B},
  journal={Journal of Economic Surveys},
  volume={20},
  number={4},
  pages={547--565},
  year={2006},
  publisher={Wiley Online Library}
}
#+end_src

- Survey sur la référencement des produits

*** cite:Josl06 [[file:Biblio/Trie/Josl06.pdf][JAE: War on terroir]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Josl06,
  title={The war on terroir: geographical indications as a
                  transatlantic trade conflict},
  author={Josling, Tim},
  journal={Journal of Agricultural Economics},
  volume={57},
  number={3},
  pages={337--363},
  year={2006},
  publisher={Wiley Online Library}
}
#+end_src

- Une /presidential address/ bien littéraire sur les intérêts et
  les limites des indications géographiques dans un contexte de
  commerce international.
- De nombreuses phrases peuvent être utilisées en citation.
- Peut servir en particulier à appuyer l'antagonisme entre l'Europe et
  les Etats Unis sur ces questions. C'est ce qu'il appelle la guerre
  du /terroir/.
- Globalement, il est pour les AOC.

*** cite:BKir07 [[file:Biblio/Trie/BKir07.pdf][Agrk: Protecting GI]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{BKir07,
  title={Exploring the economic rationale for protecting geographical
                  indicators in agriculture},
  author={Bramley, Cerkia and Kirsten, Johann F},
  journal={Agrekon},
  volume={46},
  number={1},
  pages={47--71},
  year={2007},
  publisher={Taylor \& Francis}
}
#+end_src

- Discussion sur l'économie des indications géographiques
- The economic rationale for protecting Geographical Indications
  derives mainly from the fact that place of origin may be used as a
  quality signal, or alternatively, that the resources of the region
  may be captured as quality attributes.

*** cite:MMPi08 [[file:Biblio/Trie/MMPi08.pdf][AJAE: GI to provide quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MMPi08,
  title={Geographical indications and the competitive provision of
                  quality in agricultural markets},
  author={Moschini, GianCarlo and Menapace, Luisa and Pick, Daniel},
  journal={American Journal of Agricultural Economics},
  volume={90},
  number={3},
  pages={794--812},
  year={2008},
  publisher={Oxford University Press}
}
#+end_src

- Positive welfare effects of GIs

*** cite:TBow08 [[file:Biblio/Trie/TBow08.pdf][GeoJourn: Learn from AOC]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{TBow08,
  title={Creating the taste of place in the {U}nited {S}tates: can we
                  learn from the {F}rench?},
  author={Trubek, Amy B and Bowen, Sarah},
  journal={GeoJournal},
  volume={73},
  number={1},
  pages={23--30},
  year={2008},
  publisher={Springer}
}
#+end_src

- Pour illustrer les liens entre la définition du terroir et la
  géographie.

*** cite:Bena10 [[file:Biblio/Trie/Bena10.pdf][WP: GI as a club asset]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@techreport{Bena10,
  title={The Economics of Geographical Indications: GIs modeled as
                  club assets},
  author={Benavente, Daniela},
  year={2010},
  institution={Graduate Institute of International and Development
                  Studies Working Paper}
}
#+end_src

- GIs are not pure public goods, they are club goods with non-rivality
  but partial excluability. They are also presented as intangible.
- The link between GIs and club goods is not well, it is more a
  reputation in this paper than trully geographical.

*** cite:CMCG10 [[file:Biblio/Trie/CMCG10.pdf][AJAE: Nested names]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CMCG10,
  title={The economics of nested names: {N}ame specificity,
                  reputations, and price premia},
  author={Costanigro, Marco and McCluskey, Jill J and Goemans, Christopher},
  journal={American Journal of Agricultural Economics},
  volume={92},
  number={5},
  pages={1339--1350},
  year={2010},
  publisher={Oxford University Press}
}
#+end_src

- Se pose la question de l'échelle à laquelle se déterminent les
  réputations basés sur des noms. Cela est possible car ils
  s'intéressent à un cas oû les noms sont imbriqués: vin californiens
  (également justifié par la disposition d'appréciation de la qualité
  à l'aveugle donc exogènes à la réputation).
- Le point de départ est que les agents basent leurs croyances en
  termes de réputation sur des indicateurs de la performance
  passée. Mais la relation exacte n'est pas connue.
- Modélise la réputation comme des primes sur les prix de vente des
  bouteilles de vin, avec l'approche quartile en plus. Cependant, les
  primes contiennent les coûts de recherche en plus de la WTP.
- Quand le prix du vin augmente, le coût d'avoir faux augmente et donc
  la valeur de l'information: *justification pour le quantile*
- On a également la preuve que la longévité d'un nom compte du point
  de vue de la réputation pour les consommateurs.
- Quelques détails sur la régression quartile sont intéressants
  (bootstrap).

*** cite:CFlo10 [[file:Biblio/Trie/CFlo10.pdf][CJAE: GI Burgundy]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CFlo10,
  title={The importance of geographic wine appellations: Hedonic
                  pricing of {B}urgundy wines in the {B}ritish
                  {C}olumbia wine market},
  author={Carew, Richard and Florkowski, Wojciech J},
  journal={Canadian Journal of Agricultural Economics/Revue canadienne
                  d'agroeconomie},
  volume={58},
  number={1},
  pages={93--108},
  year={2010},
  publisher={Wiley Online Library}
}
#+end_src

- Sur des modeles hédoniques du prix des vins de Bourgogne au Canada
- Les AOC ont des primes positives, sur la base du prix de la
  bouteille.
- Bonne citation pour localiser le Bourgogne

*** cite:MMos12 [[file:Biblio/Trie/MMos12.pdf][ERAE: Quality and GIs]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MMos12,
  title={Quality certification by geographical indications, trademarks
                  and firm reputation},
  author={Menapace, Luisa and Moschini, GianCarlo},
  journal={European Review of Agricultural Economics},
  volume={39},
  number={4},
  pages={539--566},
  year={2012},
  publisher={Oxford Univ Press}
}
#+end_src

- Ils montrent que, malgré la possibilité pour les producteurs de
  faire leur propre trademark, la présence d'une certification
  géographique augmente l'efficacité de la réputation pour signaler la
  qualité.
- La certification permet de diminuer les coûts de l'investissement en
  réputation.
- Ceux pour qui la réputation est basée sur une marque sont alors
  réticents à l'arrivée d'une certification, même si ils peuvent en
  profiter.
- Leur analyse plaide pour la vision européenne dans le débat avec les
  US à l'OMC.

*** cite:MSex12 [[file:Biblio/Trie/MSex12.pdf][ERAE: Excess quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MSex12,
  title={Will geographical indications supply excessive quality?},
  author={M{\'e}rel, Pierre and Sexton, Richard J},
  journal={European Review of Agricultural Economics},
  volume={39},
  number={4},
  pages={567--587},
  year={2012},
  publisher={Oxford Univ Press}
}
#+end_src

- Contre les AOC car il font du pooling equilibrium sur les basses
  qualités et offre trop de différenciations pour les autres.

*** cite:BCon14 [[file:Biblio/Trie/BCon14.pdf][AJAE: Survey label]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{BCon14,
  title={On the economics of labels: How their introduction affects
                  the functioning of markets and the welfare of all
                  participants},
  author={Bonroy, Olivier and Constantatos, Christos},
  journal={American Journal of Agricultural Economics},
  volume={97},
  number={1},
  pages={239--259},
  year={2014},
  publisher={Oxford University Press}
}
#+end_src

- Survey sur les effets économiques des labels de qualité, GI y
  compris.

*** cite:Brec14 [[file:Biblio/Trie/Brec14.pdf][REE: label profusion]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Brec14,
  title={Consumer confusion over the profusion of eco-labels: Lessons
                  from a double differentiation model},
  author={Br{\'e}card, Doroth{\'e}e},
  journal={Resource and energy economics},
  volume={37},
  pages={64--84},
  year={2014},
  publisher={Elsevier}
}
#+end_src

- Double différenciation des labels car on peut produire de la faible
  qualité sous un certain label.

*** cite:DSwi14 [[file:Biblio/Trie/DSwi14.pdf][AAWE: Political of AOC]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{DSwi14,
  title={The political economy of Geographical Indications},
  author={Deconinck, Koen and Swinnen, Johan},
  journal={AAWE working paper No 174},
  year={2014}
}
#+end_src

- Il y a une idée de centralité de l'AOC et que les consommateurs
  n'ont de signal que sur la qualité.
- Ils se posent la question de l'extension de l'aire d'appellation et
  le process institutionnel qui permet de le déterminer.

*** cite:Malt14 [[file:Biblio/Trie/Malt14.pdf][ASQ: Causality crus]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Malt14,
  title={On the causality and cause of returns to organizational
                  status: Evidence from the grands crus class{\'e}s of
                  the M{\'e}doc},
  author={Malter, Daniel},
  journal={Administrative Science Quarterly},
  volume={59},
  number={2},
  pages={271--300},
  year={2014},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}
#+end_src

- Question du Organizational Status, qu'il distingue de la qualité
  mais aussi de la réputation.
- sorted 61 wine producers into five growth classes in 1855, as a
  fixed hierarchical symbol of class status. The classification has
  defied attempts at revision for more than 150 years
- I study a period of time during which the uncertainty about quality
  has arguably declined because the Internet has made wine ratings
  ubiquitously available.
- organizational status as a signal of quality under uncertainty
  (Podolny, 2005)
- Effet des primes Bordeaux, avec exogénéité supposée des primes du
  fait de leur histoire.
- Biased matching because of unobservables: IV

*** cite:USTR17 [[file:Biblio/Trie/USTR17.pdf][Report Intellectual property]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{USTR17,
  title                    = {2017 {S}pecial 301 {R}eport},
  author                   = {USTR},
  year                     = {2017},
  journal                  = {Office of the United States Trade Representative},
  volume                   = {81 p.},
  pages                    = {\url{https://ustr.gov/sites/default/files/301/2017 Special 301 Report FINAL.PDF}}
}
#+end_src

- Contre les indications géographiques en Europe.

*** cite:GLRW17 [[file:Biblio/Trie/GLRW17.pdf][FP: Collective reputation]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{GLRW17,
  title={Evaluating the net benefits of collective reputation: The
                  case of {B}ordeaux wine},
  author={Gergaud, Olivier and Livat, Florine and Rickard, Bradley and
                  Warzynski, Frederic},
  journal={Food Policy},
  volume={71},
  pages={8--16},
  year={2017},
  publisher={Elsevier}
}
#+end_src

- Réputation collective à la suite de Tirole 1996. Lien avec Lalonde
  and Smith (1997, 1998). Here, the collective reputation refers to
  the appellation name and individual reputations at the firm level
  are proxied by the average ratings the wines have received from a
  popular wine guide.
- C'est un modèle en système imbriqué, où la réputation agrégée dépend
  des réputations individuelles et les réputations individuelles
  dépendent de la réputation agrégée. Il n'ont pas de bons instruments
  pour les réputations individuelles donc ils ne s'intéressent qu'à
  l'effet de la réputation agrégée sur les individuelles
- Ils se servent de l'imbrication des différentes échelles des
  appellations contre l'endogénéité de la réputation
  collective. L'appréciation de Bordeaux est instrumentée par les
  appréciations des autres régions viticoles à cette échelle. On a
  quelque part une sorte de modèle hiérarchiques à 2 étapes.

*** cite:MCKa17 [[file:Biblio/Trie/MCKa17.pdf][AEPP: Food labeling]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MCKa17,
  title={Labeling food processes: The good, the bad and the ugly},
  author={Messer, Kent D and Costanigro, Marco and Kaiser, Harry M},
  journal={Applied Economic Perspectives and Policy},
  volume={39},
  number={3},
  pages={407--427},
  year={2017},
  publisher={Oxford University Press}
}
#+end_src

- ça parle plutôt de labels vis-à-vis de l'environnement. Ils les
  appelle les "process label". Il sont dans une opposition binaire
  entre ce qui est scientifique et ce qui ne l'est pas, sans parler
  d'incertitude.
- When product quality and safety is uncertain, consumers can search
  for information they deem important. But when information about a
  food product is too costly or difficult to obtain, aligning food
  choices with individual preferences is problematic. Further
  complicating matters is the fact that many important food
  characteristics, such as taste, can be assessed only after consuming
  the food (“experience attributes”; Nelson 1970), and the authen-
  ticity of many claims, such as “extra virgin” olive oil, is known to
  producers but cannot be directly verified by consumers (“credence
  attributes”; Darby and Karni 1973). As pointed out by Caswell and
  Mojduszka (1996), labels can facilitate consumer choice by
  transforming credence and experience attributes into searchable
  characteristics, thereby decreasing the information gap between
  consumers and producers. Thus, a truthful certification of the
  production process should make the outcomes searchable attributes.

*** cite:YBMZ17 [[file:Biblio/Trie/YBMZ17.pdf][Quality in nested names (AJAE)]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{YBMZ17,
  title={What is in a Name? {I}nformation, Heterogeneity, and Quality
                  in a Theory of Nested Names},
  author={Yu, Jianyu and Bouamra-Mechemache, Zohra and Zago, Angelo},
  journal={American Journal of Agricultural Economics},
  volume={100},
  number={1},
  pages={286--310},
  year={2017},
  publisher={Oxford University Press}
}
#+end_src

- The economics theory of Nested names
- At Marsannay, we are clearly in such a situation in regard to the
  other wines from burgundy. The authors say: "the Burgundy
  classification system is the most sophisticated, with a very long
  tradition of classifying vineyards to find the best quality climats,
  that is, plots of land. Burgundy’s soil quality is very heteroge-
  neous and this, together with differences in altitude and
  exposition, has always led to wines of “almost unpredictable
  quality” (Johnson and Robinson 2013). However, over time traders
  have learned to distinguish the quality of wines coming from
  different climats, and so the prices of the grapes have reflected
  the quality potential of different plots. The best plots were those
  able to give quality wines consistently across years with different
  weather conditions. In short, nowadays pundits continue to argue for
  the Bungundy classification system, given that “the general validity
  of the hierarchy is well supported by the market” (Lewin 2010)."
- An interesting case is the appellation of Montagny, on the Cote
  Chalonnaise, where producers between 1989 and 1991 voluntarily
  decided to reduce the number of Premiers Crus, that is, the
  second-tier climats. “There were plenty of private and public spats
  over which vineyards kept their status [..] but the fact remains
  that the winemakers had seen over the preceeding decades that
  certain plots in Montagny made unquestionably better wines than
  others,” (Anson 2016).

*** cite:MSwi18 [[file:Biblio/Trie/MSwi18.pdf][FP: First GIs]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MSwi18,
  title={Trade and terroir. The political economy of the world’s first
                  geographical indications},
  author={Meloni, Giulia and Swinnen, Johan},
  journal={Food Policy},
  volume={81},
  pages={1--20},
  year={2018},
  publisher={Elsevier}
}
#+end_src

- 

*** cite:CSCa19 [[file:Biblio/CSCa19.pdf][Vertical differentiation and geographical indications (FP)]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CSCa19,
  title={Vertical differentiation via multi-tier geographical
                  indications and the consumer perception of quality:
                  The case of {C}hianti wines},
  author={Costanigro, Marco and Scozzafava, Gabriele and Casini, Leonardo},
  journal={Food Policy},
  year={2019},
  publisher={Elsevier}
}
#+end_src

** Informational structure
*** cite:Aker70 [[file:Biblio/Trie/Aker70.pdf][QJE: Market for lemons]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Aker70,
  title={The market for "lemons": Quality uncertainty and the market
                  mechanism},
  author={Akerlof, George A},
  journal={Quarterly Journal of Economics},
  pages={488--500},
  year={1970},
  publisher={JSTOR}
}
#+end_src

- Papier séminal sur l'absence d'information qui tire la qualité des
  produits vers le bas.

*** cite:Nels70 [[file:Biblio/Trie/Nels70.pdf][JPE: Experience goods]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Nels70,
  title={Information and consumer behavior},
  author={Nelson, Phillip},
  journal={The Journal of Political Economy},
  volume={78},
  number={2},
  pages={311--329},
  year={1970},
  publisher={JSTOR}
}
#+end_src

- Défini ce que sont les biens d'expérience par rapport aux bien de
  recherche dans Stigler 1961. Le point commun est l'information.
- Les biens sont définis sur la manière dont les consommateurs
  obtiennent de l'information sur leur qualité.
- La fréquence d'achat et le prix du bien (qui est le coût
  d'acquisition de l'information en cas d'expérience) sont des
  attributs importants desquels il tire une typologie stylisée.

*** cite:Nels74 [[file:Biblio/Trie/Nels74.pdf][JPE: Advertising information]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Nels74,
  title={Advertising as information},
  author={Nelson, Phillip},
  journal={Journal of political economy},
  volume={82},
  number={4},
  pages={729--754},
  year={1974},
  publisher={The University of Chicago Press}
}
#+end_src

- Seminal paper about advertising and information, mais Nelson 1970
  (sur les biens d'expérience) est beaucoup cité tout au long de
  l'article
- Pour les biens d'expérience (ou plutôt les qualités d'expérience),
  la publicité n'a pas forcément d'intérêt à coller à la réalité
- The major control that consumers have over the market for experience
  qualities is whether they repeat the purchase of a brand or not
  (Nelson 1970).

*** cite:MRos78 [[file:Biblio/Trie/MRos78.pdf][JET: Monopole and quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MRos78,
  title={Monopoly and product quality},
  author={Mussa, Michael and Sherwin Rosen},
  journal={Journal of Economic Theory},
  volume={18},
  number={},
  pages={301--317},
  year={1978}
}
#+end_src

- Monopole et biais dans la provision de qualité
- Papier très théorique

*** cite:Shap82 [[file:Biblio/Trie/Shap82.pdf][BJE: Information and quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Shap82,
  title={Consumer information, product quality, and seller reputation},
  author={Shapiro, Carl},
  journal={The Bell Journal of Economics},
  pages={20--35},
  year={1982},
  publisher={JSTOR}
}
#+end_src

- Viewing reputation as an expectation of quality, this article
  studies the properties of quality expectations that are
  fulfilled. When sellers set quality once and for all, any
  self-fulfilling quality level must lie below the perfect information
  quality level
- Once for all endogenous quality

*** cite:Shap86 [[file:Biblio/Trie/Shap86.pdf][RES: License and certification]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Shap86,
  title={Investment, moral hazard, and occupational licensing},
  author={Shapiro, Carl},
  journal={The Review of Economic Studies},
  volume={53},
  number={5},
  pages={843--862},
  year={1986},
  publisher={Wiley-Blackwell}
}
#+end_src

- La présence de licences et de certifications ne sert à rien.

*** cite:BDWh87 [[file:Biblio/Trie/BDWh87.pdf][QJE: Quality distorsion]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{BDWh87,
  title={Monopoly and quality distortion: Effects and remedies},
  author={Besanko, David and Donnenfeld, Shabtai and White, Lawrence
                  J},
  journal={Quarterly Journal of Economics},
  volume={102},
  number={4},
  pages={743--767},
  year={1987},
  publisher={Oxford University Press}
}
#+end_src

- Article séminal sur les biais qualitatifs en présence d'absence
  d'information et donc de pouvoir de monopole.
- Minimum quality standard, No distorsion at the top

*** cite:DNab91 [[file:Biblio/Trie/DNab91.pdf][EL: Efficient certification scheme]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{DNab91,
  title={Economic implications of imperfect quality certification},
  author={De, Sankar and Nabar, Prafulla},
  journal={Economics Letters},
  volume={37},
  number={4},
  pages={333--337},
  year={1991},
  publisher={Elsevier}
}
#+end_src

- Efficient certification: better product is more likely to have
  higher quality ratio: Ordered models.

*** cite:BLar92 [[file:Biblio/Trie/BLar92.pdf][QJE: Gurus manipulate markets]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{BLar92,
  title={Using privileged information to manipulate markets: Insiders,
                  gurus, and credibility},
  author={Benabou, Roland and Laroque, Guy},
  journal={Quarterly Journal of Economics},
  volume={107},
  number={3},
  pages={921--958},
  year={1992},
  publisher={MIT Press}
}
#+end_src

- Théorie qui semble correpondre à nos résultats, les agents ont pu
  profiter des informations qu'ils avaient pour manipuler la qualité
  de l'information.

*** cite:Ryu93  [[file:Biblio/Trie/Ryu93.pdf][EL: Kullback-Leibler]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Ryu93,
  title={Monotonicity of the Fisher information and the
                  {K}ullback-{L}eibler divergence measure},
  author={Ryu, Keunkwan},
  journal={Economics Letters},
  volume={42},
  number={2-3},
  pages={121--128},
  year={1993},
  publisher={Elsevier}
}
#+end_src

- The information gain of discretizing a continuous signal,
  asymptotically.

*** cite:Tiro96 [[file:Biblio/Trie/Tiro96.pdf][RES: History vs stereotypes]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Tiro96,
  title={A theory of collective reputations (with applications to the
                  persistence of corruption and to firm quality)},
  author={Tirole, Jean},
  journal={Review of Economic Studies},
  volume={63},
  number={1},
  pages={1--22},
  year={1996},
  publisher={Wiley-Blackwell}
}
#+end_src

- The information gain of discretizing a continuous signal,
  asymptotically.

*** cite:Lizz99 [[file:Biblio/Trie/Lizz99.pdf][RJE: Monopoly in certifications]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Lizz99,
  title={Information revelation and certification intermediaries},
  author={Lizzeri, Alessandro},
  journal={The RAND Journal of Economics},
  pages={214--231},
  year={1999},
  publisher={JSTOR}
}
#+end_src

- La question de l'intermédiaire de certification lorsqu'il est en
  monopole.
- Il donne que très peu d'information mais la concurrence entre des
  intermédiaires d'information peut aller vers l'information parfaite.

*** cite:Tade99 [[file:Biblio/Trie/Tade99.pdf][AER: What's in a name]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Tade99,
  title={What's in a Name? {R}eputation as a Tradeable Asset},
  author={Tadelis, Steven},
  journal={American Economic Review},
  volume={89},
  number={3},
  pages={548--563},
  year={1999}
}
#+end_src

- Seminal reference

*** cite:ALiz01 [[file:Biblio/Trie/ALiz01.pdf][IER: Welfare certification]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{ALiz01,
  title={Strategic certification and provision of quality},
  author={Albano, Gian Luigi and Lizzeri, Alessandro},
  journal={International Economic Review},
  volume={42},
  number={1},
  pages={267--283},
  year={2001},
  publisher={Wiley Online Library}
}
#+end_src

- Effets de bien être d'un organisme tiers qui prodit de la
  classification.
- Welfare improving mais moins qu'en full information.

*** cite:Bagw01 [[file:Biblio/Trie/Bagw01.pdf][Book: Economics advertising]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@BOOK{Bagw01,
  TITLE = {The Economic Analysis of Advertising},
  AUTHOR = {Bagwell, Kyle},
  YEAR = {2001},
  PUBLISHER = {Edward Elgar Publishing},
}
#+end_src

- Seminal reference

*** cite:Guer01 [[file:Biblio/Trie/Guer01.pdf][WP: Ordered rankings of levels]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Guer01,
  title={Certification Disclosure and Informational Efficiency: A Case
                  for Ordered Ranking of Levels},
  author={Guerra, Gerardo A},
  year={2001},
  journal={University of Oxford, Department of Economics, Discussion
                  Paper 64},
  volume= {ISSN 1471-0498}
}

#+end_src

- have noisy estimates of the quality level of the agent being
  certified (seller), a disclosure in the form of ordered ranking of
  levels is predicted.

*** cite:MShi02 [[file:Biblio/Trie/MShi02.pdf][AER: Public information]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MShi02,
  title={Social value of public information},
  author={Morris, Stephen and Shin, Hyun Song},
  journal={The American Economic Review},
  volume={92},
  number={5},
  pages={1521--1534},
  year={2002},
  publisher={American Economic Association}
}
#+end_src

- Valeur de l'information sociale pas forcément positive quand elle
  cohabite avec de l'information privée.
- Modèle intéressant car très simple et met une équation structurelle
  de l'information disponible aux individus, à la fois de manière
  collective et individuelle.
- L'incertitude est globale, pas propre aux individus, ce qui rend le
  modèle difficilement applicable à l'information sur les AOC.
- Par un écart de l'action des individus avec l'état du monde
  objectif, la fonction de bien-être agrégé est facilement
  proportionnel à la précision de l'information: l'inverse de la
  variance des résidus.
- Je ne comprend pas l'équation 10 donc j'ai arrêté la lecture à ce
  point.

*** cite:JLes03 [[file:Biblio/Trie/JLes03.pdf][QJE: Hygiene quality in restaurants]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{JLes03,
  title={The effect of information on product quality: Evidence from
                  restaurant hygiene grade cards},
  author={Jin, Ginger Zhe and Leslie, Phillip},
  journal={Quarterly Journal of Economics},
  volume={118},
  number={2},
  pages={409--451},
  year={2003},
  publisher={MIT Press}
}
#+end_src

- Un effet très fort de la qualité endogène à l'information

*** cite:JMya06 [[file:Biblio/Trie/JMya06.pdf][AER: simple advertising]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{JMya06,
  title={On the simple economics of advertising, marketing, and
                  product design},
  author={Johnson, Justin P and Myatt, David P},
  journal={American Economic Review},
  volume={96},
  number={3},
  pages={756--784},
  year={2006}
}
#+end_src

- C'est un style de survey sur les rotations de demande, par
  opposition aux shifts étudiés habituellement.
- On distingue l'information selon qu'elle soit hype (demande shift)
  ou real (demande rotation).
- Analytiquement assez loin de ce que je cherche.

*** cite:DJin10 [[file:Biblio/Trie/DJin10.pdf][JEL: Quality certification]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{DJin10,
  title={Quality disclosure and certification: Theory and practice},
  author={Dranove, David and Jin, Ginger Zhe},
  journal={Journal of Economic Literature},
  volume={48},
  number={4},
  pages={935--63},
  year={2010}
}
#+end_src

- Revue de littérature sur les certifications de la qualité

*** cite:GPen10 [[file:Biblio/Trie/GPen10.pdf][Econca: Signal ordering]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{GPen10,
  title={Signal orderings based on dispersion and the supply of
                  private information in auctions},
  author={Ganuza, Juan-Jos{\'e} and Penalva, Jose S},
  journal={Econometrica},
  volume={78},
  number={3},
  pages={1007--1030},
  year={2010},
  publisher={Wiley Online Library}
}
#+end_src

- Ils n'utilisent pas la variance pour mesurer la précision, on ne
  voit pas trop pourquoi, probablement des raisons analytiques. Il
  faudrait comparer les critères qu'ils proposent à la variance dans
  le cas gaussien ordonné.
- Notice that signals are ordered for a given prior. The prior plays a
  crucial role in the definition, as E[V|X_k] is computed using both
  the prior and the signal. Thus, precision criteria are defined as
  orders over the information structures. Cet information prior est
  pour nous le modèle économétrique, on va donc avoir des résultats
  différents selon le modèle sélectionné.
- A la fin de l'article il y a d'autres critères qui pourraient
  également rentrer dans notre comparaison pour le cas gaussien.

*** cite:WSor11 [[file:Biblio/Trie/WSor11.pdf][OS: Inflencing classifications]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{WSor11,
  title={The ratings game: Asymmetry in classification},
  author={Waguespack, David M and Sorenson, Olav},
  journal={Organization Science},
  volume={22},
  number={3},
  pages={541--553},
  year={2011},
  publisher={INFORMS}
}
#+end_src

- Certains inidivdus arrivent à influencer les classements
- C'est observé sur des film par comparaison entre pays.

*** cite:BSwa12 [[file:Biblio/Trie/BSwa12.pdf][PNAS: Information flows]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{BSwa12,
  title={Identifying sources of variation and the flow of information
                  in biochemical networks},
  author={Bowsher, Clive G and Swain, Peter S},
  journal={Proceedings of the National Academy of Sciences},
  volume={109},
  number={20},
  pages={E1320--E1328},
  year={2012},
  publisher={National Acad Sciences}
}
#+end_src

- With supplementary Information [[file:Biblio/Trie/BSwa12a.pdf][here]] for the formula and the
  links with the information theory.
- Multivariate variance decomposition.

*** cite:LSKa15 [[file:Biblio/Trie/LSKa15.pdf][JARE: Noisy information signal]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{LSKa15,
  title={Noisy information signals and endogenous preferences for
                  labeled attributes},
  author={Liaukonyte, Jura and Streletskaya, Nadia A and Kaiser, Harry
                  M},
  journal={Journal of Agricultural and Resource Economics},
  pages={179--202},
  year={2015},
  publisher={JSTOR}
}
#+end_src

- Modèle théorique gaussien qui peut être utilisé pour dériver des
  intuitions sur notre modèle.
- Les calculs sont en annexe et peuvent être pédagogique (Bayes rule)

*** cite:Gola17 [[file:Biblio/Trie/Gola17.pdf][Book: Info-metrics]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Gola17,
  title={Foundations of info-metrics: modeling and inference with
                  imperfect information},
  author={Golan, Amos},
  year={2017},
  publisher={Oxford University Press}
}
#+end_src

- La théorie de l'information appliquée à l'économie

*** cite:BZJL18 [[file:Biblio/Trie/BZJL18.pdf][AEJ: Countersignaling]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{BZJL18,
  title={Incomplete disclosure: Evidence of signaling and
                  countersignaling},
  author={Bederson, Benjamin B and Jin, Ginger Zhe and Leslie, Phillip
                  and Quinn, Alexander J and Zou, Ben},
  journal={American Economic Journal: Microeconomics},
  volume={10},
  number={1},
  pages={41--66},
  year={2018}
}
#+end_src

- On regarde si les restaurants communiquent sur une niveau d'hygiène
  qui a été établit volontairement dans un comté Californien.
- Les auteurs trouvent que les restaurants les mieux classés ne sont
  pas ceux qui communiquent le plus car ne pas communiquer montre que
  l'on est au-dessus des autres: c'est le countersignaling.

** Parametric ordered
*** cite:PHal83 [[file:Biblio/Trie/PHal83.pdf][ER: Residuals for diagnostics]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{PHal83,
  title={Diagnostic tests as residual analysis},
  author={Pagan, Adrian Rodney and Hall, Anthony David},
  journal={Econometric Reviews},
  volume={2},
  number={2},
  pages={159--218},
  year={1983},
  publisher={Taylor \& Francis}
}
#+end_src

- Seminal paper about using residuals for model dignostics

*** cite:Smal87 [[file:Biblio/Trie/Smal87.pdf][Econca: ordered alternatives]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Smal87,
  title={A discrete choice model for ordered alternatives},
  author={Small, Kenneth A},
  journal={Econometrica},
  pages={409--424},
  year={1987},
  publisher={JSTOR}
}
#+end_src

- GEV model proven to not work well

*** cite:GMRT87 [[file:Biblio/Trie/GMRT87.pdf][JoE: Generalised residuals]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{GMRT87,
  title={Generalised residuals},
  author={Gourieroux, Christian and Monfort, Alain and Renault, Eric
                  and Trognon, Alain},
  journal={Journal of Econometrics},
  volume={34},
  number={1},
  pages={5--32},
  year={1987},
  publisher={Elsevier}
}
#+end_src

- Proposent une définition des résidus généralisés et les manières de
  s'en servir pour faire plein de tests différents sur des modèles non
  linéaires.
- Les modèles concernés doivent avoir pour base une variable latente
  avec une structure de link exponentielle.
- Voir en particulier pour la construction des résidus et les
  écritures à l'ancienne.

*** cite:CIri87 [[file:Biblio/Trie/CIri87.pdf][JoE: Residuals grouped]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CIri87,
  title={Residual analysis in the grouped and censored normal linear
                  model},
  author={Chesher, Andrew and Irish, Margaret},
  journal={Journal of Econometrics},
  volume={34},
  number={1},
  pages={33--61},
  year={1987},
  publisher={Elsevier}
}
#+end_src

- Utile pour la formule des résidus généralisés dans le cadre du
  probit ordonné (qu'ils appellent le modèle grouped data).
- Certaines procédures de test sont présentées mais difficiles à
  comprendre, variable omise, hétéroscédasiticité.
- Une analyse graphique un peu naïve est présentée mais les
  discussions peuvent être intéressantes.

*** cite:Bran90 [[file:Biblio/Trie/Bran90.pdf][Bitrics: Assessing proportionality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Bran90,
  title={Assessing proportionality in the proportional odds model for
                  ordinal logistic regression},
  author={Brant, Rollin},
  journal={Biometrics},
  pages={1171--1178},
  year={1990},
  publisher={JSTOR}
}
#+end_src

- Tester la proportionnalité à partir de modèles binaires séparés
- Il y a quand même certains problèmes associés à ce test

*** cite:CPVe98 [[file:Biblio/Trie/CPVe98.pdf][ER: inference in MNL and ORD]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CPVe98,
  title={Simple inference in multinomial and ordered logit},
  author={Crawford, David L and Pollak, Robert A and Vella, Francis},
  journal={Econometric Reviews},
  volume={17},
  number={3},
  pages={289--299},
  year={1998},
  publisher={Taylor \& Francis}
}
#+end_src

- For the OP and OL with have the single crossing property which works
  on linear in variable model (not quadratic nor interactions)
- They also compare multinomial and ordered models claiming that the
  theory choose between both models.
- They show for the MNL that computing the individual marginal effects
  and averaging is not a good strategy.

*** cite:PShi00 [[file:Biblio/Trie/PShi00.pdf][JAE: Specification tests OP]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{PShi00,
  title={Gender, race, pay and promotion in the British nursing
                  profession: Estimation of a generalized ordered
                  probit model},
  author={Pudney, Stephen and Shields, Michael},
  journal={Journal of Applied Econometrics},
  volume={15},
  number={4},
  pages={367--399},
  year={2000},
  publisher={Wiley Online Library}
}
#+end_src

- specification tests and generalized models which relax two of the
  restrictive features of the ordered probit model: the constancy of
  threshold parameters and exogeneity of explanatory variables.
- In general, if the same variables impact the threshold and the
  latent variables, the two effects cannot be separated. According to
  the author we have to force by dropping one possibility. We use the
  threshold constancy test developed in Section 3.2 to allocate each
  explanatory variable either to the thresholds.
- Terza (1985) seems to be the seminal paper for non-constant
  thresholds.
- The test for non-constant thresholds is close to a parallel
  assumption. It is tested through an extended definition of
  coefficients from the latent variable. Then it is a score test.
- The specification procedure is strange (with non-constant
  thresholds), see p.374.
- Endogeneity is treated exclusively through simultaneity questions,
  tested through the generalized residuals (only possible for a
  discrete endogenous explanatory variable, Pagan and Vella 1989),
  Implemented by simulated likelihood.
- Ancien commentaires:
   - Un modèle ordonné généralisé de plus mais avec les intérêts de
     (i) proposer un test de constance des seuils, (ii) proposer un
     test d'exogénéité de certaines variables explicatives et (iii) de
     proposer l'estimation de variables ordonnées endogènes (elles
     mêmes dans une deuxième étape ordonnée).
   - Ils disent que c'est dur de spécifier des formes fonctionnelles
     flexibles sur les seuils car il y a autant de formes à estimer
     que de seuils et donc font des transformations a priori des
     variables qui expliquent les seuils et qui ont des effets non
     linéaires.
   - Leur modèle a équation simultannées est un peu laborieux:
     inclusion d'effets aléatoires on ne sait pas pourquoi,
     estimation par maximum de vraisemblance simulé.
   - Par contre les deux test présentés pour la constance des seuils
     et l'exogénéité d'une variable ordonnée (marche aussi si la
     deuxième étape est continue) sont d'un intérêt fort.

*** cite:CHNa07 [[file:Biblio/Trie/CHNa07.pdf][IER: Economic content of ordered]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CHNa07,
  title={The identification and economic content of ordered choice
                  models with stochastic thresholds},
  author={Cunha, Flavio and Heckman, James J and Navarro, Salvador},
  journal={International Economic Review},
  volume={48},
  number={4},
  pages={1273--1309},
  year={2007},
  publisher={Wiley Online Library}
}
#+end_src

- They present Prescott and Visscher (1977) which look like ideal
  point for politics.
- The model they present is an optimal stopping, can be used for trees
  in particular.

*** cite:VDJo03 [[file:Biblio/Trie/VDJo03.pdf][JHE: Scoring from ordered]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{VDJo03,
  title={Inequalities in self-reported health: validation of a new approach to measurement},
  author={Van Doorslaer, Eddy and Jones, Andrew M},
  journal={Journal of health economics},
  volume={22},
  number={1},
  pages={61--87},
  year={2003},
  publisher={Elsevier}
}
#+end_src

- Re-scaling the latent variable with (y_i- y_min)/ (y_max- y_min)
  [density uniform distribution]
- Interval regression (with known thresholds) can be artificially
  implemented with the cdf of an auxiliary continuous variable [not
  interesting for us]
- Allowing the thresholds to depend on explanatory variables is
  equivalent to an heteroskedastic specification [and vice versa? an
  heteroskedastic ordered probit present non-constant thresholds?]
- Health concentration index, very close to a Gini index, measure the
  inequality from the relation between the distribution of wealth and
  health.
- We can also decompose the health concentration index on the basis of
  explanatory variables. These two last point justify to scale the
  predictions from OP for inter-group comparisons: "impose cardinality
  on the ordinal responses"
- For the decomposition, the ordered probit work as the interval
  regression.

*** cite:Fiel04 [[file:Biblio/Trie/Fiel04.pdf][QQ: Scaling for residual variance]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Fiel04,
  title={Scaling for residual variance components of ordered category
                  responses in generalised linear mixed multilevel
                  models},
  author={Fielding, Antony},
  journal={Quality and Quantity},
  volume={38},
  number={4},
  pages={425--433},
  year={2004},
  publisher={Springer}
}
#+end_src

- Bien moins clair et intéressant que le papier de 2009 de Baue09.

*** cite:Baue09 [[file:Biblio/Trie/Baue09.pdf][PCM: scaling ordered]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Baue09,
  title={A note on comparing the estimates of models for
                  cluster-correlated or longitudinal data with binary
                  or ordinal outcomes},
  author={Bauer, Daniel J},
  journal={Psychometrika},
  volume={74},
  number={1},
  pages={97},
  year={2009},
  publisher={Springer}
}
#+end_src

- Instead of normalizing by the variance of the residuals, we put the
  variance of the latent to a given value by rescaling
- Extension of Winship and Mare (1984) for random effects
  (clusters). the proof are in the appendix.
- Complementarity with Fielding 2004, same goal.

*** cite:XXXXXX [[file:Biblio/Trie/JackXX.pdf][Cours: Ideal point and reparam]]

- Only the course of Jackman with the theory of ideal point. 
- With two votes known thresholds (Krehbiel and Rivers), We need to
  know the amount for each vote (wage for exemple) the threshold from
  the ordered model is the center between two options the transitivity
  allow to suppress a possibility among 4, so we can make an ordered
  model with 4 modalities. (the outcome of two choices are coded as an
  ordered value).
- Jackman shows how to recover interesting parameters about scale,
  thresholds even with a model estimated with standard thresholds
  normalization.

*** cite:GHen10 [[file:Biblio/Trie/GHen10.pdf][Book: Green ordered]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{GHen10,
  title={Modeling ordered choices: A primer},
  author={Greene, William H and Hensher, David A},
  year={2010},
  publisher={Cambridge University Press}
}
#+end_src

- Tout ce qui faut savoir sur les modèles de choix ordonnés.
- Ils améliorent le probit ordonné en permettant d'avoir des seuils
  qui dépendent de chocs aléatoire et de variables explicatives.
- Ils justifient ce besoin par la prise en compte de l'hétérogénéité
  des préférences des individus, à la fois observée et inobservée.
- "The Brant test frequently rejects the null hypothesis of a common
  slope vector in these discrete choice models. The test is not about
  the choice mechanism per se, but about functional form".
- Le probit ordonné généralisé a la préférence de la littérature par
  rapport au relachement de la parallèle assumption et permet d'avoir
  des effets marginaux différents selon les outcomes.
- On n'a plus la single crossing condition, ni la parallel assumption
  par contre l'interprétation des effets marginaux est plus
  hasardeuse.
- Ils sont très critiques des modèles qui relachent la parallel
  assumption. L'idée de structurer les constantes comme des sommes
  l'une de l'autres en exponentiel est intéressante.
- L'estimation se fait par MV simulée dans la logique de Train et du
  package de Croissant.

*** cite:Wool10 [[file:Biblio/Trie/Wool10.pdf][Book: Wooldridge]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Wool10,
  title={Econometric Analysis of Cross Section and Panel Data},
  author={Wooldridge, Jeffrey M.},
  year={2010},
  publisher={MIT press}
}
#+end_src

- Version 2010 de Wooldridge.

*** cite:PRos13 [[file:Biblio/Trie/PRos13.pdf][JRSS: Vignette suridentification]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{PRos13,
  title={The heterogeneous thresholds ordered response model:
                  Identification and inference},
  author={Peracchi, Franco and Rossetti, Claudio},
  journal={Journal of the Royal Statistical Society: Series A
                  (Statistics in Society)},
  volume={176},
  number={3},
  pages={703--722},
  year={2013},
  publisher={Wiley Online Library}
}
#+end_src

- Detailed analysis of the identification of the ordered models with
  vignette for intra-personal comparability
- Present the choice of allocating variable between thresholds and
  latent as exclusion restrictions.

*** cite:NSha15 [[file:Biblio/Trie/NSha15.pdf][AMAR: Equivalence between Generalized Ordered]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{NSha15,
  title={A note on generalized ordered outcome models},
  author={Eluru, Naveen and Yasmin, Shamsunnahar},
  journal={Analytic methods in accident research},
  volume={8},
  pages={1--6},
  year={2015},
  publisher={Elsevier}
}
#+end_src

- Simple mathematical derivation of the equivalence between
  non-constant thresholds and non-parallel effects
- Simple specification Wald tests : [[pdfview:/home/jsay/geoIndic/Biblio/Trie/NSha15.pdf::6][page 6
- Generalization with random parameters (mixed model) both for
  threshold and non-parallel variables.
- For the mixed models, imposing a recursive structure for the
  thresholds allow to impose the non-negativity of the probability for
  a particular level, I think this is the same as the monotone
  condition. To verify.

*** cite:Terz16 [[file:Biblio/Trie/Terz16.pdf][JES: Correction of Green on identification]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Terz16,
  title={Threshold Specification And Parameter Identification In The
                  Generalized Ordinal Probit Model},
  author={Terza, Joseph V},
  journal={Journal of Economic Surveys},
  volume={30},
  number={4},
  pages={696--697},
  year={2016},
  publisher={Wiley Online Library}
}
#+end_src

- Contrary to what GHHW14 said, it is possible to estimate ordered
  models with variable thresholds (with heterogeneous coefficients
  between modalities) and many common explanatory variables in the
  latent and thresholds.
- GHHW14 said that we can only identify the effect of common
  explanatory variables for a modality (modality 1 in particular).
- This paper shows that if one threshold is normalized (to 0 in
  particular), the coefficients of the common explanatory variables
  are identified, they are equal to the structural parameters minus
  the structural parameter for the threshold normalized.

** R implementations
*** CORE       :: cite:Core19 CORE team

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@Manual{Core19,
title = {R: A Language and Environment for Statistical Computing},
author = {{R Core Team}},
organization = {R Foundation for Statistical Computing},
address = {Vienna, Austria},
year = {2019},
url = {http://www.R-project.org/},
}
#+end_src

*** Effects    :: cite:FHon09 [[file:Biblio/Trie/FHon09.pdf][JSS: Effect plots]] 

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{FHon09,
  title={Effect displays in R for multinomial and proportional-odds
                  logit models: Extensions to the effects package},
  author={Fox, John and Hong, Jangman},
  journal={Journal of Statistical Software},
  volume={32},
  number={1},
  pages={1--24},
  year={2009}
}
#+end_src

- Papier JSS pour ploter les effets de modèles multinomiaux et de
  modèles ordonnés
- En plus de l'explication des commandes R, il y a le calcul des
  écarts-types pour les modèles multinomiaux.

*** MASS       :: cite:VRip02 [[file:Biblio/Trie/VRip02.pdf][Book: Ordered model with MASS]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@Book{VRip02,
    title = {Modern Applied Statistics with S},
    author = {W. N. Venables and B. D. Ripley},
    publisher = {Springer},
    edition = {Fourth},
    address = {New York},
    year = {2002},
    note = {ISBN 0-387-95457-0},
    url = {http://www.stats.ox.ac.uk/pub/MASS4},
}
#+end_src

- Pour le Package MASS

*** sp, spdep  :: cite:BPGR13 [[file:Biblio/Trie/BPGR13.pdf][Book: Spatial data with R]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{BPGR13,
  title={Applied spatial data: analysis with R},
  author={Bivand, Roger S and Pebesma, Edzer J and Rubio, Virgilio
                  G{\'o}mez},
  year={2008},
  publisher={Springer}
}
#+end_src

- Pour les fonctions spatiales

*** car        :: cite:FWei19 [[file:Biblio/Trie/FWei19.pdf][Book: Companion Applied Regression]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{FWei19,
  title={An R companion to applied regression},
  author={Fox, John and Weisberg, Sanford},
  year={2010},
  publisher={Sage}
}
#+end_src

- Pour les fonctions spatiales

*** VGAM       :: cite:Yee10  [[file:Biblio/Trie/Yee10.pdf][JSS: Vector generalized models]] [[file:Biblio/Trie/Yee15.pdf][Book]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Yee10,
    AUTHOR = {Yee, Thomas W.},
     TITLE = {The \textsf{VGAM} Package for Categorical Data Analysis},
   JOURNAL = {J. Statist. Soft.},
  FJOURNAL = {Journal of Statistical Software},
    VOLUME = {32},
      YEAR = {2010},
    NUMBER = {10},
     PAGES = {1--34},
    URL = {http://www.jstatsoft.org/v32/i10/},
}
@book{Yee15,
    AUTHOR = {Yee, T. W.},
     TITLE = {Vector Generalized Linear and Additive Models:
              With an Implementation in {R}},
      YEAR = {2015},
 Publisher = {Springer},
   Address = {New York, NY, USA},
}
#+end_src

- marginal effect can be computed
- conditional mnl can be estimated, also parallel multinomial!
- Reduced Rank is a kind of PLS
- At the end of the paper, it shows how to force spline to have the
  same knots to be used in the constraints.
- Seemingly Unrelated Regression: [[pdfview:/home/jsay/geoIndic/Biblio/Trie/Yee15.pdf::317][ici, with 3 means to estimate:
  Zellner plug-in (maxit= 1), Zellner interactive (maxit as default
  and SURff(divisor = "sqrt")) and multivariate normal errors.

*** Ordinal    :: cite:CBro13 [[file:Biblio/Trie/CBro13.pdf][JSFS: Paper for ordinal package]]

    with R paper on the functions [[file:Biblio/Trie/clm18.pdf][clm]] and [[file:Biblio/Trie/clmm18.pdf][clmm]] from the package
    [[file:Biblio/Trie/ordi18.pdf][ordinal]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CBro13,
  title={Analysis of sensory ratings data with cumulative link models},
  author={Christensen, Rune Haubo Bojesen and Brockhoff, Per Bruun},
  journal={Journal de la Soci{\'e}t{\'e} Fran{\c{c}}aise de Statistique},
  volume={154},
  number={3},
  pages={58--79},
  year={2013}
}
#+end_src

- The JSFS paper contains simple inference procedure for ordinal
  models
- It is interesting to present the nominal coefficients jointly with
  the thresholds. p.31, many explications about the identification of
  the ordered models but there is not a method to deal with.
- Originality according to the author: scale effect
  (heteroscedasticity), structured thresholds (symetric or
  equidistant), partially proportional (called nominal effects),
  flexible link function (gumbel, log-gamma)
- If nominal effects are based on dummy variables, be careful to the
  reference modality
- Link function that looks like a box-cox transformation: with a
  additional parameter that can be estimated (could be long)
- Look at convergence failure if unordered thresholds
- We can test the parallel assumption for all the variables
  independently.
- We can plot the profile likelihood which can be used as a test for
  "derivative of LL with respect to the parameter" used in another
  paper. GMCB18 (R journal for surrogate) say that Harrel 2001 (book,
  p.334) "suggest to compute each observation contribution to the
  first derivative of the log lilkelihood function with respect to
  beta and averaging them within each of the J categories".
- For random effects, we have only an example with clmm2, another
  function clmm is announced but not already available. clmm2(rating ~
  temp + contact, random=judge, data=wine) Tutz, G. and W. Hennevogl
  (1996). Random effects in ordinal regression models. Computational
  Statistics & Data Analysis 22, 537–557
- Be careful for predictions with mixed models

*** brglm      :: cite:Kosm14 [[file:Biblio/Trie/Kosm14.pdf][JRSS: Bias correction ML ordered]] [[file:Biblio/Trie/Kosm17.pdf][pres]]

    with
    - https://github.com/ikosmidis/brglm2
    - https://cran.r-project.org/web/packages/brglm2/vignettes/iteration.html

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Kosm14,
  title={Improved estimation in cumulative link models},
  author={Kosmidis, Ioannis},
  journal={Journal of the Royal Statistical Society: Series B
                  (Statistical Methodology)},
  volume={76},
  number={1},
  pages={169--196},
  year={2014},
  publisher={Wiley Online Library}
}
#+end_src

*** mgcv       :: cite:WPSa16 [[file:Biblio/Trie/WPSa16.pdf][JASA: General smooth models]]

    with [[file:Biblio/Trie/Knei16.pdf][Kneib]], [[file:Biblio/Trie/Yee16.pdf][Yee]], [[file:Biblio/Trie/GSch16.pdf][Greven and Scheipl]] comments and a [[file:Biblio/Trie/WPSa16a.pdf][Rejoinder]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{WPSa16,
  title={Smoothing parameter and model selection for general smooth models},
  author={Wood, Simon N and Pya, Natalya and S{\"a}fken, Benjamin},
  journal={Journal of the American Statistical Association},
  volume={111},
  number={516},
  pages={1548--1563},
  year={2016},
  publisher={Taylor \& Francis}
}
#+end_src

- We can specify heteroscedasticity with the package (called
  location-scale model)
- They propose a new Information Criterion for model selection
- Additional material at the end of the file
- Section 7 is an example with an ordered outcome, the first threshold
  is normalized to 1 in order to have an intercept in the model.
- Section 8 is a bivariate additive continuous model with correlated
  errors with random effects about car manufacturer
- Kneib et al. call these models structured additive distributional
  regression models in a bayesian framework.
- Yee says that the link= "identity" is confusing as it is a logit
  link, additional links could be provided. The non-parallel
  application could also be difficult.

*** mgcv       :: cite:Wood17 [[file:Biblio/Trie/Wood17.pdf][Book: Wood gam]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Wood17,
  title={Generalized additive models: An introduction with R},
  author={Wood, Simon N},
  year={2017},
  publisher={Chapman and Hall/CRC, second edition}
}
#+end_src

From [[file:Biblio/Trie/WoodSmooth.pdf][slides]] about smoothing choices
- with univariate smooth function, there are several alternatives for
  smooth functions without elements to choose between them. BUT for
  bivariate smooth functions, there is a major choice: ISOTROPIC
  smooth (for same scale: spatial locations) or SCALE INVARIANT (for
  variables measured in different units)
- For the splines, for a given number of basis, the lambda is the
  weight on the penalization. More alpha is high more the function is
  smooth. Two possibilities about basis choice: choose some knots
  (knot based) or choosing the number of basis (eigen based).
- With the inside argument bs= "", we have:
  - "cr" basis is knot based, "cc" is a cyclic version
  - "tp" is an eigen approximation to a thin plate spline
  - "ps" p-splines with flexibility with penalties and basis functions
  - "ad" adaptive smoother in with strength of penalty varies with
    covariate.
  - In general "cr", "tp" and "ps" produce similar results, "ad" is in
    general different.
- In 2 dimensions, thin plate is isotropic. Isotropic smooths assume
  that a unit change in one variable is equivalent to a unit change in
  another variable, in terms of function variability. Tensor product
  smooths have some flexibility in the different
  dimensions. te(x,z,v,bs="ps",k=5) creates a tensor product smooth of
  x, z and v using rank 5 P-spline marginals: the resulting smooth has
  3 penalties and basis dimension 125
  (5x5x5). te(x,z,t,bs=c("tp","cr"),d=c(2,1),k=(20,5)) creates a
  tensor product of an isotropic 2-D TPS with a 1-D smooth in
  time. The result is isotropic in x,z, has 2 penalties and a basis
  dimension of 100. This sort of smooth would be appropriate for a
  location-time interaction.
- You have to choose the number of basis functions to use for each
  smooth, using the k argument of s or te. The default is essentially
  arbitrary. HE PROPOSE AN ANALYSIS BASED ON THE RESIDUALS!

*** ordinalNet :: rien

    [[file:Biblio/Trie/WRHa17.pdf][Vignette]] 

*** sure       :: cite:LZha18 [[file:Biblio/Trie/LZha18.pdf][JASA: Surrogate residuals]] [[file:Biblio/Trie/LZha18a.pdf][Sup Mat]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{LZha18,
  title={Residuals and Diagnostics for Ordinal Regression Models: A
                  Surrogate Approach},
  author={Liu, Dungang and Zhang, Heping},
  journal={Journal of the American Statistical Association},
  pages={1--10},
  year={2018},
  publisher={Taylor \& Francis}
}
@article{GMCB18,
  title={Residuals and Diagnostics for Binary and Ordinal Regression
                  Models: An Introduction to the sure Package},
  author={Greenwell, Brandon M and McCarthy, Andrew J and Boehmke,
                  Bradley C and Liu, Dungang},
  journal={The R Journal},
  year={2018}
}
#+end_src

   Also a R journal article : [[file:Biblio/Trie/GMCB18.pdf][RJ: Surrogate residuals]]
   and a Github repo : https://github.com/koalaverse/sure

- work with polr, clm, vglm, vgam
- used to test specification (variables and link), heteroscedasticity,
  proportionality, missing covariates,
- Proposition of monotonicity (for a same x, if the AOC is greater for
  one observation, the residual is also greater for this
  observation). This is not the case for multinomials. We have to see
  the validity of this proposition along the OP / MNL gradient.
- Proofs in the supplementary material
- An originality could be to used them to test spatial
  auto-correlation.
- In the appendix, a discussion of goodness-of-fit, with
  Kolmogorov-Smirnov distance (to compare different distribution
  functions)

*** mvord      :: cite:HHVa18 [[file:Biblio/Trie/HHVa18.pdf][SMA: Multivariate ordinal regression]]

    Application of Multivariate ordinal =mvord= [[file:Biblio/Trie/HHVa17.pdf][vignette]] and [[file:Biblio/Trie/HHVa18a.pdf][slides]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{HHVa18,
  title={Multivariate ordinal regression models: an analysis of
                  corporate credit ratings},
  author={Hirk, Rainer and Hornik, Kurt and Vana, Laura},
  journal={Statistical Methods \& Applications},
  pages={1--33},
  year={2018},
  publisher={Springer}
}
#+end_src

- Can be used to model old and new GIs with correlation in the
  unobservable (including with binary outcome but not at the right of
  the main equation)
- Can be used to relax parallel assumption, heteroscedasticity and
  constant thresholds. Correlation between errors can also depends on
  covariates.
- Thresholds parameters are constrained to achieve monotonicity.
- Many constrains on the parameters which allow exclusion relations.

*** functions  :: cite:ATar18 [[file:Biblio/Trie/ATar18.pdf][SN: Interpret effects]] [[file:Biblio/Trie/ATar18a.pdf][Sup Mat]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{ATar18,
  title={Simple ways to interpret effects in modeling ordinal
                  categorical data},
  author={Agresti, Alan and Tarantola, Claudia},
  journal={Statistica Neerlandica},
  year={2018},
  publisher={Wiley Online Library}
}
@article{AKat17,
  title={Ordinal probability effect measures for group comparisons in
                  multinomial cumulative link models},
  author={Agresti, Alan and Kateri, Maria},
  journal={Biometrics},
  volume={73},
  number={1},
  pages={214--219},
  year={2017},
  publisher={Wiley Online Library}
}
#+end_src

- Marginal effects presented are not relevant for polynomial effects,
  so not relevant for us.
- The best measure of partial effect is AME: derive for each
  observation and aggregate (or plot, Long and Freese 2014, Sun 2015)
- For predictive evaluation, concordance effects (already present in
  our code) and a particular interpretation of MacFadden pseudoR2.
- The supmat include some R functions to interpret dummy variables and
  compute standard deviations.
- The second paper [[file:Biblio/Trie/AKat17.pdf][AKat17]] provides a measure of the proba of ordinal
  dominance that can be interesting for communes effects once the
  terroir is fully controlled.

*** PRes

    Allow to compute residuals but also quantify the conditional
    association between ordinal variables, can be used to compare old
    and new GIs: [[file:Biblio/Trie/LShe10.pdf][Paper]] and [[file:Biblio/Trie/DHLL18.pdf][Manual]]

*** plot effects

    [[file:Biblio/Trie/FWei18.pdf][Gallery]]

*** [[file:Biblio/Trie/AHNG18.pdf][Mixor]] and [[file:Biblio/Trie/AHZF18.pdf][ordinalgmifs]]

- Mixor is interesting for clusterized approaches, as a substitute for
  random effects
- ordinalgmifs is for shrinkage regressions on ordered outcomes
  
*** Extended Ordered Regression

     [[file:Biblio/Trie/MMWZ14.pdf][Paper]] and [[file:Biblio/Trie/MMWZ18.pdf][vignette]] 

*** multgee

    [[file:Biblio/Trie/Toul16.pdf][Vignette]], [[file:Biblio/Trie/Toul15.pdf][JSS paper]] and [[file:Biblio/Trie/Toul16a.pdf][R journal]] article about simulations

*** Oglmx

    [[file:Biblio/Trie/Caro18.pdf][Vignette]]

    Not interesting, only allow heteroscedasticity.

*** Interval with selection

    [[file:Biblio/Trie/HPHe17.pdf][Vignette]]

    Petersen, Henningsen, Henningsen, non encore publié mais il y a la
    vignette associée au package sampleSelection. Pour l'instant ne
    permet pas d'estimer les seuils, ils doivent être spécifiés
    explicitement. C'est pour cela que l'on va favoriser la
    non-parellel assumption, d'autant plus que l'absence d'AOC
    correspond bien à un niveau plus faible dans la hiérarchie.

*** Monotonicity

    https://github.com/dongwookim1984/Testing_SD

*** Ordered GWR

    see additional material of DNBr18

*** vcrpart

    recursive partitioning [[file:Biblio/Trie/BRit17.pdf][JSS paper]] and [[file:Biblio/Trie/BRit18.pdf][Manual]]

** Spatial econometrics
*** cite:PCad95 [[file:Biblio/Trie/PCad95.pdf][Science: Spatial heterogeneity]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{PCad95,
  title={Landscape ecology: spatial heterogeneity in ecological systems},
  author={Pickett, Steward TA and Cadenasso, Mary L},
  journal={Science},
  volume={269},
  number={5222},
  pages={331--333},
  year={1995},
  publisher={New York, NY:[sn] 1880-}
}
#+end_src

- Un papier qui explique la généralité des pattern spatiaux suite à
  l'hétérogénéité

*** cite:KPru01 [[file:Biblio/Trie/KPru01.pdf][JoE: Moran's I for qualitative responses]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{KPru01,
  title={On the asymptotic distribution of the Moran I test statistic
                  with applications},
  author={Kelejian, Harry H and Prucha, Ingmar R},
  journal={Journal of Econometrics},
  volume={104},
  number={2},
  pages={219--257},
  year={2001},
  publisher={Elsevier}
}
#+end_src

- Formulas and asymptotic theory for the Moran's I on residuals from
  discrete models, ordered in particular. [[pdfview:/home/jsay/geoIndic/Biblio/Trie/KPru01.pdf::19][ici]]

*** cite:KWan03 [[file:Biblio/Trie/KWan03.pdf][JRSS: Geoadditive models]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{KWan03,
  title={Geoadditive models},
  author={Kammann, EE and Wand, Matthew P},
  journal={Journal of the Royal Statistical Society: Series C (Applied
                  Statistics)},
  volume={52},
  number={1},
  pages={1--18},
  year={2003},
  publisher={Wiley Online Library}
}
#+end_src

- Approche statistique sur les modèles additifs qui admettent les
  coordonnées parmi les variables explicatives.

*** cite:MMil03 [[file:Biblio/Trie/MMil03.pdf][IRSR: Moran for misspecification]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MMil03,
  title={Spatial autocorrelation or model misspecification?},
  author={McMillen, Daniel P},
  journal={International Regional Science Review},
  volume={26},
  number={2},
  pages={208--217},
  year={2003},
  publisher={Sage Publications}
}
#+end_src

- about Moran's I usage for misspecification
- Un classique de McMillen, avec des simulations mais très peu
  d'analytique.

*** cite:Dell10 [[file:Biblio/Trie/Dell10.pdf][Econca: Spatial coordinates]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Dell10,
  title={The persistent effects of {P}eru's mining \emph{mita}},
  author={Dell, Melissa},
  journal={Econometrica},
  volume={78},
  number={6},
  pages={1863--1903},
  year={2010},
  publisher={Wiley Online Library}
}
#+end_src

- Un papier avec des fonctions de lissage et une discontinuité
  spatiale.
- Illustration des coordonnées pour l'hétérogénéité spatiale

*** cite:MMil10 [[file:Biblio/Trie/MMil10.pdf][JRS: Spatial nonparam]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MMil10,
  title={Issues in spatial data analysis},
  author={McMillen, Daniel P},
  journal={Journal of Regional Science},
  volume={50},
  number={1},
  pages={119--141},
  year={2010},
  publisher={Wiley Online Library}
}
#+end_src

- Papier sur les spécifications non paramétriques pour gagner en
  flexibilité par rapport aux approches spatial paramétriques.

*** cite:MMil12 [[file:Biblio/Trie/MMil12.pdf][JRS: Spatial econometrics]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MMil12,
  title={Perspectives on Spatial Econometrics: Linear Smoothing with
                  Structured Models},
  author={McMillen, Daniel P},
  journal={Journal of Regional Science},
  volume={52},
  number={2},
  pages={192--209},
  year={2012},
  publisher={Wiley Online Library}
}
#+end_src

- Smoothed non parametric functions are better than spatial AR models,
  more parametric

*** cite:LVEP15 [[file:Biblio/Trie/LVEP15.pdf][LE: Geoadditive as fixed effects]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{LVEP15,
  title={An Alternative to the Standard Spatial Econometric Approaches
                  in Hedonic House Price Models},
  author={Lausted Veie, Kathrine and Panduro, Toke Emil},
  journal={Land Economics},
  volume={91},
  number={2},
  pages={386--409},
  year={2015},
  publisher={University of Wisconsin Press}
}
#+end_src

- Enfin un papier qui décrit une fonction GAM des coordonnées
  spatiales comme une alternatives aux effets fixes spatiaux
- Il n'y a pas grand chose d'un point de vue structurel (pas de
  référence à la méthode proxy)
- mais ils comparent par rapport aux méthodes d'économétrie spatiale
  paramétrique et montrent que ça marche mieux

** Terroir importance
*** cite:JLom93 [[file:Biblio/Trie/JLom93.pdf][AJEV: Review wine quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{JLom93,
  title={Environmental and management practices affecting grape
                  composition and wine quality-a review},
  author={Jackson, DI and Lombard, PB},
  journal={American Journal of Enology and Viticulture},
  volume={44},
  number={4},
  pages={409--430},
  year={1993},
  publisher={Am Soc Enol Viticulture}
}
#+end_src

- Revue de littérature sur ce qui fait la qualité d'un vin

*** cite:AALa95 [[file:Biblio/Trie/AALa95.pdf][Chance: Prix, climat, qualité]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{AALa95,
  title={Bordeaux wine vintage quality and the weather},
  author={Ashenfelter, Orley and Ashmore, David and Lalonde, Robert},
  journal={Chance},
  volume={8},
  number={4},
  pages={7--14},
  year={1995},
  publisher={Taylor \& Francis}
}
#+end_src

- Sur la base des prix longue période de quelques Château Bordelais,
  ils montrent que les variables climatiques sont des bons indicateurs
  des prix des vins.
- Ils utilisent des prix actuels (y compris pour les vieux millésimes)
  ce qui permet d'estimer le taux de rendement interne associé à la
  détention de Bordeaux. Ce sont les écart à cette tendance qui sont
  alors utilisées.
- Ils montrent en outre que le marché des primeurs a du mal a révéler
  l'information sur la qualité mais que cela peut se comprendre étant
  donné la fonction "lissage des revenus" qu'à le marché des vins en
  primeur.

*** cite:VLFC04 [[file:Biblio/Trie/VLFC04.pdf][AJEV: Terroir measured]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{VLFC04,
  title={Influence of climate, soil, and cultivar on terroir},
  author={Van Leeuwen, Cornelis and Friant, Philippe and Chone, Xavier
                  and Tregoat, Olivier and Koundouras, Stephanos and
                  Dubourdieu, Denis},
  journal={American Journal of Enology and Viticulture},
  volume={55},
  number={3},
  pages={207--217},
  year={2004},
  publisher={Am Soc Enol Viticulture}
}
#+end_src

- Il montre que le terroir est plus du climat et des sols que des
  modes de culture
- Par contre c'est sur les attributs biophysiques du raisin plutôt que
  sur une histoire économique

*** cite:LVis06 [[file:Biblio/Trie/LVis06.pdf][JWE: Weather and price]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{LVis06,
  title={Spatial variations in weather conditions and wine prices in
                  Bordeaux},
  author={Lecocq, S{\'e}bastien and Visser, Michael},
  journal={Journal of Wine Economics},
  volume={1},
  number={02},
  pages={114--124},
  year={2006},
  publisher={Cambridge Univ Press}
}
#+end_src

- Sur les données climatiques et le prix des bordeaux, en utilisant
  les variations inter-annuelles.

*** cite:Ashe08 [[file:Biblio/Trie/Ashe08.pdf][EJ: Predicting quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Ashe08,
  title={Predicting the quality and prices of Bordeaux wine},
  author={Ashenfelter, Orley},
  journal={Economic Journal},
  volume={118},
  number={529},
  pages={F174--F184},
  year={2008},
  publisher={Wiley Online Library}
}
#+end_src

- I show that a simple statistical analysis predicts the quality of a
  vintage, and hence its price, from the weather during its growing
  season.
- good vintages produce good wines in all vineyards and the best wines
  are produced in the best vineyards in all vintages.
- In fact, a more advanced statistical analysis reveals that
  information on chateau and vintage alone explain over 90% of the
  variation in the prices.
- In fact, as Edmund Penning-Rowsell (1985) points out in his classic
  book The Wines of Bordeaux, the famous 1855 classification of the
  chateaux of Bordeaux into quality grades was based on a similar
  assessment by price alone.
- there are two natural dimensions on which to search for hedonic
  determinants of wine quality: the vintage and the vineyard. In
  climatological terms it is natural to associate the first with
  weather variability from year to year and the second with climate
  variability across vineyards.
- Econometric analyses using data from vineyards in France (Combris et
  al., 1997; Jones and Storchmann, 2001), California (Haeger and
  Storchmann, 2006) and Germany (Ashenfelter and Storchmann, 2006) all
  show that heat retention and drainage (to remove excess water when
  it exists) are key determinants of vineyards prices and wine
  quality.
- He use summer temperature and harvest rain. Finally, the historical
  reputation of the chateau that produced the wine explains much of
  the remaining variability in prices. Not very much here: about 10%.

*** cite:GGin08 [[file:Biblio/Trie/GGin08.pdf][EJ: Natural endowments]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{GGin08,
  title={Natural Endowments, Production Technologies and the Quality
                  of Wines in Bordeaux. Does Terroir Matter?},
  author={Gergaud, Olivier and Ginsburgh, Victor},
  journal={Economic Journal},
  volume={118},
  number={529},
  pages={F142--F157},
  year={2008},
  publisher={Wiley Online Library}
}
#+end_src

- Variables instrumentales pour tester l'effet des natural endowments,
  car la technologie est endogène
- Ils ne trouvent pas d'effets significatifs sur les natural
  endowments
     
*** cite:WWJo09 [[file:Biblio/Trie/WWJo09.pdf][NGeo: Land and wine]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{WWJo09,
  title={Land and wine},
  author={White, Michael A and Whalen, Philip and Jones, Gregory V},
  journal={Nature Geoscience},
  volume={2},
  number={2},
  pages={82},
  year={2009},
  publisher={Nature Publishing Group}
}
#+end_src

- Ils ne croient pas en la terre comme source de la qualité des vins
- Ils plaident pour une vision dynamique du terroir en lien avec les
  changements technologiques et les changements climatiques.
- Deux de leurs arguments ne sont pas vérifiés par les
  faits. L'importance forte du climat: quand on regarde les variations
  de prix entre les crus, la dimension spatiale est plus forte. Le
  changement climatique et technologique va déplacer les AOC, un
  classement qui date de 1915 que les bouquins récents et les prix ne
  remettent pas en cause.
- typique pour illustrer les papier anti-terroir, avec bien sûr une
  référence au jugement de Paris.

*** cite:ASto10 [[file:Biblio/Trie/ASto10.pdf][REE: Solar radiation]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{ASto10,
  title={Using hedonic models of solar radiation and weather to assess
                  the economic effect of climate change: the case of
                  Mosel valley vineyards},
  author={Ashenfelter, Orley and Storchmann, Karl},
  journal={The Review of Economics and Statistics},
  volume={92},
  number={2},
  pages={333--349},
  year={2010},
  publisher={MIT Press}
}
#+end_src

- Model sur le prix du vignoble, qui utilise des données biophysiques
  pour estimer l'effet du réchauffement climatique sur les vignes.
- Il ya un modèle de probit ordonné pour les désignations AOC mais
  ils ne testent pas l'endogénéité des désignations.
- Des trucs intéressant sur l'échelle des variables explicatives
  (climat versus attribut de la terre) sur la variable proxy qu'ils
  calculent: solar radiation.
     
*** cite:CPSt11 [[file:Biblio/Trie/CPSt11.pdf][AER: Value of terroir]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CPSt11,
  title={What is the Value of Terroir?},
  author={Cross, Robin and Plantinga, Andrew J and Stavins, Robert N},
  journal={American Economic Review},
  volume={101},
  number={3},
  pages={152},
  year={2011}
}
#+end_src

- Sur l'utilisation de modèles hédoniques appliqués à la terre pour
  estimer la valeur du terroir.

*** cite:BTRM14 [[file:Biblio/Trie/BTRM14.pdf][PNAS: Microbial geography]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{BTRM14,
  title={Microbial biogeography of wine grapes is conditioned by
                  cultivar, vintage, and climate},
  author={Bokulich, Nicholas A and Thorngate, John H and Richardson,
                  Paul M and Mills, David A},
  journal={Proceedings of the National Academy of Sciences},
  volume={111},
  number={1},
  pages={E139--E148},
  year={2014},
  publisher={National Acad Sciences}
}
#+end_src

- Sur le role des microbes dans la composition des vignes
- Peut être utilisé pour justifier le spatial dans l'hétérogénéité non
  observée

*** cite:GLZa14 [[file:Biblio/Trie/GLZa14.pdf][PNAS: Microbial terroir]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{GLZa14,
  title={Microbial terroir for wine grapes},
  author={Gilbert, Jack A and van der Lelie, Daniel and Zarraonaindia,
                  Iratxe},
  journal={Proceedings of the National Academy of Sciences},
  volume={111},
  number={1},
  pages={5--6},
  year={2014},
  publisher={National Acad Sciences}
}
#+end_src

- Un commentaire du papier sur le role des microbes dans la
  définion du terroir,
- Peut être cité pour donner du poids à la première

*** cite:RBGS14 [[file:Biblio/Trie/RBGS14.pdf][FC: Terroir effect in wine]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{RBGS14,
  title={A grape and wine chemodiversity comparison of different
                  appellations in {B}urgundy: Vintage vs terroir
                  effects},
  author={Roullier-Gall, Chlo{\'e} and Boutegrabet, Lemia and Gougeon,
                  R{\'e}gis D and Schmitt-Kopplin, Philippe},
  journal={Food chemistry},
  volume={152},
  pages={100--107},
  year={2014},
  publisher={Elsevier}
}
#+end_src

- Therefore, and for a given vintage and a given appellation, terroir
  was treated as the composite of all possible environmental factors,
  which could influence the overall characteristics of
  vineyard-related grapes and subsequent wines
- it can be seen that wines could be rather well separated according
  to vintages but not according to the terroir (without ageing)
- the terroir as a whole – i.e. that considers the
  vine-soil-climate-human ecosystem – definitely impacts the initial
  chemical complexity of a wine, but time – i.e. bottle ageing – might
  be required to fully reveal it through the in-bottle diagenesis of
  complex chemical signatures. (par contre ces effets de terroir sont
  obtenus par l'identification des effets cote de beaune vs cote de
  nuits)

*** cite:KKFG15 [[file:Biblio/Trie/KKFG15.pdf][ScReport: Microbial terroir]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{KKFG15,
  title={Regional microbial signatures positively correlate with
                  differential wine phenotypes: Evidence for a
                  microbial aspect to terroir},
  author={Knight, Sarah and Klaere, Steffen and Fedrizzi, Bruno and
                  Goddard, Matthew R},
  journal={Scientific reports},
  volume={5},
  year={2015},
  publisher={Nature Publishing Group}
}
#+end_src

- Un autre papier qui montre l'exemple du rôle des microbes comme
  effet du terroir

*** cite:Gang16 [[file:Biblio/Trie/Gang16.pdf][Book: Intellectual property]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@book{Gang16,
  title={Research handbook on intellectual property and geographical
                  indications},
  author={Gangjee, Dev S},
  year={2016},
  publisher={Edward Elgar Publishing}
}
#+end_src

- Le lien pointe sur le chapitre de Bérard
- For better or worse, that principle is steadily gaining global
  acceptance

*** cite:Ashe17 [[file:Biblio/Trie/Ashe17.pdf][JWE: Vineyard site selection]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Ashe17,
  title={The hedonic approach to vineyard site selection: Adaptation
                  to climate change and grape growing in emerging
                  markets},
  author={Ashenfelter, Orley},
  journal={Journal of Wine Economics},
  volume={12},
  number={1},
  pages={3--15},
  year={2017},
  publisher={Cambridge University Press}
}
#+end_src

- optimizing grape type for each location, estimate the quality of
  wines that can be produced in a particular area, and judge whether
  wine grape production is economically viable.
- He does not deal with scale effects.
- The plantation of older vineyard areas may, therefore, require
  adaptation to crops of higher quality in order to maintain their
  economic viability.
- A precursor to much of this work is Gladstone’s (1992) remarkable
  analysis of Australian vineyard sites. Gladstone details the
  characteristics that ameliorate weather in many Australian
  plantation areas and recommends appropriate grape varietals for
  each. His recommendations have been very successful, especially in
  Western Australia. See also Haeger and Storchmann (2006).
- One purpose of this review is to show how subjective measures of
  wine quality may be used to calibrate the role of weather in the
  determination of wine quality.
- Less weather in Burgundy wine price, less anter-annual variations,
  more terroir.

*** cite:VLRR18 [[file:Biblio/Trie/VLRR18.pdf][OENO: Terroir survey]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{VLRR18,
  title={Soil-related \emph{terroir} factors: A review},
  author={van Leeuwen, Cornelis and Roby, Jean-Philippe and de
                  Ress{\'e}guier, Laure},
  journal={OENO One},
  volume={52},
  number={2},
  pages={173--188},
  year={2018}
}
#+end_src

- Un survey sur le lien du terroir à la terre

** Wine quality
*** cite:CLVi97 [[file:Biblio/Trie/CLVi97.pdf][EJ: Hedonic wine]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CLVi97,
  title={Estimation of a hedonic price equation for {B}ordeaux wine:
                  Does quality matter?},
  author={Combris, Pierre and Lecocq, S{\'e}bastien and Visser, Michael},
  journal={Economic Journal},
  volume={107},
  number={441},
  pages={390--402},
  year={1997},
  publisher={Wiley Online Library}
}
#+end_src

- Estimation sur données expérimentales
- Une des premiers papier sur l'hédonisme appliqué au prix du
  vin. Remarquable en particulier par la structure en prime de la
  valeur des différentes réputations (échelles à vérifier).

*** cite:Oczk01 [[file:Biblio/Trie/Oczk01.pdf][ER: Hedonic measurement errors]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Oczk01,
  title={Hedonic wine price functions and measurement error},
  author={Oczkowski, Edward},
  journal={Economic record},
  volume={77},
  number={239},
  pages={374--382},
  year={2001},
  publisher={Wiley Online Library}
}
#+end_src

- Les erreurs de mesures sont en lien avec la qualité des vins et la
  réputation. C'est une modélisation en terme de variables latentes.
- Par rapport à un modèle biophysique, ces variables de qualité sont
  déjà endogènes.
- Intéressant contre la multicolinéarité au même titre que les PLS,
  mais corriger des erreurs de mesure en supprimant des variables est
  étonnant.

*** cite:HLoc02 [[file:Biblio/Trie/HLoc02.pdf][JWR: Prediction of wine quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{HLoc02,
  title={What price quality? An investigation into the prediction of
                  wine-quality ratings},
  author={Horowitz, Ira and Lockshin, Larry},
  journal={Journal of Wine Research},
  volume={13},
  number={1},
  pages={7--22},
  year={2002},
  publisher={Taylor \& Francis}
}
#+end_src

- Question de la redondance de l'information lorsque l'on achète du
  vin. the quality ratings of wines take on the role of the dependent
  variable in a series of regression equations that employ as the
  independent explanatory variables many of the same factors that
  other researchers have included in their explorations.
- Rating between 3 and 5 with .5 increment
- Modèle de régression linéaire avec plein de variables endogènes et
  des R2 de l'ordre de 30%.

*** cite:HSto06 [[file:Biblio/Trie/HSto06.pdf][AE: Determinant of Pinot noir price]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{HSto06,
  title={Prices of American Pinot Noir wines: climate, craftsmanship,
                  critics},
  author={Haeger, John W and Storchmann, Karl},
  journal={Agricultural Economics},
  volume={35},
  number={1},
  pages={67--78},
  year={2006},
  publisher={Wiley Online Library}
}
#+end_src

- Les prix des pinots N américains en lien avec le climat, les marques
  et les critiques.
- L'article identifie le climat bourguignon comme le plus adapté au
  pinot noir (mais peut être est-ce l'inverse?)

*** cite:LJHP06 [[file:Biblio/Trie/LJHP06.pdf][FQP: Wine choices]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{LJHP06,
  title={Using simulations from discrete choice experiments to measure
                  consumer sensitivity to brand, region, price, and
                  awards in wine choice},
  author={Lockshin, Larry and Jarvis, Wade and d’Hauteville,
                  Fran{\c{c}}ois and Perrouty, Jean-Philippe},
  journal={Food quality and preference},
  volume={17},
  number={3-4},
  pages={166--178},
  year={2006},
  publisher={Elsevier}
}
#+end_src

- Un modèle de simulation sur les attributs des vins.

*** cite:Prii06 [[file:Biblio/Trie/Prii06.pdf][IJWM: GI masks quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Prii06,
  title={Wine's placebo effect: How the extrinsic cues of visual
                  assessments mask the intrinsic quality of South
                  African red wine},
  author={Priilaid, David A},
  journal={International Journal of Wine Marketing},
  volume={18},
  number={1},
  pages={17--32},
  year={2006},
  publisher={Emerald Group Publishing Limited}
}
#+end_src

- 2 types d'appréciations sont considérées, aveugle ou non aveugle.
- Dans la seconde, le prix de la bouteille est important, tout comme
  la région d'origine.
- Par contre à l'aveugle la région d'origine ne joue pas donc c'est du
  fake.

*** cite:CMCM07 [[file:Biblio/Trie/CMCM07.pdf][JAE: Segmented wine market]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CMCM07,
  title={Segmenting the wine market based on price: hedonic regression
                  when different prices mean different products},
  author={Costanigro, Marco and McCluskey, Jill J and Mittelhammer,
                  Ron C},
  journal={Journal of Agricultural Economics},
  volume={58},
  number={3},
  pages={454--466},
  year={2007},
  publisher={Wiley Online Library}
}
#+end_src

- Ils disent que la consommation de vin est souvent associée à des
  occasions sociales. C'est un argument intéressant pour justifier ou
  discuter de la présence des AOC dans la fonction d'utilité.
- Le risque dans l'achat d'une bouteille de vin est croissant avec le
  prix de la bouteille est décroissant avec l'information
  disponible. Puisque les gens qui achètent des vins chers sont mieux
  informés, la courbe est en U inversé avec un maximum de risque pour
  les vins de milieu de gamme.
- Ils utilisent une /negative square root transformation/ pour la
  variable dépendante.
- En fixant le nombre de segments de marché de manière exogène. Puis
  en testant un ensemble de prix seuils au travers des effets sur les
  RMSE, ils arrivent à déterminer les prix seuils qui distinguent les
  segments: $13, $21, $40. Les prix hédoniques apparaissent
  significativement différents entre les segments de prix.
- Cette méthode de segmentation est clairement moins bien que
  l'utilisation de fonctions quantiles.

*** cite:ANau07 [[file:Biblio/Trie/ANau07.pdf][AJAE: Pricing en primeur]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{ANau07,
  title={The pricing of experience goods: The example of \emph{en
                  primeur} wine},
  author={Ali, H{\'e}la Hadj and Nauges, C{\'e}line},
  journal={American Journal of Agricultural Economics},
  volume={89},
  number={1},
  pages={91--103},
  year={2007},
  publisher={Oxford University Press}
}
#+end_src

- Sur l'effet de la réputation de long terme, des variations annuelles
  dans les prix observés lors des ventes en primeur

*** cite:CPet07 [[file:Biblio/Trie/CPett07.pdf][FQP: Wine quality]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CPet07,
  title={The dimensions of wine quality},
  author={Charters, Steve and Pettigrew, Simone},
  journal={Food Quality and Preference},
  volume={18},
  number={7},
  pages={997--1007},
  year={2007},
  publisher={Elsevier}
}
#+end_src

- Essai de définition de la qualité d'un vin, avec des références
  intrinsèques et extrinsèques.

*** cite:MLSB10 [[file:Biblio/Trie/MLSB10.pdf][FQP: Back label information]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{MLSB10,
  title={Message on a bottle: The relative influence of wine back
                  label information on wine choice},
  author={Mueller, Simone and Lockshin, Larry and Saltman, Yaelle and
                  Blanford, Jason},
  journal={Food Quality and Preference},
  volume={21},
  number={1},
  pages={22--32},
  year={2010},
  publisher={Elsevier}
}
#+end_src

- Marketing sur l'effet des contre-étiquettes, pas d'intérêt en soi

*** cite:SSto10 [[file:Biblio/Trie/SSto10.pdf][JAFIO: Wine price and information]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{SSto10,
  title={Prices as quality signals: Evidence from the wine market},
  author={Schnabel, Hubert and Storchmann, Karl},
  journal={Journal of Agricultural \& Food Industrial Organization},
  volume={8},
  number={1},
  year={2010},
  publisher={De Gruyter}
}
#+end_src

- Effet sur le prix du vin de l'information sur la qualité
- Le rapport du prix en vente directe sur le prix "Vinexpo", le
  dernier servant de référence pour des acheteurs informés.
- Régression du rapport sur la vrai qualité (guide) et sur le degré
  d'information disponible au consommateur, identifié par le prix de
  ventes. Très inspiré de la théorie de cite:BRio91.
- Une partie de la biblio empirique traite du lien entre le niveau
  d'information et la corrélation entre prix et qualité.
- L'effet de ristourne pour les professionels est pris en compte pas
  une constante, ce sont les variations en lien avec la qualité qui
  sont étudiées.
- Le niveau d'information (prix) est instrumenté par des variables
  hédoniques classiques de qualité du vin.
- Au final c'est une méthode économétrique assez indirecte pour tester
  les résultats théoriques de cite:BRio91.
- Avec des données sur les volumes vendus, on pourrait faire un
  meilleur indicateur de l'information disponible aux clients.

*** cite:Stor12 [[file:Biblio/Trie/Stor12.pdf][JWE: Wine economics]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Stor12,
  title={Wine economics},
  author={Storchmann, Karl},
  journal={Journal of Wine Economics},
  volume={7},
  number={1},
  pages={1--33},
  year={2012},
  publisher={Cambridge University Press}
}
#+end_src

- General information about wine economics

*** cite:SNCS13 [[file:Biblio/Trie/SNCS13.pdf][FQP: Facteurs extrinsèques]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{SNCS13,
  title={Perception of wine quality according to extrinsic cues: The
                  case of {B}urgundy wine consumers},
  author={S{\'a}enz-Navajas, Mar{\'\i}a-Pilar and Campo, Eva and
                  Sutan, Angela and Ballester, Jordi and Valentin,
                  Dominique},
  journal={Food Quality and Preference},
  volume={27},
  number={1},
  pages={44--53},
  year={2013},
  publisher={Elsevier}
}
#+end_src

- Eco expé sur les attributs extrinsèques des vins de Bourgogne (i.e.,
  sans dégustation).
- BDM dans un faux magasin. L'origine géographique est le facteur
  principal de qualité (Table 5).

*** cite:GMMo13 [[file:Biblio/Trie/GMMo13.pdf][JWE: Wine price]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{GMMo13,
  title={Red wines of Medoc: what is wine tasting worth?},
  author={Ginsburgh, Victor and Monzak, Muriel and Monzak, Andras},
  journal={Journal of Wine Economics},
  volume={8},
  number={02},
  pages={159--188},
  year={2013},
  publisher={Cambridge Univ Press}
}
#+end_src

- Un papier de plus sur les origines des prix du vin
- We show that technology and weather conditions are able to explain
  two thirds of the riance of prices; when reputation effects (based
  on the wine classification made in 1855) are included, this
  proportion rises to almost 85%.

*** cite:DMDi14 [[file:Biblio/Trie/DMDi14.pdf][ERAE: Endogenous quality choice]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{DMDi14,
  title={Are geographical indications a worthy quality label? A
                  framework with endogenous quality choice},
  author={Desquilbet, Marion and Monier-Dilhan, Sylvette},
  journal={European Review of Agricultural Economics},
  volume={42},
  number={1},
  pages={129--150},
  year={2014},
  publisher={Oxford University Press}
}
#+end_src

- Deux niveaux d'information, qualité et GI, mais le premier est à la
  base une qualité endogène.

** Wine ranking
*** cite:AQua99 [[file:Biblio/Trie/AQua99.pdf][Chance: Jugement de Paris]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{AQua99,
  title={Analyzing a wine tasting statistically},
  author={Ashenfelter, Orley and Quandt, Richard},
  journal={Chance},
  volume={12},
  number={3},
  pages={16--20},
  year={1999},
  publisher={Taylor \& Francis}
}
#+end_src

- how to best to aggregate reported preferences.

*** cite:ALVi08 [[file:Biblio/Trie/ALVi08.pdf][EJ: Parker Gourou]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{ALVi08,
  title={The Impact of Gurus: Parker Grades and En Primeur Wine
                  Prices},
  author={Ali, H{\'e}la Hadj and Lecocq, S{\'e}bastien and Visser,
                  Michael},
  journal={Economic Journal},
  volume={118},
  number={529},
  pages={F158--F173},
  year={2008},
  publisher={Wiley Online Library}
}
#+end_src

- Papier sur l'utilisation de la crise 2002 pour identifier la
  valeur des appréciations Parker dans le prix des vins en primeur.
- Trouve un effet positif.

*** cite:CSto10 [[file:Biblio/Trie/CSto10.pdf][JWE: Judge Performance]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CSto10,
  title={Evaluation of wine judge performance through three
                  characteristics: Bias, discrimination, and
                  variation},
  author={Cao, Jing and Stokes, Lynne},
  journal={Journal of Wine Economics},
  volume={5},
  number={1},
  pages={132--142},
  year={2010},
  publisher={Cambridge University Press}
}
#+end_src

- Evaluation/ décomposition des notes allouées par les juges. Mentione
  les eggshell plot pour voir les juges qui sont discordants, utile
  pour classer différents classements.

*** cite:DNau10 [[file:Biblio/Trie/DNau10.pdf][IJIO: Quality and expert]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{DNau10,
  title={Identifying the effect of unobserved quality and expert
                  reviews in the pricing of experience goods:
                  Empirical application on {B}ordeaux wine},
  author={Dubois, Pierre and Nauges, C{\'e}line},
  journal={International Journal of Industrial Organization},
  volume={28},
  number={3},
  pages={205--212},
  year={2010},
  publisher={Elsevier}
}
#+end_src

- Basé sur la théorie standard d'économie industrielle, une approche à
  la Olley and Pakes sur la qualité inobservable d'un vin et l'absence
  de bonnes variables instrumentales.

*** cite:TMut11 [[file:Biblio/Trie/TMut11.pdf][JWE: Reconsidering classification]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{TMut11,
  title={Reconsidering the 1855 Bordeaux classification of the Medoc
                  and Graves using wine ratings from 1970--2005},
  author={Thompson, Gary M and Mutkoski, Stephen A},
  journal={Journal of Wine Economics},
  volume={6},
  number={1},
  pages={15--36},
  year={2011},
  publisher={Cambridge University Press}
}
#+end_src

- Counterfactual bordeaux classification

*** cite:FGro12 [[file:Biblio/Trie/FGro12.pdf][AEJ: Expert review]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{FGro12,
  title={Do expert reviews affect the demand for wine?},
  author={Friberg, Richard and Gr{\"o}nqvist, Erik},
  journal={American Economic Journal: Applied Economics},
  volume={4},
  number={1},
  pages={193--211},
  year={2012}
}
#+end_src

- One exemple on the effect of information on demand

*** cite:AJon13 [[file:Biblio/Trie/AJon13.pdf][JWE: Demand for expert opinion]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{AJon13,
  title={The demand for expert opinion: Bordeaux wine},
  author={Ashenfelter, Orley and Jones, Gregory V},
  journal={Journal of Wine Economics},
  volume={8},
  number={3},
  pages={285--293},
  year={2013},
  publisher={Cambridge University Press}
}
#+end_src

- This establishes that the expert opinions are not efficient, in the
  sense that they can be easily improved by weather data.
- Ils corrèlent la qualité du millésime annoncée au moment du primeur
  avec la valeur du millésime dans les enchères plus tard.
- We construct the index of a vintage’s average price from a
  regression of the logarithm of the price from several thousand
  auction sales on dummy variables indicating the château and the
  vintages. The regression coefficients for the vintage dummies are
  then used to construct the vintage index. This provides a simple way
  to construct a vintage index in the presence of an unbalanced sample
  design.
- ordered probit of the effects of weather on the ratings. Pour
  vraiment arriver au résultat sur le bais des experts, je dirais
  qu'il faut faire de l'out of sample (ou du
  jacknife). Rétrospectivement, c'est facile.

*** cite:Bodi17 [[file:Biblio/Trie/Bodi17.pdf][JWE: Judge consistency]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{Bodi17,
  title={Disentangling wine judges’ consensus, idiosyncratic, and
                  random expressions of quality or preference},
  author={Bodington, Jeffrey},
  journal={Journal of Wine Economics},
  volume={12},
  number={3},
  pages={267--281},
  year={2017},
  publisher={Cambridge University Press}
}
#+end_src

- p2 a good survey about wine ranking.
- This article show the importance of replicants in wine ratings.
- Par la modélisation conditionelle des note données aux vins, il
  permet d'obtenir un classement cohérent ou le vin répliqué est
  classé de manière cohérente (c'est à dire qu'ils se suivent dans la
  hiérarchie). the reason for the change in order is that
  low-randomness judges (such as Judge #7) have more influence on
  differences between expected values than high-randomness judges
  (such as Judge #4). That effect also applies to the orders implied
  by sums of ranks, Shapley values, Borda counts, and prefer-
  ence-model results.
- Disentangling Consensus, Idiosyncratic, and Random Ratings. Il y a
  la question de la pertinance des modèle multinomiaux pour étudier
  les ratings. Il plaide pour du rank-preference
  model. rank-preference models can be tailored to discrete, ordered,
  and bounded ratings that are assigned with or without replacement.
  The works of Marden (1995) and Alvo and Yu (2014) are widely cited
  texts concerning these models.

*** cite:CSto17 [[file:Biblio/Trie/CSto17.pdf][JWE: Ranking methods]]

#+begin_src bibtex :tangle ./Biblio.bib :exports none
@article{CSto17,
  title={Comparison of different ranking methods in wine tasting},
  author={Cao, Jing and Stokes, Lynne},
  journal={Journal of Wine Economics},
  volume={12},
  number={2},
  pages={203--210},
  year={2017},
  publisher={Cambridge University Press}
}
#+end_src

- Rien de sensationnel, utilisation de la valeur Shapley de manière
  assez ad hoc, sans vraiment montrer son intérêt
- La partie intéressante de l'article est celle relative au modèle
  ordonné avec coefficients hétérogènes mais seuil homogènes avec une
  qualité latente qui rentre multiplicativement. Cela me fait penser
  au modèle théorique que j'avais fait pour le prix des vignes et
  présenté à Besançon. Mais pour le détail de ce modèle, il faut mieux
  renvoyer à leur papier de 2010.

** Bibliography                              :noheading:
   
   bibliographystyle:../Softwares/latex/erae
   bibliography:Biblio.bib

#+LATEX: \clearpage\appendix

* Data papier
  :PROPERTIES:
  :EXPORT_FILE_NAME:    DataPaper
  :EXPORT_LATEX_CLASS:  ManueStat
  :EXPORT_TITLE:        @@latex: \vspace{-1cm} \huge\textbf{Déterminants biophysiques des AOC viticoles :\\ Construction des données et modélisation \\[.25cm]}@@
  :EXPORT_AUTHOR:       @@latex: \begin{tabular}{ccc} \textsc{Jean-Sauveur Ay} && \textsc{Mohamed Hilal} \\ < \url{jean-sauveur.ay@inra.fr} > && < \url{mohamed.hilal@inra.fr} > \\[.5cm] \multicolumn{3}{c}{Unité Mixte de Recherche CESAER} \\ \multicolumn{3}{c}{AgroSup / INRA / Univ. Bourgogne Franche-Comté} \\ \multicolumn{3}{c}{26 boulevard du docteur Petitjean 21000 DIJON}\\[.25cm] \end{tabular} @@
  :EXPORT_DATE:         /Data paper/ version 0.2 du Vendredi 12 avril 2019
  :EXPORT_OPTIONS:      TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc toc:nil
  :EXPORT_LATEX_HEADER: \usepackage[T1]{fontenc} \usepackage{tabularx, rotating, booktabs, lscape, tikz, dcolumn, amssymb, amsmath, amsthm, bbm, eurosym, threeparttable, pdflscape, txfonts, rotfloat} \usepackage{tocloft} \renewcommand{\abstractname}{Résumé} \usepackage[toc]{multitoc}\renewcommand*{\multicolumntoc}{2}\setlength{\columnseprule}{.5pt}\setlength{\columnsep}{1cm} \renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}} \renewcommand*\contentsname{Table des Matières}
  :END:
** Résumé                                    :noheading:
#+begin_export html
---
title:  Déterminants biophysiques des AOC viticoles, Construction des données et modélisation
author: Jean-Sauveur Ay et Mohamed Hilal
date:   UMR CESAER, AgroSup, INRA, Université Bourgogne Franche-Comté
---

# Résumé
#+end_export
#+BEGIN_abstract
Nous présentons le détails de la construction de données à l'échelle
parcellaire pour étudier statistiquement les relations existantes
entre les caractéristiques biophysiques (topographie, géologie,
pédologie) des parcelles viticoles et les appellations d'origine
contrôlée (AOC).  La zone d'étude comprend actuellement 31 communes de
la Côte d'Or entre Dijon et Santenay, incluses dans la Côte de Beaune
et la Côte de Nuits.  L'intérêt de ces données est illustré par une
modélisation de l'effet des caractéristiques biophysiques des
parcelles sur leur probabilité d'être dans les différents niveaux
d'AOC.  Ce modèle permet en outre d'affiner le classement actuel des
parcelles dans un sens qui sera précisé, tout en restant fidèle à ses
principes.  Les données et prédictions du modèle sont disponibles sous
licence XX sur le portail Data de l'INRA: https://data.inra.fr. \\

*Mots-clés*: Recherche reproductible ; économie viti-vinicole ;
signes de qualité ; système d'information géographique ; modélisation
économétrique. 
#+END_abstract
#+TOC: headlines 3
** <<Intro>> Introduction
*** Contexte                                 :noheading:

    Les Appellations d'Origines Contrôlées (AOC) en Bourgogne sont
    issues de processus humains qui ont travaillées, répertoriés puis
    classés les parcelles en fonction de leur capacité à produire des
    vins de qualité.  . Niveaux.

    Christophe Lucand (dans \cite{WJac11}) cite les experts fondateurs
    (les mêmes qu'Olivier): Jullien, Morelot et Lavalle, supposent
    l'existence d'une hiérarchie commune en trois ou quatre
    catégories, avec au sommet les "têtes de cuvée" puis les premières
    cuvées. Puis il cite la thèse d'Olivier. A cette hiérarchie
    transversale se superpose une hiérarchie par villages qui ne
    détermine cependant en rien la réalité des zones
    d'approvisionnement concernées. Il s'agit plutôt d'identifications
    commerciales communes, investies d'un plus ou moins grand capital
    symbolique hérité. Ce capital symbolique hérité attribut un
    prestige plus ou moins grand à certaines communes ou propriétaires
    particulier.

    le décret instaurant les Premiers Crus ne fut toutefois adopté
    qu’en 1943. Deux classements historiques servirent de principales
    références à la désignation de ces ceux-ci: celui de Jules Lavalle
    de 1855 et le Classement du Comité d’Agriculture et de Viticulture
    de l’Arrondissement de Beaune de 1860.

    D'un point de vue économique, les AOc sont un signe de qualité bla
    mais peuvent aussi faire l'objet d'une demande pour eux mêmes.

     Une analyse économique des "signes de qualité". Labels et
     certification des produits Laurent Linnemer sem-linkAnne Perrot
     Revue économique Année 2000 51-6 pp. 1397-1418

     Asymétrie de l'information, réputation et certification Bénédicte
     Coestier Annales d'Économie et de Statistique No. 51 (Jul. -
     Sep., 1998

*** Sources de données                       :noheading:

    L'objet de cet article est premièrement de présenter la
    construction de la base de données. carte de la zone pas les
    hoautes cotes ni le châtillonnais. corresond à
    l'unesco?  https://whc.unesco.org/fr/list/1425/

    Une aire parcellaire délimitée désigne une délimitation qui repose
    sur les limites administratives du cadastre et dont le maillage
    suffisamment fin permet de tenir compte de variations très
    localisées des éléments du milieu physique (règlements européens
    510/2006 et 1234/2007) AOC en Cote d'Or: PCI-Vecteur ou cadastre
    de l'IGN. Peut comprendre des parcelle découpées.

*** Analyses                                 :noheading:

    Nous présentons également une application de cette base de données
    pour proposer une analyse statistique de l'information présente
    dans les AOC. En lien avec leur structuration hiérarchique en
    niveau,  

*** Détails techniques                       :noheading:

    Ce document contient le code R, packages, github, etc.  Les bases
    de données sources qui entrent dans le travail sont disponibles
    auprès des auteurs sur demande. 

** <<Const>> Construction des données
*** Travail préalable                        :noexport:
**** Sur la couche parcellaire

#+begin_src R :wrap example
library(rgdal)
Geo.Cada <- readOGR("./Data/VITI_JSA_MH", "dicopar", verbose= F)
Geo.Cada$CODECOM <- paste0(Geo.Cada$Code_dep, Geo.Cada$Code_com)
names(Geo.Cada)
CadaParc <- Geo.Cada[,c("IDU","CODECOM", "Area", "Perimeter", "Max_distan",
                        "Par2ras", "PAOC", "ALIG", "BPTG", "CREM", "MOUS", 
                        "BGOR", "BOUR", "VILL", "COMM", "PCRU", "GCRU")]
names(CadaParc)[ 3: 6] <- c("AREA", "PERIM", "MAXDIST", "PAR2RAS")
writeOGR(CadaParc, "Carto/", "CadaParc", "ESRI Shapefile")
#+end_src

  NOTE : l'IDU est l'identifiant unique parcellaire, composé des
    champs :
 - CODCOM : code commune sur 5 caractères (ex 56355)
 - PREFIXE : préfixe de section sur 3 caractères (par défaut 000):
   suite à fusion de communes
 - SECTION : identifiant section cadastrale sur 2 caractères (ex AB)
 - NUMPARC : numéro de parcelle sur 4 caractères (ex : 0255) D'où un
   IDU sur 14 caractères (ex : 56355000AB0255)

**** Sur le raster

#+begin_src R
library(data.table)
Dat.Dem <- fread("Data/VITI_JSA_MH/vitidem.csv")
Dat.dem <- cbind(Dat.Dem, model.matrix(~ 0+ factor(MOS), Dat.Dem))
rm(Dat.Dem) ; dim(Dat.dem)
names(Dat.dem)[ 23: 34] <-
    c("NOMOS", "FIELDS", "GRASS", "SHRUBS", "FOREST", "VINEYARD",
      "WATER", "INFRAS", "INDUSFAC", "AGRIFAC", "LOWBUILT", "HIGHBUILT")
Dat.dem$URBAN <- rowSums(Dat.dem[, 30: 34])
Dat.Rast <- Dat.dem[, c("SUB2IND", "XL93", "YL93", "PAR2RAS",
                        "NOMOS", "URBAN", "FOREST", "WATER",
                        "DEM", "SLOPE", "ASPECT", "SOLAR", "PERMEABILITY")]
names(Dat.Rast)[ 13] <- "PERMEA"
fwrite(Dat.Rast, "Data/DatRas.csv")
#+end_src

**** Sur la géologie
***** Nouveau

#+begin_src R
GEOL <- readOGR("./Data/BRGM", "GEO050K_HARM_021_S_FGEOL_CGH_2154")
Pts.Cad <- SpatialPoints(Geo.Ras, proj4string= CRS(proj4string(Geo.Ras)))
ttp <- over(Pts.Cad, GEOL)
selcol1 <- sapply(ttp, function(x) sum(is.na(x))< 1000)
selcol2 <- names(ttp)[ selcol1][ c(2, 4, 5, 15: 19, 21: 26, 28, 29)]
GeolMap <- GEOL[, selcol2]
writeOGR(GeolMap, "./Carto/", "GeolMap", "ESRI Shapefile")
#+end_src

***** Ancien

#+begin_src R :wrap "export latex"
library(rgdal) ; library(xtable)
GEOL <- readOGR("./Data/GeolPedo", "GeolL93", verb= F)
GEOL2 <- readOGR("./Data/BRGM", "GEO050K_HARM_021_S_FGEOL_CGH_2154")
head(GEOL2@data)
names(GEOL2)
table(GEOL2$DESCR)

table(GEOL2$C_FOND)

GCDtmp2 <- SpatialPointsDataFrame(GCDtmp,
                 data= cbind(Geo.CDem@data, over(GCDtmp, GEOL)[, 4: 5]))
names(GCDtmp2)[ 69: 70] <- c("CODEg", "DESCRg") 
tab <- data.frame(GCDtmp2$CODEg[!duplicated(GCDtmp2$CODEg)],
                  substr(GCDtmp2$DESCRg[!duplicated(GCDtmp2$CODEg)],1, 80))
names(tab) <- c("CODE", "DESCRIPTION")
tmp <- aggregate(rep(1, nrow(GCDtmp2)), by= list(GCDtmp2$CODEg), sum)
names(tmp) <- c("CODE", "FREQ")
tabb <- merge(tab, tmp, by= "CODE", all.x= TRUE)
tabb[32, 3] <- nrow(GCDtmp2)- sum(tmp[, 2])
print(xtable(tabb, digits= 0, caption= "Classification géologique"),
      hline.after = NULL, include.rownames= FALSE,
      add.to.row = list(pos = list(-1, 0, nrow(tab)),
          command = c("\\hline\\hline\\toprule\n", "\\midrule\n",
              "\\bottomrule\\hline\n")), caption.placement= "top",
      tabular.environment= "tabularx", width="\\textwidth",
      sanitize.text.function= identity, floating= T, table.placement="!h")
#+end_src

**** Sur la pédologie

#+begin_src R
PEDO <- readOGR("./Data/GeolPedo", "UCSCote2", verb= FALSE)
DESCRpedo <- read.csv("Inter/DescrPedo.csv", sep= ";")
Pedo.Map <- merge(PEDO, DESCRpedo, by= "NOUC")
Pedo.map <- spTransform(Pedo.Map, proj4string(Geo.Cada))
writeOGR(Pedo.map, "Carto/", "PedoMap", "ESRI Shapefile")
#+end_src

**** Sur les AOC historiques

     Le répertoire =/Data/ExportSHP_territoireAOC= contient les aires
     délimitées au moment de la création des AOC en 1936 avec les
     évolutions des 4 années qui ont suivies. Ces données m'ont été
     transmises par Florian Humbert de l'IUVV via la MSH. Il s'agit
     ici de faire une boucle sur ces fichiers shapefile et de créer
     autant d'indicatrices pour les parcelles dont le centroïde tombe
     à l'intérieur des ces aires historiques. Pour que la fonction
     ci-dessous marche bien, j'ai dû renommer certains fichiers
     initiaux:
     - =AOC_Pernand1936= devient =AOC_Pernand_Vergelesses_1936=
     - =AOC_Meursault_Blagny_Blagny_Blagny_Cote_de_Beaune_1939= devient \\
       =AOC_Meursault_Blagny_Cote_de_Beaune_1939=
     - =AOC_Cote_de_Beaune_1939= devient
       =AOC_Beaune_Cote_de_Beaune_1939=

#+begin_src R :wrap example
library(rgdal)
Geo.Cada <- readOGR("./Data/VITI_JSA_MH", "dicopar", verbose= F)
Pts.Cada <- SpatialPointsDataFrame(Geo.Cada, match.ID= FALSE,
                                   proj4string=CRS(proj4string(Geo.Cada)), 
                                   data= data.frame(1: nrow(Geo.Cada)))
Pts.Cada$Com36 <- Pts.Cada$Com37 <- Pts.Cada$Com38 <-
    Pts.Cada$Com39 <- Pts.Cada$Cote39 <- Pts.Cada$Com40 <- "NONE"

rpt <- "Data/ExportSHP_territoireAOC/"
for (i in list.files(rpt, pattern = "\\.shp$")) {
    map <- readOGR(rpt, substr(i, 1, nchar(i)- 4), ver= F)
    tmp <- over(Pts.Cada, map)
    yop <- substr(i, nchar(i)- 22, nchar(i)- 19)== "Cote"
    aoc= if (yop) substr(i, 5, nchar(i)- 24) else substr(i, 5, nchar(i)- 9)
    switch(substr(i, nchar(i)- 7, nchar(i)- 4), 
           "1936"={Pts.Cada$Com36[!is.na(tmp$Nom)]= aoc},
           "1937"={Pts.Cada$Com37[!is.na(tmp$Nom)]= aoc},
           "1938"={Pts.Cada$Com38[!is.na(tmp$Nom)]= aoc},
           "1940"={Pts.Cada$Com40[!is.na(tmp$Nom)]= aoc},
           "1939"={if (yop) {
                       Pts.Cada$Cote39[!is.na(tmp$Nom)]= aoc
                       } else Pts.Cada$Com39[!is.na(tmp$Nom)]= aoc},
       {print('erreur')})
}

aocavt <- c(levels(factor(Pts.Cada$Com39)),levels(factor(Pts.Cada$Cote39)),
            levels(factor(Pts.Cada$Com38)), levels(factor(Pts.Cada$Com37)),
            levels(factor(Pts.Cada$Com36)))

equiv <- c("Auxey_Duresses"= 3, "Batard_Montrachet"= 5,
           "Bienvenues_Batard_Montrachet"= 5, "Chassagne_Montrachet"= 3,
           "Chevalier_Montrachet"= 5, "Chorey_les_Beaune"= 3,
           "Clos_de_Tart"= 5, "Criots_Batard_Montrachet"= 5, "Ladoix"= 3,
           "Meursault"= 3, "Monthelie"= 3, "Morey_Saint_Denis"= 3,
           "NONE"= 0, "Pernand_Vergelesses"= 3, "Puligny_Montrachet"= 3,
           "Saint_Aubin"= 3, "Santenay"= 3, "Savigny"= 3, "Volnay"= 3,
           "Volnay_Santenots"= 3, ## ATTENTION
           "Beaune"= 3, "Chorey"= 3, "Meursault_Blagny"= 3,
           "Aloxe_Corton"= 3, "Vosne_Romanee"= 3, "Chambertin"= 5,
           "Chambertin_Clos_de_Beze"= 5, "Chapelle_Chambertin"= 5,
           "Charlemagne"= 5, "Charmes_Chambertin"= 5, "Clos_de_Vougeot"= 5,
           "Corton"= 5, "Corton_Charlemagne"= 5,                       
           "Cote_de_Beaune_ou_Cote_de_Beaune_Villages"= 3,
           "Echezeaux"= 5, "Gevrey_Chambertin"= 3, "Grands_Echezeaux"= 5,
           "Griotte_Chambertin"= 5, "Latricieres_Chambertin"= 5,
           "Mazis_Chambertin"= 5, "Mazoyeres_Chambertin"= 5,
           "Montrachet"= 5, "Ruchottes_Chambertin"= 5,
           "Vins_fins_de_la_Cote_de_Nuits"= 3, ## ATTENTION            
           "Vougeot_rouge"= 3, "Bonnes_Mares"= 5, "Chambolle_Musigny"= 3,
           "Clos_de_la_Roche"= 5, "Clos_Saint_Denis"= 5, "Fixin"= 3,
           "La_Tache"= 5, "Musigny"= 5, "Nuits"= 3, "Pommard"= 3,
           "Richebourg"= 5, "Romanee"= 5, "Romanee_Conti"= 5,
           "Romanee_Saint_Vivant"= 5, "Vougeot"= 3)

library(plyr)
Pts.Cada$AOC39 <- revalue(factor(Pts.Cada$Cote39), equiv)
Pts.Cada$aoc39 <- revalue(factor(Pts.Cada$Com39), equiv)
Pts.Cada$AOC38 <- revalue(factor(Pts.Cada$Com38), equiv)
Pts.Cada$AOC37 <- revalue(factor(Pts.Cada$Com37), equiv)
Pts.Cada$AOC36 <- revalue(factor(Pts.Cada$Com36), equiv)


Pts.Cada$AOCavt <- apply(Pts.Cada@data[, 8: 12], 1, max)
Pts.Cada$tmpp <- apply(Pts.Cada@data[, 8: 12], 1, which.max)
Pts.Cada$AOClab <-
    apply(Pts.Cada@data, 1, function(x) x[ 2+ as.numeric(x[ 14])])

Geo.Cada@data <- cbind(Geo.Cada@data, Pts.Cada@data)
library(rgeos)
spydf_states <- gBuffer(Geo.Cada, byid=TRUE, width=0)
library(maptools)
OLDGIS <- unionSpatialPolygons(spydf_states, as.character(Geo.Cada$AOClab))
OLDGIS$AOC36lab <- as.character(row.names(OLDGIS))
OLDGIS$AOC36lvl <- revalue(factor(OLDGIS$AOC36lab), equiv)
OLDGIS$AOC36lab[OLDGIS$AOC36lab== "Vougeot_rouge" ] <- "Vougeot"
writeOGR(OLDGIS, "Carto/", "Aoc1936", "ESRI Shapefile")
#+end_src

     On pourrait reporter les années de création mais pas dans le
     fichier géographique tel qu'il est utilisé ici.

**** Sur les lieux dits

#+begin_src R
library(rgdal)
CCOM <- readOGR("Carto/", "COML93")
ClCom <- read.csv("Data/ClassCom.csv", sep= ";")
names(ClCom)[ 1] <- "INSEE_COM"
tmpCom <- merge(CCOM, ClCom[-18, c(1, 3)], by= "INSEE_COM")
MapCom <- subset(tmpCom, tmpCom$INSEE_COM %in% c("21231",Geo.Cada$CODECOM),
                 select= c(3, 4, 8, 9, 13, 19))
writeOGR(MapCom, "Carto/", "MapCom", "ESRI Shapefile")

DatCom <- subset(tmpCom, tmpCom$INSEE_COM %in% Geo.Cada$CODECOM,
                 select= c(1, 4, 6, 7, 10, 11, 12, 13, 19))
names(DatCom) <- c("CODECOM", "LIBCOM", "XCHF", "YCHF",
                   "ALTCOM", "SUPCOM", "POPCOM", "CODECANT", "REGION")
MapLieuDits <- readOGR("Data/LieuxDits/Abziz", "COTE_NB21", verb= F)
MapLieuDits <- spTransform(MapLieuDits, proj4string(Geo.Cada))
names(MapLieuDits)[ c(2, 4, 6)] <- c("CODECOM", "LIEUDIT", "CLDVIN")
LieuDit <- merge(MapLieuDits[, c(2, 4, 6)], DatCom, by= "CODECOM")
writeOGR(Lieu.Dit, "./Carto/", "LieuDit", "ESRI Shapefile")
#+end_src

*** Les parcelles cadastrales

    Le travail porte sur l'ensemble des parcelles cadastrales des 31
    communes de la Côte de Beaune et de la Côte de Nuits reportées
    dans la Figure XX en Annexe A.  La géométrie du parcellaires est
    issue de la BD parcellaire de l'IGN version X.XX téléchargée le
    XX/XX/2018.  Deux traitements ont été effectués au préalable, nous
    avons calculé à l'aide d'un système d'information géographique
    (SIG) des caractéristiques géométriques des parcelles (surface,
    périmètre, et distance maximale entre deux sommets, voir Table
    [[Tab:1]]) et appariée l'information sur les AOC à partir du fichier
    de l'INAO sur \url{data.gouv.fr}.  Sur ce deuxième point, blabla.

    À partir du Shapefile =dicopar= disponible sur le cloud au
    <2019-01-11 ven.> projection Lambert 93, nous créons un code INSEE
    par concaténation du département et du code commune:

#+begin_src R :wrap example
library(sp) ; library(rgdal)
Geo.Cada <- readOGR("./Carto", "CadaParc")
sapply(Geo.Cada@data, function(x) sum(is.na(x)))
#+end_src

#+RESULTS:
#+begin_example
OGR data source with driver: ESRI Shapefile 
Source: "/home/jsay/geoIndic/Carto", layer: "CadaParc"
with 110350 features
It has 17 fields
    IDU CODECOM    AREA   PERIM MAXDIST PAR2RAS    PAOC    ALIG 
      0       0       0       0       0       0       0       0 
   BPTG    CREM    MOUS    BGOR    BOUR    VILL    COMM    PCRU 
      0       0       0       0       0       0       0       0 
   GCRU 
      0
#+end_example

    La base parcellaire contient donc $110\,350$ observations et 30
    variables issues des données cadastrales IGN (variables 1 à 8),
    des descripteurs de la géométrie des parcelles (variables 9 à 16),
    un identifiant pour l'appariement avec les données raster, un
    identifiant cadastral et les variables issues de l'INAO (variables
    19 à 29):

#+begin_src R :exports results :results value :colnames yes :rownames yes
(labs <- data.frame(NOM= c("IDU", "CODECOM", "AREA", "PERIM", "MAXDIST",
                           "PAR2RAS","PAOC", "ALIG", "BPTG","CREM", "MOUS",
                           "BGOR", "BOUR", "VILL", "COMM", "PCRU", "GCRU"),
                   TYPE= 1: 17,
                   LABEL= c("Identifiant cadastral", "Code INSEE commune",
                            "Surface de la parcelle",
                            "Périmètre de la parcelle",
                            "Distance maximale entre deux sommets",
                            "Identifiant pour appariement avec raster",
                            "Hors périmètre AOC", "Bourgogne Aligoté",
                            "Bourgogne Passe Tout Grain",
                            "Crémant de Bourgogne", "Bourgogne Mousseux",
                            "Coteaux Bourguignon", "Bourgogne Régional",
                            "Bourgogne Village", "Bourgogne Communal",
                            "Premier Cru", "Grand Cru")))
#+end_src

#+ATTR_LATEX: :environment tabularx :width \textwidth :align lllX
#+CAPTION: Numéro, nom, type et label des variables parcellaires
#+NAME: Tab:1
#+RESULTS:
|    | NOM     | TYPE | LABEL                                    |
|----+---------+------+------------------------------------------|
|  1 | IDU     |    1 | Identifiant cadastral                    |
|  2 | CODECOM |    2 | Code INSEE commune                       |
|  3 | AREA    |    3 | Surface de la parcelle                   |
|  4 | PERIM   |    4 | Périmètre de la parcelle                 |
|  5 | MAXDIST |    5 | Distance maximale entre deux sommets     |
|  6 | PAR2RAS |    6 | Identifiant pour appariement avec raster |
|  7 | PAOC    |    7 | Hors périmètre AOC                       |
|  8 | ALIG    |    8 | Bourgogne Aligoté                        |
|  9 | BPTG    |    9 | Bourgogne Passe Tout Grain               |
| 10 | CREM    |   10 | Crémant de Bourgogne                     |
| 11 | MOUS    |   11 | Bourgogne Mousseux                       |
| 12 | BGOR    |   12 | Coteaux Bourguignon                      |
| 13 | BOUR    |   13 | Bourgogne Régional                       |
| 14 | VILL    |   14 | Bourgogne Village                        |
| 15 | COMM    |   15 | Bourgogne Communal                       |
| 16 | PCRU    |   16 | Premier Cru                              |
| 17 | GCRU    |   17 | Grand Cru                                |

*** Enrichissement de la topographie

    Les données raster sont également issues du cloud, avec le fichier
    =vitidem.csv=. Nous transformons la variable catégorielle =MOS= sur
    les modes d'occupation du sol en indicatrices afin de pouvoir
    l'agréger au niveau des parcelles. Ensuite, les autres variables
    quantitatives seront simplement moyennées au niveau des
    parcelles. Nous pourrions imaginer d'autres méthodes d'agrégation
    et reporter d'autres statistiques: pour plus tard. Les données sont
    lourdes donc les codes suivants sont assez longs à tourner (surtout
    le =model.matrix=) et il faut veiller à effacer les bases
    lorsqu'elles ne servent plus.  14253070

#+begin_src R :wrap example
library(data.table)
dim(Dat.Ras <- fread("./Data/DatRas.csv"))
Cad.Ras <- Dat.Ras[, lapply(.SD, mean), by= list(PAR2RAS),
                   .SDcols= names(Dat.Ras)[ -c(1, 4)]]
Geo.Ras <- merge(Geo.Cada, Cad.Ras, by= "PAR2RAS")
sapply(Geo.Ras@data[, 18: 28], function(x) sum(is.na(x))); rm(Dat.Ras)
#+end_src

#+RESULTS:
#+begin_example
data.table 1.11.4  Latest news: http://r-datatable.com
[1] 14253070       13
  XL93   YL93  NOMOS  URBAN FOREST  WATER    DEM  SLOPE ASPECT  SOLAR 
  2096   2096   2096   2096   2096   2096   2096   2096   2096   2096 
PERMEA 
  2096
#+end_example

    Il y a $2\,096$ parcelles pour lesquelles le code =Par2ras= ne
    correspond à aucun des quelques 14 millions de raster. Ce sont /a
    priori/ des petites parcelles avec une taille médiane de 10 m$^2$
    (max. 339) alors que pour l'ensemble la médiane est de $3\,084$
    m$^2$. Il faudrait connaître le détails de la jonction entre les
    données parcelles et les données raster pour comprendre l'origine
    de ces valeurs manquantes.

    Même tableau que précédemment

*** Enrichissement de la géologie

    Depuis mars 2019, le BRGM a libéré l'accès aux cartes géologiques
    au $1/50\,000$ Bd Charm-50 sous licence Ouverte / Open Licence
    Etalab Version 2.0
    (http://infoterre.brgm.fr/page/conditions-dutilisation-donnees).
    Les données utilisées ici sont une extraction de la Côte d'Or,
    téléchargées en avril 2019 sur le site http://infoterre.brgm.fr.
    Les données sont constituées de différentes couches SIG décrivant
    les formations géologiques, les éléments linéaires et ponctuels
    structuraux et divers.  

#+begin_src R :wrap example
Geol.Map <- readOGR("./Carto/", "GeolMap")
Pts.Cad <- SpatialPoints(Geo.Ras, proj4string= CRS(proj4string(Geo.Ras)))
Geo.Ras@data <- cbind(Geo.Ras@data, over(Pts.Cad, Geol.Map))
sapply(Geo.Ras@data[, 29: 44], function(x) sum(is.na(x)))
#+end_src

#+RESULTS:
#+begin_example
OGR data source with driver: ESRI Shapefile 
Source: "/home/jsay/geoIndic/Carto", layer: "GeolMap"
with 13960 features
It has 16 fields
      CODE   NOTATION      DESCR  TYPE_GEOL  AP_LOCALE    TYPE_AP 
        31         31         31         31        862        862 
  GEOL_NAT   ISOPIQUE    AGE_DEB    ERA_DEB    SYS_DEB LITHOLOGIE 
        31         31         31         31         31         31 
    DURETE  ENVIRONMT  GEOCHIMIE  LITHO_COM 
        69         31         31         69
#+end_example


    On a fait une sélection sur les valeurs omises et sur la
    redondance d'information.

*** Enrichissement de la pédologie

    La couche pédologique est issue du Référentiel Pédologique de
    Bourgogne : Régions naturelles, pédopaysage et sols de Côte d'Or
    (étude 25021) au $1/250\,000$, compatible avec la base de données
    nationale DoneSol. La localisation des types de sol s'opère par des
    Unités Cartographiques de Sols ou Pédopaysages qui regroupent
    différents types de sols mais sans que ces derniers puissent être
    localisés plus précisément. En l'absence de données plus fines
    spatialement, les données parcellaires seront enrichies des code
    des unités cartographiques censées regroupés des sols
    homogènes. Les intitulés des UCS sont obtenus par un travail manuel
    reporté à l'annexe 2 (par le site
    https://bourgogne.websol.fr/carto).  On peut cite ma thèse.

#+begin_src R :wrap example
Pedo.Map <- readOGR("./Carto", "PedoMap")
Geo.Ras@data <- cbind(Geo.Ras@data, over(Pts.Cad, Pedo.Map))
sapply(Geo.Ras@data[, 45: 60], function(x) sum(is.na(x)))
#+end_src

#+RESULTS:
#+begin_example
OGR data source with driver: ESRI Shapefile 
Source: "/home/jsay/geoIndic/Carto", layer: "PedoMap"
with 194 features
It has 16 fields
    NOUC    NO_UC NO_ETUDE   SURFUC     TARG     TSAB     TLIM 
   14645    14645    14645    14645    14645    14645    14645 
  TEXTAG    EPAIS      TEG      TMO      RUE      RUD     NOUS 
   14645    14645    14645    14645    14645    14645    14645 
   OCCUP   DESCRp 
   14645    14645
#+end_example

    Il apparaît que les descriptions des Pédopaysages combinent des
    caractéristiques topographiques (Plaines, massifs, piedmonts), des
    caractéristiques d'occupation (forestiers, vignoble) et des
    caractéristiques géologiques (plio-pléistocènes, calcaires). Le
    redondance de ce découpage avec les variables topographiques, le
    découpage géologique et le mode d'occupation des sols se pose
    effectivement.  Les valeurs manquantes correspondent aux espaces
    urbanisés (pas vraiment à partir du MOS)

*** Enrichissement des AOC de 1936
     
#+begin_src R :wrap example
Hist.Aoc <- readOGR("Carto/", "Aoc1936")
Geo.Ras@data <- cbind(Geo.Ras@data, over(Pts.Cad, Hist.Aoc))
sapply(Geo.Ras@data[, 61: 62], function(x) sum(is.na(x)))
#+end_src

#+RESULTS:
#+begin_example
OGR data source with driver: ESRI Shapefile 
Source: "/home/jsay/geoIndic/Carto", layer: "Aoc1936"
with 56 features
It has 2 fields
AOC36lab AOC36lvl 
      70       70
#+end_example

     Nous obtenons des aires sensiblement plus réduites que les
     actuelles, 27% au lieu de 55% trouvés ci-dessus. Hormis le creux
     de 1938, entre 10 et 15% des parcelles sont classées chaque
     années, sachant qu'il y a du double compte. Dans le Data paper, il
     s'agira d'identifier les grands crus des villages avec et sans nom
     reconnus pour retrouver la structure hiérarchique. Par contre les
     premiers crus ne pourront pas apparaître car ils n'existaient pas
     à l'époque. Il faudrait voir avec Florian pourquoi les aires en
     Côte de Beaune sont moins étendues que les aires villages avec nom
     (vérifié pour Auxey-Duresses et Chassagne-Montrachet). Dans le cas
     de Meursault, les Côtes de Beaune associés sont les parcelles
     périphériques, inclues toutefois dans l'aire de Meursault. Par
     contre l'aire =Meursault_Blagny= (renommée) en Côte de Beaune est
     disjointe. En 1937, on a un polygone Côte de Beaune ou Côte de
     Beaune Village qui est disjoint de toutes les couches de cette
     année donc on l’inclut comme une modalité. Un polygone "Côte de
     Beaune" en 1939 plus étendu est ajouté à la variable Cote39,
     modalité =Beaune=. Les "vins fins de la cote de nuits" délimités
     en 1937 entrent comme une modalité dans la variable =Com37= car
     ils sont disjoint avec l'ensemble des polygones de cette année. Il
     y a deux ensembles: le nord de Gevrey et le sud de Nuits. La
     variable =Com40= ne compte que des =NONE= car les couches de cette
     année sont uniquement en Saône et Loire.

     L'appellation Vins fins de la Côte de Nuits a été remplacée le
     20/08/1964 par l'appellation Côte de Nuits Villages. Mais, le nom
     de Vins fins de la Côte de Nuits peut toujours être utilisé.  ce
     terroir est quasi-exclusivement consacré à la production de vins
     rouges.

     *Remarques:* Éric Vincent (INAO) s'est dit intéressé pour
     vectoriser les données 1860 avec de nouvelles variables sur le
     prix des terres en particulier, il s'agira de voir si l'on peu les
     intégrer dans une version 2 de la base. Je n'ai ces données pour
     l'instant que pour 5 communes qui peuvent servir de pilote. Des
     analyses descriptives m'ont fait apparaître une corrélation forte
     entre la forme du parcellaire et les AOC anciennes (parcelles en
     ligne), il faudrait regarder dans quelle mesure cela colle avec
     les nouvelles AOCs.

     *Actualisation* <2019-02-01 ven.> Rien à
     Chenove/Marsannay/Couchey. Voir callage Griotte chambertin par exemple.

*** Enrichissement des lieux dits

    Il s'agit ici d'inclure de l'information cadastrale à partir des
    sources =data.gouv.fr=. Nous utilisons le Plan Cadastral
    Informatisé Vecteur (Format EDIGÉO,
    https://cadastre.data.gouv.fr/datasets/plan-cadastral-informatise)
    téléchargé pour la Côte d'Or (21) le <2019-01-13 dim.>. License
    ouverte Etalab. La difficulté avec les lieux dit est qu'ils doivent
    être croisés avec les communes car un même nom lieu dit peut être
    présent sur plusieurs communes. Comme la géométrie des lieux dits
    et des parcelles colle parfaitement, nous pouvons enrichir les
    données parcellaires directement par le centroïde. Ajout
    <2019-01-23 mer.>, des données communales, nous extrayons également
    les coordonnées des chefs-lieux pour calculer une distance à vol
    d'oiseaux, la population (peuvent être des sur-identifications sur
    le land use) et la distinction Côte de Beaune / Côtes de
    Nuits. Nous enregistrons également une shapefile =MapCom= qui
    permet de cartographier les contours communaux dans les figures.

#+begin_src R :wrap example
Lieu.Dit <- readOGR("./Carto/", "LieuDit")
Geo.Ras@data <- cbind(Geo.Ras@data, over(Pts.Cad, Lieu.Dit[, -1]))
sapply(Geo.Ras@data[, 63: 72], function(x) sum(is.na(x)))
#+end_src

#+RESULTS:
#+begin_example
OGR data source with driver: ESRI Shapefile 
Source: "/home/jsay/geoIndic/Carto", layer: "LieuDit"
with 3285 features
It has 11 fields
 LIEUDIT   CLDVIN   LIBCOM     XCHF     YCHF   ALTCOM   SUPCOM 
    4494     4494     4494     4494     4494     4494     4494 
  POPCOM CODECANT   REGION 
    4494     4494     4494
#+end_example

    Pour 4% des parcelles, aucun lieu dit n'a été apparié. Ces
    parcelles se concentrent sur les communes de Chenôve,
    Marsannay-la-Côte et Beaune (Corgoloin dans une moindre
    mesure). Ces "trous" apparaissent déjà dans le fichier source et ne
    sont donc pas un résultat de l'appariement. Ils semblent être des
    espaces bâtis sur la carte, mais ce n'est pas confirmé par le MOS.

*** Enregistrement de la base

    Pour l'instant, on est à moins de 500 Mo.

#+begin_src R :wrap example
dim(Geo.Ras)
save(Geo.Ras, file= "Inter/GeoRas.Rda")
writeOGR(Geo.Ras, "Carto/", "GeoRas", driver= "ESRI Shapefile")
#+end_src

#+RESULTS:
#+begin_example
[1] 110350     72
#+end_example

*** Vérif 1 : anciens AOC INAO               :noexport:

    Il s'agit ici de vérifier la cohérence interne des nouveaux
    fichiers INAO et s'ils correspondent aux anciens. Nous joignons les
    deux couches en utilisant le centroïde des parcelles cadastrales
    (afin de déterminer dans quel polygone AOC ils tombent). Les
    anciens fichiers INAO contiennent une information simplifiée en 6
    classes exclusives et cumulatives, que nous croisons avec les
    nouvelles données dans le code suivant.

 #+begin_src R :wrap example
BGOR <- readOGR(rpt <- "./Data/INAOlocal", "BGOR", verbose= F)
BOUR <- readOGR(rpt, "BOUR", ver= F) ; VILL <- readOGR(rpt, "VILL", ver= F)
PCRU <- readOGR(rpt, "PCRU", ver= F) ; GCRU <- readOGR(rpt, "GCRU", ver= F)
GCDtmp <- Geo.Cada@data ; coordinates(GCDtmp) <- coordinates(Geo.Cada)
proj4string(GCDtmp) <- proj4string(Geo.Cada)
Geo.Cada$AOC <- factor(ifelse(!is.na(over(GCDtmp, GCRU)[, 9]), "GCRU",
                       ifelse(!is.na(over(GCDtmp, PCRU)[, 9]), "PCRU",
                       ifelse(!is.na(over(GCDtmp, VILL)[, 9]), "VILL",
                       ifelse(!is.na(over(GCDtmp, BOUR)[, 9]), "BOUR",
                       ifelse(!is.na(over(GCDtmp, BGOR)[, 9]), "BGOR", "NONE"))))),
                       levels= c("NONE", "BGOR", "BOUR", "VILL", "PCRU", "GCRU"))
addmargins(apply(Geo.Cada@data[, c(19: 21, 24, 28, 27, 29, 26)],
                 2, function(x) table(x== 1, Geo.Cada$AOC)[2, ]))
 #+end_src

 #+RESULTS:
 #+begin_example
      PAOC  BPTG  BGOR  BOUR  COMM  VILL  PCRU GCRU    Sum
NONE   369   201   201   349   136    23    20    3   1302
BGOR  9829  9829  9160     5     0     0     0    0  28823
BOUR 13494 13482 13482 13490     5     4     2    0  53959
VILL 26167 26111 26111 26166 23366 11524    10    0 139455
PCRU  8827  8812  8812  8826  7835  5389  8668    1  57170
GCRU  1946  1944  1944  1946  1944   173  1944 1943  13784
Sum  60632 60379 59710 50782 33286 17113 10644 1947 294493
 #+end_example

    Il y a $60\,632$ ($54.9\%$) parcelles de la zone qui ont une AOC
    viticole. La structure hiérarchique des AOC ferait que
    théoriquement sur l'ensemble de ces parcelles les AOC les moins
    prestigieuses peuvent être produites (Passe-Tout-Grain dans les
    tableau mais aussi Aligoté, Crémants et Mousseux, dont les aires
    sont identiques, résultats non reportés pour ces derniers). Nous
    obtenons une différence de 253 parcelles éparpillées sur toute la
    zone. 252 de ces parcelles sont classées en Bourgogne régional et 2
    sont classées en Premier cru (ce qui indique qu'une est classée à
    la fois Bourgogne régional et Premier cru). À part pour ces
    parcelles, la hiérarchie par rapport aux niveaux inférieurs est
    bien respectée. La hiérarchie se tient pour les Côteaux
    Bourguignons et les Bourgognes régionaux (hormis pour les 2
    parcelles de premiers crus mentionnées ci-avant). Il y a ensuite
    une certaine horizontalité entre =VILL= et =COMM=, on ne peut pas
    tester la consistance de la hiérarchie mais je dirais que le niveau
    Village final doit être la somme des deux. Tout se règle par
    l'échelle de la commune. Il y a $33\,286$ parcelles en appellation
    communale avec environ la moitié ($17\,877$) dans des communes sans
    appellation village et l'autre moitié ($15\,409$) dans des communes
    avec appellation village. Seule la commune de Beaune contient des
    parcelles avec =VILL= égal à 1 avec =COMM= égal à 0 ($N= 1\,704$),
    il faut les ajouter aux parcelles en appellation
    communale. (Retravailler le texte dans le papier.) La hiérarchie
    avec les premiers crus n'est pas vérifiée pour 94 parcelles (dont
    92 à Fixin et 2 à Brochon) à voir d'où vient l'erreur. Pour les
    Grands Crus c'est presque bon, ils peuvent tous peuvent se replier
    dans l'ensemble des autres appellations, sauf pour $1,774$
    parcelles grand cru localisées dans les communes de
    Chassagne-Montrachet et Puligny-Montrachet, où les Grands crus ne
    peuvent pas se replier en Village. Cela renforce le choix de sommer
    =VILL= et =COMM=, nous retrouverons la cohérence de la hiérarchie.

    Pour la comparaison avec les anciennes AOC, le triangle supérieur
    de la matrice monte une assez bonne cohérence (si on néglige la
    première ligne sur les parcelles hors AOC). Seulement 27 parcelles
    se retrouvent dans une AOC différente, leurs identifiants sont
    reportés en annexe 1. Pour les 369 parcelles qui étaient hors AOC
    dans les anciennes données (=AOC= = =NONE=) qui se retrouve avec
    des AOC dans les nouvelles, il pourrait s'agir de modifications
    parcellaires, les IDU sont reportées dans le fichier
    =./Inter/HorsAOC.csv= (script ci-dessous). Globalement, moyennant
    le traitement sur les communes et les villages, les nouvelles
    données sont cohérentes et correspondent aux anciens, donc nou ne
    retenons que ces nouveaux fichiers.

 #+begin_src R :results raw :file "Inter/HorsAOC.csv" :colnames yes
Geo.Cada@data[Geo.Cada$AOC== "NONE" &
              rowSums(Geo.Cada@data[, 19: 29])> 1, 18: 30]
 #+end_src

 #+RESULTS:
 [[file:Inter/HorsAOC.csv]]

*** Vérif 2: vignes dans le MOS              :noexport:

    Vérifications à l'échelle communale avec le Casier Viticole
    Informatisé 2015 sur lequel je travaille avec l'INAO. Les surfaces
    communales de vigne en 2015 sont disponibles dans le fichier
    =/Inter/CP2015.csv=. J'utilise également les surfaces produites par
    FranceAgriMer en 2016 (issues du projet avec Estelle).

#+begin_src R :results graphics :file "Figures/Verif2.pdf"
load("Inter/AocRank.Rda")
names(AocRank)
yop <- aggregate(AocRank@data[, 51: 62]* AocRank$Area/ 10000,
          by= list(AocRank$AOC), sum, na.rm= T)
row.names(yop) <- yop[, 1]
addmargins(round(as.matrix(yop[, -1], nrow= 6), 1))
yop

AocRank$SUPVIGNE <- AocRank$VINEYARD* AocRank$Area/ 10000
tmp <- aggregate(AocRank$SUPVIGNE, by=list(AocRank$CODECOM), sum, na.rm= T)
names(tmp)[ 1] <- "CODGEO"
FAM16 <- read.csv("~/bioEstelle/Data/NewData2016.csv", sep= ";")
tmp1 <- subset(FAM16, FAM16$CODECOM %in% levels(factor(tmp$CODGEO)))
names(tmp1)[ 5] <- "CODGEO"
CVI15 <- read.csv("Inter/CP2015.csv", sep= ";")
tmp2 <- subset(CVI15, CVI15$CODGEO %in%  levels(factor(tmp$CODGEO)))

tmp3 <- merge(tmp1, tmp2, by= "CODGEO")
plot(tmp3$SUPVIGNE, tmp3$TOTha)
tmp4 <- merge(tmp, tmp3, by= "CODGEO")
plot(tmp4$x, tmp4$TOTha,
     xlab= "Surfaces en vignes selon le MOS (ha)",
     ylab= "Surfaces en vignes selon le CVI (ha)")
abline(a= 0, b= 1)
names(tmp4)
tmp4[tmp4$x== 0 & tmp4$TOTha> 200, c("CODGEO", "NOMCOM", "TOTha")]
#+end_src

#+ATTR_LaTeX: :options scale= .35
#+Caption: *Relation entre les surfaces MOS et CVI pour les communes de la zone*
#+RESULTS:
[[file:Figures/Verif2.pdf]]

*** Lieux dits: actualisation PLUS TARD      :noexport:

    Pour les lieux dit la version cadastre retravaillée Etalab
    (https://www.data.gouv.fr/fr/datasets/cadastre/) serait suffisante
    mais le PCI contient plus de variables. Les sources sont dans le
    répertoire =/Data/PCI/dpt21/=, j'utilise alors l'extension
    =cadastre= de QGis pour générer des SpatiaLite par commune qui
    contiennent l'ensemble des informations disponibles dans le PCI. Il
    faut pour cela créer une base Spatialite pour chaque commune, que
    je localise dans le répertoire =/Data/PCI/SpatiaLite/= en utilisant
    le nom simplifié de chaque commune. Il faut ensuite localiser le
    répertoire des fichiers EDIGEO mettre la projection Lambert 93 en
    source et en cible mettre le code commune en lot et lancer
    l'export. Au redémarrage de QGis les fichiers exportés apparaissent
    dans l'explorateur, au niveau SpatiaLite.

#+begin_src R
rpt <- "Data/PCI/LieuxDits/"
map <- readOGR(rpt, "21166")
plot(map, border= "blue", add= T)
plot(Geo.CDem, add= T)
proj4string(map) <- proj4string(Geo.CDem)
yop <- over(Geo.CDem, map)
table(yop$tex)
#+end_src

** <<StatD>> Statistiques descriptives
*** Général

    Avant ici pas de stat des

#+begin_src R

Reg.Rank$AOCc <- ifelse(Reg.Rank$GCRU== 1, 5,
                 ifelse(Reg.Rank$PCRU== 1, 4,
                 ifelse(Reg.Rank$VILL== 1 | Reg.Rank$COMM== 1, 3,
                 ifelse(Reg.Rank$BOUR== 1, 2, 1))))

tmp <- DatCom$LIBCOM[order(DatCom$YCHF, decreasing= TRUE)]
GCDtmp5$LIBCOM <- factor(GCDtmp5$LIBCOM, levels= tmp)
GCDtmp5$DISTCHF <- sqrt((GCDtmp5$XL93- GCDtmp5$XCHF* 100)^2
                        + (GCDtmp5$YL93- GCDtmp5$YCHF* 100)^2)

#+end_src

*** Bilan surfacique des AOC

    Définition de nos niveaux et implications en termes de surfaces
    sur la pyramides des AOC.

    The endogeneity is about the size or the shape of parcels, but not
    the pedoclimatic variables. The endogeneity of the size/ shape of
    parcel can be due both to simultaneity and omitted land quality
    effects. Both seems to be intuitively treated. Size of parcels
    multiples of ha, m2 or ouvrée (= 428 m2)?

*** Liens avec les AOC historiques

   First load the =.shp= file in the R workspace. 

   The database contains ...

   Hiérachisation des données historiques par les nom de crus et s'il
   sont présents dans les nouvelles données.

\begin{equation}\label{eq:2}
y= ax+ b
\end{equation}

   Retravail des données brutes AOC (XX et XXI) et création des
   niveaux hiérachiques.

*** Distribution spatiale
** <<Ordon>> Modèle ordonné de désignation
*** Variable transformations

#+begin_src R
RegRank$RAYAT <- with(RegRank@data, (SOLAR- mean(SOLAR))/ sd(SOLAR))
RegRank$EXPO <- factor(ifelse(RegRank$ASPECT< 45, "0-45",
                       ifelse(RegRank$ASPECT< 90, "45-90",
                       ifelse(RegRank$ASPECT<135, "90-135",
                       ifelse(RegRank$ASPECT<180, "135-180",
                       ifelse(RegRank$ASPECT<225, "180-225",
                       ifelse(RegRank$ASPECT<270, "225-270",
                       ifelse(RegRank$ASPECT<315, "270-315", "315-360"))))))),
                       levels= c("0-45", "45-90", "90-135", "135-180",
                                 "180-225","225-270","270-315","315-360"))

RRank <- spTransform(RegRank, CRS("+proj=longlat +ellps=WGS84"))
SSank <- as(RRank, "data.frame")
RRank$X= SSank$coords.x1
RRank$Y= SSank$coords.x2



#+end_src

*** Spécification du modèle

    La différence avec le multinomial c'est dans l'interprétation des
    données. Dans le MNL, tu dis c'est VILL est la meilleure AOC pour
    cette parcelle. Dans le OP, tu dis cette parcelle peut est mieux
    que Bourgogne, mieux que VILL, mais moins bien que PCRU et Grand
    cru. L'OP intègre mieux l'information, il ne faut pas mettre les 2
    en concurrence. cette pratique est liée au principe de
    hiérarchisation des appellations d'origine, qui [...] s'emboîtent
    de manière pyramidale à partir d'une appellation régionale socle
    […]. Dans cette optique, le vin élaboré selon le cahier des
    charges d'une appellation hiérarchiquement supérieure répondrait
    de facto aux exigences de l'appellation régionale, dont les
    conditions de production sont moins contraignantes.

#+begin_src R
library(mgcv) ## ASSEZ LONG
gam2 <- gam(AOCc~ s(DEM, k= 10)+ s(SLOPE)+ s(ASPECT)+ s(RAYAT)+ s(PERMEABILITY)
            + s(XREG, YREG, k= 200)+ LIBCOM
          , data= RegRank, family= ocat(R= 5))

summary(gam2)
plot(gam2, scale= 0)

plot(density((gam2$linear.pred- min(gam2$linear.pred))/
             (max(gam2$linear.pred)- min(gam2$linear.pred))))
prdat <- RegRank
prdat$LIBCOM <- "BROCHON"

gg <- predict(gam2, type= "response", newdata= prdat)
hh <- ifelse(gg[, 1]> 1- 1/1e16, 1- 1/1e16, gg[, 1])
prdat$score <- qlogis(1- hh)
RegRank$SCORE <- (prdat$score- min(prdat$score))/
    (max(prdat$score)- min(prdat$score))

plot(density(RegRank$SCORE))
library(plyr)
ee <- ddply(RegRank, .(CODEld),
            function(x) data.frame(Mean= mean(x$SCORE),
                                   Median= median(x$SCORE),
                                   WMean= weighted.mean(x$SCORE, x$Area)))
head(ee[order(ee$Mean, decreasing= TRUE), ], 20)

ff <- ddply(RegRank, .(LIBCOM),
            function(x) data.frame(Mean= mean(x$SCORE),
                                   Median= median(x$SCORE),
                                   WMean= weighted.mean(x$SCORE, x$Area)))
ff[order(ff$Mean, decreasing= TRUE), ]
ff[order(ff$WMean, decreasing= TRUE), ]
#+end_src

*** Effets des variables biophysiques
*** Prédiction du score et classifications
** <<Carto>> Mise en cartographie dynamique

   AGGREGATION PAR LIEUX DITS

   On utilise mapview, https://r-spatial.github.io/mapview/
   - sudo apt install libgdal-dev
   - sudo ln -s /usr/lib/rstudio/bin/pandoc/pandoc /usr/local/bin
   - webshot::install_phantomjs()

   On pourrait également utiliser:
   - http://symbolixau.github.io/googleway/articles/googleway-vignette.html
   - https://www.osgeo.org/projects/mapguide-open-source/
   - http://geoserver.org/
   - https://rstudio.github.io/leaflet/shiny.html
   - https://github.com/mtennekes/tmap

   On peut mettre des graphiques quand on clique sur un polygone:
   https://r-spatial.github.io/mapview/articles/articles/mapview_04-popups.html

   also show info on the epsg code and the proj4string press and hold
   Ctrl and move the mouse. addMouseCoordinates also allows us to copy
   the info about the current mouse position to the clipboard by
   holding the Ctrl and left-clicking on the map.

#+begin_src R
library(rgdal)
Geo.Cada <- readOGR("./Data/VITI_JSA_MH", "dicopar", verbose= F)
MapCom <- readOGR("Carto/", "MapCom")
mapviewOptions()
mapviewOptions(maxpolygons= 150000)
library(mapview)

Geo.Cada$AOC <- factor(ifelse(Geo.Cada$GCRU== 1, "Grand Cru",
                       ifelse(Geo.Cada$PCRU== 1, "Premier Cru",
                       ifelse(Geo.Cada$COMM== 1 |
                              Geo.Cada$VILL== 1, "Communale",
                       ifelse(Geo.Cada$BOUR== 1, "Régionale",
                              "Coteaux")))),
                       levels= c("Coteaux", "Régionale", "Communale",
                                 "Premier Cru", "Grand Cru"))

n <- mapview(subset(Geo.Cada, PAOC== 1 & Nom_com== "Chenôve"),
             zcol= "AOC", alpha.regions= .6,
             col.regions= paste0("purple", c("1", "2", "", "3", "4")),
             color= "white",
             label= com1$IDU,
             layer.name= "Chenôve",
             popup = popupTable(com1,
                                zcol = c("Area", "Perimeter", "P_a")))+
    
    mapview(subset(Geo.Cada, PAOC== 1 & Nom_com== "Marsannay-la-Côte"),
            zcol= "AOC", alpha.regions= .6,
            col.regions= paste0("purple", c("1", "2", "", "3", "4")),
            color= "white",
              label= com2$IDU,
            layer.name= "Marsannay-la-Côte",
            popup = popupTable(com2,
                               zcol = c("Area", "Perimeter", "P_a")))+
    
    mapview(subset(Geo.Cada, PAOC== 1 & Nom_com== "Couchey"),
            zcol= "AOC", alpha.regions= .6,
            col.regions= paste0("purple", c("1", "2", "", "3", "4")),
            color= "white",
              label= com2$IDU,
            layer.name= "Couchey",
            popup = popupTable(com2,
                               zcol = c("Area", "Perimeter", "P_a")))+
    
    mapview(subset(Geo.Cada, PAOC== 1 & Nom_com== "Fixin"),
            zcol= "AOC", alpha.regions= .6,
            col.regions= paste0("purple", c("1", "2", "", "3", "4")),
            color= "white",
              label= com2$IDU,
            layer.name= "Fixin",
            popup = popupTable(com2,
                               zcol = c("Area", "Perimeter", "P_a")))+
    
    mapview(subset(Geo.Cada, PAOC== 1 & Nom_com== "Brochon"),
            zcol= "AOC", alpha.regions= .6,
            col.regions= paste0("purple", c("1", "2", "", "3", "4")),
            color= "white",
              label= com2$IDU,
            layer.name= "Brochon",
            popup = popupTable(com2,
                               zcol = c("Area", "Perimeter", "P_a")))+
    
    mapview(subset(Geo.Cada, PAOC== 1 & Nom_com== "Gevrey-Chambertin"),
            zcol= "AOC", alpha.regions= .6,
            col.regions= paste0("purple", c("1", "2", "", "3", "4")),
            color= "white", label= com2$IDU,
            layer.name= "Gevrey-Chambertin",
            popup = popupTable(zcol = c("Area", "Perimeter", "P_a")))
+
    
    mapview(subset(Geo.Cada, PAOC== 1 & Nom_com== "Morey-Saint-Denis"),
            zcol= "AOC", alpha.regions= .6,
            col.regions= paste0("purple", c("1", "2", "", "3", "4")),
            color= "white", lwd= .25,
            label= com2$IDU,
            layer.name= "Morey-Saint-Denis",
            popup = popupTable(com2,
                               zcol = c("Area", "Perimeter", "P_a")))



## addLogo(n, "http://www7.inra.fr/fournisseurs/images/logo.jpg",
##         width = 200, height = 100, offset.x= 75, offset.y= 20)
n
## create standalone .html
mapshot(n, url = paste0(getwd(), "/DynMap/tst.html"))

## create .html and .png
mapshot(m, url = paste0(getwd(), "/DynMap/test.html"),
        file = paste0(getwd(), "/DynMap/test.png"),
        remove_controls = c("homeButton", "layersControl"))
#+end_src

** <<Concl>> Conclusion

   Le chiffres d’affaire des signes de qualité c’est 32 milliards
   d’euros et le budget de l’INAO 32 millions d’euros, c’est un
   millième du chiffre d’affaires.

#+begin_src R :wrap example
sessionInfo()
#+end_src

** <<Bibli>> Bibliographie
   
   bibliographystyle:../Softwares/latex/erae
   bibliography:Biblio.bib

#+LATEX: \clearpage\appendix

** <<Annex>> Annexes
*** Annexe 1: incohérence des AOC

#+begin_src R :wrap example
as.vector(Geo.CDem$IDU[Geo.CDem$AOC== "BGOR" & rowSums(Geo.CDem@data[, c(24, 26: 29)])> 0])
as.vector(Geo.CDem$IDU[Geo.CDem$AOC== "BOUR" & rowSums(Geo.CDem@data[, 26: 29])> 0])
as.vector(Geo.CDem$IDU[Geo.CDem$AOC== "VILL" & rowSums(Geo.CDem@data[, c(26, 29)])> 0])
as.vector(Geo.CDem$IDU[Geo.CDem$AOC== "PCRU" & Geo.CDem@data[, 26]> 0])
#+end_src

#+RESULTS:
#+begin_example
 [1] "21412000AZ0139" "21464000AN0094" "21492000AR0011"
 [4] "21492000BN0045" "215690000C0840"

 [1] "210370000A0507" "21110000AK0116" "21150000AM0096"
 [4] "21428000AA0019" "21582000BC0069"

 [1] "21037000AH0094" "21037000AH0096" "21110000AM0101"
 [4] "21133000AB0401" "21133000AC0005" "21133000AC0003"
 [7] "21133000AC0002" "21133000AC0004" "21512000AE0292"
[10] "21582000AL0049"

 [1] "21442000AB0315"
#+end_example

*** Annexe 2: les intitulés pédologiques

    Pour retrouver les intitulés des UCS, nous utilisons le site web
    https://bourgogne.websol.fr/carto où les différents types de sols
    qui composent les UCS sont consultables. Le travail manuel a
    consisté à extraire les coordonnées Lambert 93 d'au moins une
    parcelle par UCS et d'aller chercher sur le site le nom de l'UCS
    correspondante. Nous voyons également que lorsque l'UCS est un
    numéro manquant c'est qu'il s'agit de sols artificialisés
    (Chenôve, Nuits et Beaune). Il y a un léger effet frontière au sud
    sur les valeurs qui ne sont pas appariées.

#+begin_src R
yy <- data.frame(coordinates(GCDtmp3), GCDtmp3$NOUC)
yy[!duplicated(GCDtmp3$NOUC), ]
plot(GCDtmp3)
plot(GCDtmp3[GCDtmp3$NOUC== "0",], col= "blue", add= T, pch= 20)
#+end_src

*** Methods for GI codes                     :noexport:
    :PROPERTIES:
    :EXPORT_FILE_NAME: Codage
    :EXPORT_LATEX_CLASS: WorkinPap
    :EXPORT_OPTIONS: TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc toc:nil H:3
    :EXPORT_TITLE: Détails sur le codage des AOCs
    :EXPORT_AUTHOR:
    :END:
**** Description

     A partir du fichier SIG multicouche
     =delimitation_parcellaire_aoc_viticoles_inao=, il faudrait
     construire les 11 variables suivantes dans le fichier =dicopar= (ou
     dans une autre base de données avec l'identifiant =PAR2RAS=):
  
    1. PAOC : vaut 1 si la parcelle est dans une AOC viticole, 0 sinon
       (i.e., si elle a une intersection non vide avec la couche inao).
    2. BPTG : vaut 1 si la parcelle est dans un polygone avec la
       variable =appellation= égale à "Bourgogne Passe-tout-Grain", 0
       sinon
    3. BGOR : vaut 1 si la parcelle est dans un polygone avec la
       variable =appellation= égale à "Coteaux Bourguignons ou Bourgogne
       grand ordinaire ou Bourgogne ordinaire", 0 sinon
    4. CREM : vaut 1 si la parcelle est dans un polygone avec la
       variable =appellation= égale à "Crémant de Bourgogne", 0 sinon
    5. ALIG : vaut 1 si la parcelle est dans un polygone avec la
       variable =appellation= égale à "Bourgogne aligoté", 0 sinon
    6. BOUR : vaut 1 si la parcelle est dans un polygone avec la
       variable =appellation= égale à "Bourgogne", 0 sinon
    7. MOUS : vaut 1 si la parcelle est dans un polygone avec la
       variable =appellation= égale à "Bourgogne mousseux", 0 sinon
    8. GCRU : vaut la valeur de la variable =appellation= si la parcelle
       est dans un polygone avec la valeur =appellation= dans la liste
       des grand crus ci-dessous, 0 sinon
    9. VILL : vaut la valeur de la variable =appellation= si la parcelle
       est dans un polygone avec la valeur =appellation= dans =c("Côte
       de Beaune", "Côte de Beaune-Villages", "Côte de
       Nuits-Villages")=, 0 sinon
    10. COMM : vaut la valeur de la variable =appellation= si la
	parcelle est dans un polygone avec la valeur =appellation= dans
	la liste des communes ci-dessous, 0 sinon
    11. PCRU : différente de 0 si le terme "premier cru" apparaît dans
	la variable =denomination= (recherche du type expression
	régulière). Cette variable prend la valeur du nom qui suit la
	mention du premier cru dans la variable =denomination=. (ex:
	elle vaut "La Coutière" si denomination= "Aloxe-Corton premier
	cru La Coutière"). Pour les valeurs avec "premier cru" seul,
	sans nom qui suit (ex: denomination= "Aloxe-Corton premier cru")
	la variable premier cru doit prendre la valeur "sans nom".

**** Codes

  # Liste des Grands Crus
  #+begin_src R :results output exemple
Liste_Grand_Crus <- c("Chambertin", "Chambertin-clos de Bèze",
                      "Charmes-Chambertin", "Mazoyères-Chambertin",
                      "Chapelle-Chambertin", "Griottes-Chambertin",
                      "Latricières-Chambertin", "Mazis-Chambertin",
                      "Ruchottes-Chambertin", "Bonnes Mares",
                      "Clos de la Roche", "Clos de Tart",
                      "Clos des Lambrays", "Clos St Denis",
                      "Bonnes Mares", "Musigny",
                      "Clos de Vougeot ou Clos Vougeot",
                      "Romanée-Conti", "La Romanée",
                      "La Tâche", "Richebourg",
                      "La Grande Rue", "Romanée-St-Vivant",
                      "Echezeaux", "Grands Echezeaux",  
                      "Corton", "Corton-Charlemagne",
                      "Charlemagne", "Montrachet",
                      "Chevalier-Montrachet",
                      "Bâtard-Monrachet", "Bienvenues-Bâtard-Montrachet",
                      "Montrachet", "Bâtard-Montrachet",
                      "Criots-Bâtard-Montrachet")
  #+end_src

  # Liste des Communes
  #+begin_src R :results output exemple
Liste_Communes <- c("Aloxe-Corton", "Auxey-Duresses", "Beaune",
                    "Blagny", "Chambolle-Musigny",
                    "Chassagne-Montrachet", "Chorey-lès-Beaune",
                    "Fixin", "Gevrey-Chambertin", "Ladoix",
                    "Marsannay", "Meursault", "Monthélie",
                    "Morey-Saint-Denis", "Nuits-Saint-Georges",
                    "Pernand-Vergelesses", "Pommard",
                    "Puligny-Montrachet", "Saint-Aubin",
                    "Saint-Romain", "Santenay", "Savigny-lès-Beaune",
                    "Volnay", "Vosne-Romanée", "Vougeot")
  #+end_src

  # Liste des Grands Crus matchés aux communes
  #+begin_src R :results output exemple
GrandCru <- data.frame("Gevrey-Chambertin", "Chambertin",
                       "Gevrey-Chambertin", "Chambertin-clos de Bèze",
                       "Gevrey-Chambertin", "Charmes-Chambertin",
                       "Gevrey-Chambertin", "Mazoyères-Chambertin",
                       "Gevrey-Chambertin", "Chapelle-Chambertin",
                       "Gevrey-Chambertin", "Griottes-Chambertin",
                       "Gevrey-Chambertin", "Latricières-Chambertin",
                       "Gevrey-Chambertin", "Mazis-Chambertin",
                       "Gevrey-Chambertin", "Ruchottes-Chambertin",
                       "Morey St Denis", "Bonnes Mares",
                       "Morey St Denis", "Clos de la Roche",
                       "Morey St Denis", "Clos de Tart",
                       "Morey St Denis", "Clos des Lambrays",
                       "Morey St Denis", "Clos St Denis",
                       "Chambolle-Musigny", "Bonnes Mares",
                       "Chambolle-Musigny", "Musigny",
                       "Vougeot", "Clos de Vougeot ou Clos Vougeot",
                       "Vosne-Romanée", "Romanée-Conti",
                       "Vosne-Romanée", "La Romanée",
                       "Vosne-Romanée", "La Tâche",
                       "Vosne-Romanée", "Richebourg",
                       "Vosne-Romanée", "La Grande Rue",
                       "Vosne-Romanée", "Romanée-St-Vivant",
                       "Flagey-Echezeaux", "Echezeaux",
                       "Flagey-Echezeaux", "Grands Echezeaux",  
                       "Ladoix-Serrigny", "Corton",
                       "Ladoix-Serrigny", "Corton-Charlemagne",
                       "Pernand-Vergelesses", "Corton",
                       "Pernand-Vergelesses", "Corton-Charlemagne",
                       "Pernand-Vergelesses", "Charlemagne",
                       "Puligny-Montrachet", "Montrachet",
                       "Puligny-Montrachet", "Chevalier-Montrachet",
                       "Puligny-Montrachet", "Bâtard-Monrachet",
                       "Puligny-Montrachet", "Bienvenues-Bâtard-Montrachet",
                       "Chassagne-Montrachet", "Montrachet",
                       "Chassagne-Montrachet", "Bâtard-Montrachet",
                       "Chassagne-Montrachet", "Criots-Bâtard-Montrachet")
  #+end_src

* Reproducibility
  :PROPERTIES:
  :EXPORT_FILE_NAME:    ReproPaper
  :EXPORT_LATEX_CLASS:  ManueStat
  :EXPORT_LANGUAGE:     en
  :EXPORT_OPTIONS:      TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc toc:nil H:3
  :EXPORT_TITLE:        @@latex: \textbf{The Informational Content of Geographical Indications}\\[.5cm] @@
  :EXPORT_AUTHOR:       @@latex: \textsc{Jean-Sauveur Ay}\footnote{\url{jsay@inra.fr} at UMR CESAER, AgroSup, INRA, Univ. Bourgogne Franche-Comté, 26 bd Dr Petitjean, 21000 Dijon (FR).} \\[.15cm] INRA UMR CESAER @@
  :EXPORT_DATE:         @@latex: Reproducibility file Version 0.1 : \today @@
  :EXPORT_LATEX_HEADER: \usepackage[T1]{fontenc}\usepackage{tabularx, rotating, booktabs, lscape, tikz, dcolumn, amssymb, amsmath, amsthm, bbm, eurosym, threeparttable, pdflscape, txfonts, rotfloat}  \usepackage{tocloft} \usepackage[toc]{multitoc}\renewcommand*{\multicolumntoc}{2}\setlength{\columnseprule}{.5pt}\setlength{\columnsep}{1cm}
  :END:
** Abstract                                  :noheading:
#+begin_export html
---
title:  The Informational Content of Geographical Indications
author: Jean-Sauveur Ay
date:   UMR CESAER, AgroSup, INRA, Université Bourgogne Franche-Comté
---

# Abstract
#+end_export
#+BEGIN_abstract
This file contents the R codes associated with the paper "The
informational content of geographical indications" AAWE Working Paper
No XXX.  The data used are under licence Creative Commons Attribution
Share Alike 4.0 International, available on the INRA dataverse
website: https://data.inra.fr.  R functions used are reported in the
appendix to preserve the visibility of codes.  Additional elements are
in the French version available from the following Github repository:
.
#+END_abstract
#+TOC: headlines 3
** Simulation                                :noexport:

   for Gaussian DGPs

*** Constant thresholds

#+begin_src R :results graphics :height 6 :width 11 :file "./Figures/Simu1.pdf"
x <- rnorm(10000, mean= 2, sd= 2)
xi <- rnorm(10000, sd= 1)
yi <- (.5* x)+ xi
y1 <- ifelse(yi< -1, 1, 0)
y2 <- ifelse(yi< 2 & yi> -1, 1, 0)
y3 <- ifelse(yi> 2, 1, 0)
y <- factor(ifelse(yi< -1, 1, ifelse(yi> 2, 3, 2)))
plot(yi[order(yi)], .5* x[order(yi)], type= "l",
     xlab= "Latent Variable (Signal+Noise) Increasingly Sorted",
     ylab= "Signal Part of Latent Variable")
abline(v= c(-1, 2), col= "orange", lty= 3, lwd= 2)
abline(a= 1/2, b= 1/ 2, col= "blue", lwd= 2)
lines(x= c(-10: -1, -1: 2, 2: 10),
      y= c(rep(mean(.5* x[ y1== 1]), 10),
           rep(mean(.5* x[ y2== 1]), 4), rep(mean(.5* x[ y3== 1]), 9)),
      col= "green", lty= 5, lwd= 2)
#+end_src

#+CAPTION: Gaussian Simulation of Information Signal from Geographical Indication (N= 10000)
#+ATTR_LATEX: :options scale= .55
#+RESULTS:
[[file:./Figures/Simu1.pdf]]

*** Variable thresholds

    The correlation between commune and quality has strong effects.

#+begin_src R
library(MASS) # for mvrnorm
xi <- rnorm(100000, sd= 1)
## If corr pos. inverse signal of ranking
Sig <- matrix(c(4, 0, 0, 1), 2, 2)
tmp <- mvrnorm(100000, c(2, 0), Sig)
x <- tmp[, 1] ; cx <- tmp[, 2]
cA <- ifelse(cx< -2/ 3 , 1, 0)
cB <- ifelse(cx> -2/ 3 & cx< -.05, 1, 0)
cC <- ifelse(cx> -.05  & cx< 1/3, 1, 0)
cD <- ifelse(cx> 1/3   , 1, 0)
ci <- factor(ifelse(cA== 1, "A",
             ifelse(cB== 1, "B",
             ifelse(cC== 1, "C", "D"))))
yi <- (.5* x)+ xi
gg <- model.matrix(~ 0+ ci)
s1 <- apply(gg, 1, function(z) -1+ sum(z* c(-3, -2, 1, 2)))
s2 <- apply(gg, 1, function(z)  2+ sum(z* c(-3, -2, 1, 2)))
table(yi< s1, yi> s2)
y1 <- ifelse(yi< s1, 1, 0)
y2 <- ifelse(yi< s2 & yi> s1, 1, 0)
y3 <- ifelse(yi> s2, 1, 0)
y <- factor(ifelse(yi< s1, 1, ifelse(yi> s2, 3, 2)))

plot(yi[order(yi)], .5* x[order(yi)], type= "l",
     xlab= "Latent Variable (Signal+Noise) Increasingly Sorted",
     ylab= "Signal Part of Latent Variable")
abline(v= c(-1, 2), col= "orange", lty= 3, lwd= 2)
abline(a= 1/2, b= 1/ 2, col= "blue", lwd= 2)
lines(x= c(-10: -1, -1: 2, 2: 10),
      y= c(rep(mean(.5* x[ y1== 1]), 10),
           rep(mean(.5* x[ y2== 1]), 4), rep(mean(.5* x[ y3== 1]), 9)),
      col= "green", lty= 5, lwd= 2)
#+end_src

*** Old codes                                :noexport:

#+begin_src R
## library(MASS)
## summary(polr(y~ x))
## plot(yi[order(x)], ylim= c(-5, 5))
## par(new= TRUE)
## plot(.5* x[order(x)], type= "l", col= "blue", ylim= c(-5, 5))
## abline(h= -1, col= "pink")
## abline(h= 2, col= "purple")
yop <- density(.5* x)
yap <- density(yi)
plot(yap, xlim= c(-6, 10), ylim= c(0, .42), col= "blue")
abline(v= c(-1, 2), lty= 3)
lines(x= -7: -1, y= rep(mean(yap$y[yap$x< -1]), 7), col= "pink")
lines(x= -1: 2, y= rep(mean(yap$y[yap$x> -1 & yap$x< 2]), 4), col= "pink")
lines(x= 2: 10, y= rep(mean(yap$y[yap$x< 2]), 9), col= "pink")
par(new= T)
plot(yop, xlim= c(-6, 10), ylim= c(0, .42), col= "red")
lines(x= -7: -1, y= rep(mean(yop$y[yap$x< -1]), 7), col= "red")
lines(x= -1: 2, y= rep(mean(yop$y[yap$x> -1 & yap$x< 2]), 4), col= "red")
lines(x= 2: 10, y= rep(mean(yop$y[yap$x< 2]), 9), col= "red")
#+end_src

** Previous work                             :noexport:

   Only change the projection of the base and create coordinates.

#+begin_src R
library(sp) ; load("Inter/GeoRas.Rda")
PolyVny <- spTransform(Geo.Ras, CRS("+proj=longlat +ellps=WGS84"))
yop <- coordinates(PolyVny)
PolyVny$X= yop[, 1] ; PolyVny$Y= yop[, 2]
save(PolyVny, file= "Inter/PolyVny.Rda")
#+end_src

** Descriptive Statistics
*** Nouveau                                  :noheading:

    Include stat des about sample selection

#+begin_src R :wrap example
library(sp) ; load("Inter/PolyVny.Rda")
Reg.Rank <- subset(PolyVny,
                   PolyVny$PAOC!= 0 & !is.na(PolyVny$DEM) & !is.na(PolyVny$LIBCOM))
Reg.Rank$AOCc <- ifelse(Reg.Rank$GCRU== 1, 5,
                 ifelse(Reg.Rank$PCRU== 1, 4,
                 ifelse(Reg.Rank$VILL== 1 | Reg.Rank$COMM== 1, 3,
                 ifelse(Reg.Rank$BOUR== 1, 2, 1))))
tst <- Reg.Rank@data[, 12: 17]
tst$COMM <- ifelse(tst$VILL== 1 | tst$COMM== 1, 1, 0)
tst$VILL <- 0
table(rowSums(tst), Reg.Rank$AOCc)

tmp <- Reg.Rank$LIBCOM[order(Reg.Rank$YCHF, decreasing= TRUE)]
Reg.Rank$LIBCOM <- factor(Reg.Rank$LIBCOM, levels= unique(tmp))
Reg.Rank$RAYAT <- with(Reg.Rank@data, (SOLAR- mean(SOLAR))/ sd(SOLAR))
Reg.Rank$EXPO <- cut(Reg.Rank$ASPECT,
                     breaks= c(-2, 45, 90, 135, 180, 225, 270, 315, 360))
sapply(Reg.Rank@data, function(x) sum(is.na(x)))
#table(Reg.Old$LIBCOM, Reg.Old$AOCo)
#+end_src

#+RESULTS:
#+begin_example
   PAR2RAS        IDU    CODECOM       AREA      PERIM    MAXDIST 
         0          0          0          0          0          0 
      PAOC       ALIG       BPTG       CREM       MOUS       BGOR 
         0          0          0          0          0          0 
      BOUR       VILL       COMM       PCRU       GCRU       XL93 
         0          0          0          0          0          0 
      YL93      NOMOS      URBAN     FOREST      WATER        DEM 
         0          0          0          0          0          0 
     SLOPE     ASPECT      SOLAR     PERMEA       CODE   NOTATION 
         0          0          0          0          0          0 
     DESCR  TYPE_GEOL  AP_LOCALE    TYPE_AP   GEOL_NAT   ISOPIQUE 
         0          0         80         80          0          0 
   AGE_DEB    ERA_DEB    SYS_DEB LITHOLOGIE     DURETE  ENVIRONMT 
         0          0          0          0         10          0 
 GEOCHIMIE  LITHO_COM       NOUC      NO_UC   NO_ETUDE     SURFUC 
         0         10        658        658        658        658 
      TARG       TSAB       TLIM     TEXTAG      EPAIS        TEG 
       658        658        658        658        658        658 
       TMO        RUE        RUD       NOUS      OCCUP     DESCRp 
       658        658        658        658        658        658 
  AOC36lab   AOC36lvl    LIEUDIT     CLDVIN     LIBCOM       XCHF 
        18         18        152        152        152        152 
      YCHF     ALTCOM     SUPCOM     POPCOM   CODECANT     REGION 
       152        152        152        152        152        152 
         X          Y       AOCc      RAYAT       EXPO 
         0          0          0          0          0
#+end_example

*** Ancien                                   :noexport:

#+begin_src R
load("Inter/AocRank.Rda")
RegRank <- subset(AocRank, AocRank$PAOC!= 0 &
                           !is.na(AocRank$DEM) & !is.na(AocRank$CODEg))
RegRank$AOCc <- ifelse(RegRank$GCRU== 1, 5,
                ifelse(RegRank$PCRU== 1, 4,
                ifelse(RegRank$VILL== 1 | RegRank$COMM== 1, 3,
                ifelse(RegRank$BOUR== 1, 2, 1))))
RegRank$RAYAT <- with(RegRank@data, (SOLAR- mean(SOLAR))/ sd(SOLAR))
RegRank$EXPO <- factor(ifelse(RegRank$ASPECT< 45, "0-45",
                       ifelse(RegRank$ASPECT< 90, "45-90",
                       ifelse(RegRank$ASPECT<135, "90-135",
                       ifelse(RegRank$ASPECT<180, "135-180",
                       ifelse(RegRank$ASPECT<225, "180-225",
                       ifelse(RegRank$ASPECT<270, "225-270",
                       ifelse(RegRank$ASPECT<315, "270-315", "315-360"))))))),
                       levels= c("0-45", "45-90", "90-135", "135-180",
                                 "180-225","225-270","270-315","315-360"))
RRank <- spTransform(RegRank, CRS("+proj=longlat +ellps=WGS84"))
SSank <- as(RRank, "data.frame")
RRank$X= SSank$coords.x1
RRank$Y= SSank$coords.x2
RRank$AOCo <- factor(ifelse(RRank$GCRU== 1, "GCRU",
                     ifelse(RRank$PCRU== 1, "PCRU",
                     ifelse(RRank$VILL== 1 | RRank$COMM== 1, "VILL",
                     ifelse(RRank$BOUR== 1, "BOUR", "BGOR")))),
                     c("BGOR", "BOUR",
                       "VILL", "PCRU", "GCRU"))

aocavt <- c(levels(factor(RRank$Com39)), levels(factor(RRank$Cote39)),
            levels(factor(RRank$Com38)), levels(factor(RRank$Com37)),
            levels(factor(RRank$Com36)))

equiv <- c("Auxey_Duresses"= 3,                   
           "Batard_Montrachet"= 5,                        
           "Bienvenues_Batard_Montrachet"= 5,             
           "Chassagne_Montrachet"= 3,                     
           "Chevalier_Montrachet"= 5,                     
           "Chorey_les_Beaune"= 3,                        
           "Clos_de_Tart"= 5,                             
           "Criots_Batard_Montrachet"= 5,                 
           "Ladoix"= 3,                                   
           "Meursault"= 3,                                
           "Monthelie"= 3,
           "Morey_Saint_Denis"= 3,                        
           "NONE"= 0,                                     
           "Pernand_Vergelesses"= 3,                      
           "Puligny_Montrachet"= 3,                       
           "Saint_Aubin"= 3,                              
           "Santenay"= 3,                                 
           "Savigny"= 3,                                  
           "Volnay"= 3,
           "Volnay_Santenots"= 3, ## ATTENTION
           "Beaune"= 3,
           "Chorey"= 3,
           "Meursault_Blagny"= 3,                         
           "Aloxe_Corton"= 3,
           "Vosne_Romanee"= 3,                            
           "Chambertin"= 5,                               
           "Chambertin_Clos_de_Beze"= 5,                  
           "Chapelle_Chambertin"= 5,                      
           "Charlemagne"= 5,                              
           "Charmes_Chambertin"= 5,                       
           "Clos_de_Vougeot"= 5,                          
           "Corton"= 5,                                   
           "Corton_Charlemagne"= 5,                       
           "Cote_de_Beaune_ou_Cote_de_Beaune_Villages"= 3,
           "Echezeaux"= 5,                                
           "Gevrey_Chambertin"= 3,                        
           "Grands_Echezeaux"= 5,                         
           "Griotte_Chambertin"= 5,
           "Latricieres_Chambertin"= 5,                   
           "Mazis_Chambertin"= 5,                         
           "Mazoyeres_Chambertin"= 5,                     
           "Montrachet"= 5,
           "Ruchottes_Chambertin"= 5,
           "Vins_fins_de_la_Cote_de_Nuits"= 0, ## ATTENTION            
           "Vougeot_rouge"= 3,
           "Bonnes_Mares"= 5,                             
           "Chambolle_Musigny"= 3,                        
           "Clos_de_la_Roche"= 5,
           "Clos_Saint_Denis"= 5,                         
           "Fixin"= 3,
           "La_Tache"= 5,                                 
           "Musigny"= 5,
           "Nuits"= 3,
           "Pommard"= 3,                                  
           "Richebourg"= 5,                               
           "Romanee"= 5,                            
           "Romanee_Conti"= 5,                            
           "Romanee_Saint_Vivant"= 5,                     
           "Vougeot"= 3)

library(plyr)
RRank$AOC39 <- revalue(factor(RRank$Com39), equiv)
RRank$aoc39 <- revalue(factor(RRank$Cote39), equiv)
RRank$AOC38 <- revalue(factor(RRank$Com38), equiv)
RRank$AOC37 <- revalue(factor(RRank$Com37), equiv)
RRank$AOC36 <- revalue(factor(RRank$Com36), equiv)

RRank$AOCavt <- apply(RRank@data[, 89: 93], 1, max)
RRank$AOCavt <- as.numeric(ifelse(RRank$AOCavt== "0", 1,
                           ifelse(RRank$AOCavt== "3", 2, 3)))

RRank$SELOLD <- ifelse(!RRank$LIBCOM %in%
                       c("CHENOVE", "MARSANNAY-LA-COTE", "COUCHEY",
                         "COMBLANCHIEN","CORGOLOIN", "SAINT-ROMAIN"), 1, 0)
SRank <- subset(RRank, SELOLD== 1)
SRank$LIBCOM <- factor(SRank$LIBCOM)
#+end_src

*** Encore plus ancien                       :noexport:

#+begin_src R
RegRank <- subset(AocRank@data, AocRank$PAOC!= 0 &
                  !is.na(AocRank$DEM) & !is.na(AocRank$CODEg))
RegRank$AOCc <- ifelse(RegRank$GCRU== 1, 5,
                ifelse(RegRank$PCRU== 1, 4,
                ifelse(RegRank$VILL== 1 | RegRank$COMM== 1, 3,
                ifelse(RegRank$BOUR== 1, 2, 1))))
RegRank$RAYAT <- with(RegRank, (SOLAR- mean(SOLAR))/ sd(SOLAR))
RegRank$XREG  <- with(RegRank, (XL93-  mean(XL93))/  sd(XL93))
RegRank$YREG  <- with(RegRank, (YL93-  mean(YL93))/  sd(YL93))
RegRank$EXPO <- factor(ifelse(RegRank$ASPECT< 45, "0-45",
                       ifelse(RegRank$ASPECT< 90, "45-90",
                       ifelse(RegRank$ASPECT<135, "90-135",
                       ifelse(RegRank$ASPECT<180, "135-180",
                       ifelse(RegRank$ASPECT<225, "180-225",
                       ifelse(RegRank$ASPECT<270, "225-270",
                       ifelse(RegRank$ASPECT<315, "270-315", "315-360"))))))),
                       levels= c("0-45", "45-90", "90-135", "135-180",
                                 "180-225","225-270","270-315","315-360"))
RegRank$PERM <- factor(ifelse(RegRank$PERMEABILITY<= 1, "0",
                       ifelse(RegRank$PERMEABILITY<= 2, "1",
                       ifelse(RegRank$PERMEABILITY<= 3, "2", "3"))))
tmp <- table(RegRank$CODEg)< 500
RegRank$Cg5 <- factor(
    ifelse(RegRank$CODEg%in% c("Hydro","j5b-c","l2","LP","t7-l1","Uy","X"),
           "ZZZ", ifelse(RegRank$CODEg %in% levels(RegRank$CODEg)[ tmp],
                         "0AREF", as.character(RegRank$CODEg))))
table(RegRank$Cg5)
tmp <- table(RegRank$CODEp)< 1000
RegRank$Cp10 <- factor(
    ifelse(RegRank$CODEp %in% c(1, 10, 17, 41), "ZZZ",
    ifelse(RegRank$CODEp %in% levels(RegRank$CODEp)[ tmp], "0AREF",
           as.character(RegRank$CODEp))))
table(RegRank$Cp10)

#+end_src

** Models of GI designation
*** Parametric ordered logit

   Benchmark parametric ordered logistic model

#+begin_src R :wrap example
library(MASS)
por1 <- polr(factor(AOCc)~ 0+ LIBCOM+ EXPO
             + poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
             + poly(X, 3)* poly(Y, 3), data= Reg.Rank, Hess= TRUE)
por1a <- polr(factor(AOCc)~ 0 + EXPO
              + poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
              + poly(X, 3)* poly(Y, 3), data= Reg.Rank, Hess= TRUE)
por1b <- polr(factor(AOCc)~ 0+ LIBCOM+ EXPO
              + poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
            , data= Reg.Rank, Hess= TRUE)
#+end_src

#+RESULTS:
#+begin_example
Warning messages:
1: In polr(factor(AOCc) ~ 0 + LIBCOM + EXPO + poly(DEM, 2) + poly(SLOPE,  :
  une coordonnée à l'origine est nécessaire et assumée
2: In polr(factor(AOCc) ~ 0 + LIBCOM + EXPO + poly(DEM, 2) + poly(SLOPE,  :
  le plan ne semble pas de rang plein, des coefs seront ignorés
#+end_example

   Why warning message can be omitted.

*** Ordered generalized additive 

   The loop that allow to create the gamod object, the results of the
   models.  I advice to not run the loop but to pick some value for
   the maximum degree of freedom and run the models individually.

#+begin_src R :wrap example
library(mgcv)
listk <- c(50, 100, 200, 300, 400, 500, 600, 700, 800, 900)
gamod <- vector("list", length(listk))
system.time(
for (i in 1: length(listk)){
    gamod[[ i]] <- gam(AOCc~ 0+ LIBCOM+ EXPO+ s(DEM)+ s(SLOPE)+ s(RAYAT)
                       + s(X, Y, k= listk[ i])
                     , data= Reg.Rank, family= ocat(R= 5))
})
names(gamod) <- paste0("gam", listk)
save(gamod, file= "Inter/gamod.Rda")

gammod <- vector("list", length(listk))
system.time(
for (i in 1: length(listk)){
    gammod[[ i]] <- gam(AOCc~ 0+ EXPO+ s(DEM)+ s(SLOPE)+ s(RAYAT)
                        + s(X, Y, k= listk[ i])
                      , data= Reg.Rank, family= ocat(R= 5))
})
names(gammod) <- paste0("gam", listk)
save(gammod, file= "Inter/gammod.Rda")
#+end_src

#+RESULTS:
#+begin_example
utilisateur     système      écoulé 
    56177.4       384.9       56565 
utilisateur     système      écoulé 
    42413.2       262.8     42679.6
#+end_example

** Diagnostics
*** Significance
**** POL                                     :noheading:

#+begin_src R :wrap example
library(car)
res1a <- anova(por1, por1b)
(res1 <- Anova(por1))
#+end_src

#+RESULTS:
#+begin_example
Analysis of Deviance Table (Type II tests)

Response: factor(AOCc)
                      LR Chisq Df Pr(>Chisq)    
LIBCOM                   14625 31     <2e-16 ***
EXPO                      1212  7     <2e-16 ***
poly(DEM, 2)              5334  2     <2e-16 ***
poly(SLOPE, 2)             385  2     <2e-16 ***
poly(RAYAT, 2)            1921  2     <2e-16 ***
poly(X, 3)                2478  3     <2e-16 ***
poly(Y, 3)                 639  3     <2e-16 ***
poly(X, 3):poly(Y, 3)     9555  9     <2e-16 ***
---
codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#+end_example

**** OGAM                                    :noheading:

#+begin_src R :wrap example
load("Inter/gamod.Rda")
resume <- function(mod){
    tmp <- anova(mod)
    res <- c(as.vector(rbind(tmp$s.table[, 3], tmp$s.table[, 1])),
             as.vector(rbind(tmp$pTerms.tab[, 2], tmp$pTerms.tab[, 1])))
    names(res) <- c(as.vector(rbind(rownames(tmp$s.table), rep("", 4))),
                    as.vector(rbind(rownames(tmp$pTerms.tab), rep("", 2))))
    round(res, 1)
}
sapply(gamod[ 1: 5* 2], resume)
#+end_src

#+RESULTS:
#+begin_example
          gam100  gam300  gam500   gam700   gam900
s(DEM)    5020.2  2385.4  1677.7   1692.6   1766.8
             9.0     8.9     8.8      8.8      8.8
s(SLOPE)  1281.1   458.2   266.1    225.3    243.6
             8.5     8.5     8.5      8.4      8.4
s(RAYAT)  2491.6  1196.5   667.3    554.7    557.9
             8.3     8.2     7.7      7.6      7.5
s(X,Y)   41458.2 73705.5 94094.8 103941.0 107522.8
            98.7   295.2   483.1    666.7    844.7
LIBCOM    6793.2  6079.7  4594.7   3555.0   2894.5
            31.0    31.0    31.0     31.0     31.0
EXPO       110.3   123.2   222.3    153.5    160.8
             7.0     7.0     7.0      7.0      7.0
#+end_example

*** Goodness of fit
**** POL                                     :noheading:

#+begin_src R :wrap example
psR2 <- function(x) 1- (logLik(x)/ logLik(update(x, . ~ + 1)))
round(c(psR2(por1), AIC(por1)/ 1000,
        sum(diag(table(predict(por1), Reg.Rank$AOCc)))/nrow(Reg.Rank)), 2)
#+end_src

#+RESULTS:
#+begin_example
[1]   0.29 119.40   0.59
#+end_example

**** OGAM                                    :noheading:

#+begin_src R :wrap example
library(mgcv)
pcgp <- function(x){
    sum(diag(table(cut(x$line, c(-Inf, x$family$getTheta(TRUE), Inf)),
                   x$model[, 1])))/ nrow(x$model)* 100
}

rbind(sapply(gamod[ 1: 5* 2], pcgp), sapply(gamod[ 1: 5* 2], AIC))
#sapply(gamod, psR2)
#+end_src

#+RESULTS:
#+begin_example
       gam100   gam300   gam500   gam700   gam900
[1,]    73.89    79.94    84.23    86.94    89.15
[2,] 82412.10 64710.89 54941.54 48291.33 43535.14
#+end_example

*** Omitted variable
**** POL                                     :noheading:

#+begin_src R :wrap example
library(lmtest) ; library(sandwich) ; library(sure)
wal1 <- 0 ; nsim= 100 
for (i in 1: nsim){
    tmp <- surrogate(por1a)- por1a$lp
    wal1[ i] <- waldtest(lm(tmp~ Reg.Rank$LIBCOM), . ~ 1, vcov= vcovHC)$F[ 2]
}
quantile(wal1, c(.05, .5, .95))
#+end_src

#+RESULTS:
#+begin_example
   5%   50%   95% 
268.0 274.2 279.6
#+end_example

**** OGAM                                    :noheading:

     A passer en Reg.Rank, introduire la fonction sur les surrogate
     residuals des modèles gams en annexe.

#+begin_src R :wrap example
load("Inter/gammod.Rda") ; source("myFcts.R")
omitVar <- function(mod, nsim= 100, old= F){
    usq <- 0
    if (!old) COM <- RRank$LIBCOM else COM <- SRank$LIBCOM 
    for(i in 1: nsim) {
        if (!old) RES <- surlGAM(mod) else RES <- suroldGAM(mod) 
        tmp <- lm(I(RES- mod$linear.pred)~ COM) 
        usq[ i] <- waldtest(tmp, . ~ 1, vcov= vcovHC)$F[ 2]
    }
    usq
}
wal2 <- sapply(gammod, omitVar)
apply(wal2[, 1: 5* 2], 2, function(x) quantile(x, c(.05, .5, .95)))
#+end_src

#+RESULTS:
#+begin_example
    gam100 gam300 gam500 gam700 gam900
5%   17.38  6.060  3.377  2.004  1.704
50%  18.94  6.806  4.130  2.525  2.181
95%  20.15  7.746  4.864  3.060  2.760
#+end_example

**** Plot                                    :noheading:

#+begin_src R :results graphics :height 7 :width 10 :file "./Figures/SignifPlot.pdf"
library(lattice)
pltdat <- stack(data.frame(logit= wal1, wal2))
bwplot(values~ ind, data= pltdat, type=c("l","g"), horizontal= FALSE,
       xlab='Model of GI designation', ylab='Bootstraped F-statistics',
       par.settings = list(box.rectangle=list(col='black'),
                           plot.symbol = list(pch='.', cex = 0.1)),
       scales=list(y= list(log= TRUE)),
       panel = function(..., box.ratio) {
           panel.grid(h= -1, v = -11)
           panel.violin(..., col = "lightblue",
                        varwidth = FALSE, box.ratio = box.ratio)
           panel.bwplot(..., col='black',
                        cex=0.8, pch='|', fill='gray', box.ratio = .1)
           panel.abline(h= log(1.47), col= "red", lty= 3)
           panel.text(2, log(1.55), "F= 1.47: critical value at 5%")})
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .5
#+RESULTS:
[[file:./Figures/SignifPlot.pdf]]

*** Specification
**** POL                                     :noheading:

     Surrogate residuals can also be used to test specification,
     results not reported. 

#+begin_src R :exports code :results graphics :height 7 :width 12 :file "./Figures/Surrogate.pdf"
library(sure) ; library(ggplot2) ; library(gridExtra)
var <- c("DEM", "SLOPE", "RAYAT", "EXPO", "LIBCOM", "X", "Y")
plots <- lapply(var, function(.x)
    autoplot(por1, what= "covariate", x= RRank@data[, .x], xlab= .x))
(atp <- autoplot(por1, what= "qq"))
do.call(grid.arrange, c(list(atp), plots))
#+end_src

#+CAPTION: Surrogate for the model XX
#+ATTR_LATEX: :options scale= .5
#+RESULTS:
[[file:./Figures/Surrogate.pdf]]

**** OGAM                                    :noheading:

     Introducing =pltSURE= function.

#+begin_src R :exports code :results graphics :height 7 :width 12 :file "./Figures/Surrogateb.pdf"
restmp <- surlGAM(gamod$gam900)- gamod$gam900$line 
plot(qlogis(1: nrow(RRank)/ nrow(RRank), scale= 1), sort(restmp))
abline(0, 1)
par(mfrow= c(3, 3)) ; for (i in var) pltSURE(restmp, RRank@data[, i], i)
#+end_src

#+CAPTION: Surrogate for the model XX
#+RESULTS:
[[file:./Figures/Surrogateb.pdf]]

** Marginal effects
*** Parametric ordered logit

#+begin_src R :results graphics :height 7 :width 12 :file "./Figures/Effects1.pdf"
library(effects)
plot(predictorEffects(por1, ~ DEM+ SLOPE+ RAYAT+ EXPO, latent= TRUE,
                      xlevels=list(DEM= 200: 500,
                                   SLOPE= 0: 400/ 10, RAYAT= -60: 30/ 10)))
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .5
#+RESULTS:
[[file:./Figures/Effects1.pdf]]

*** Ordered generalized additive

    On voit bien que le lissage est le même que le papier.

#+begin_src R :results graphics :height 9 :width 15 :file "./Figures/Effects2.pdf"
plot(gamod$gam100, pages= 1, scale= 0)
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .4
#+RESULTS:
[[file:./Figures/Effects2.pdf]]

*** Ordinal superiority figure

#+begin_src R :results graphics :height 6 :width 9 :file "./Figures/ComEff.pdf"
library(latticeExtra)
plogi <- function(x) exp(x/ sqrt(2))/ (1+ exp(x/ sqrt(2)))
xx <- data.frame(sapply(gamod, function(x)
    2* plogi(I(x$coeff[ 4: 31]- mean(x$coeff[ 4: 31])))- 1))
ww <- data.frame(xx,
                 LIBCOM= substr(names(gamod[[1]]$coef[ 4: 31]), 7, 30),
                 MIN= apply(xx[ 7: 10], 1, min),
                 MAX= apply(xx[ 7: 10], 1, max),
                 MEAN= apply(xx[ 7: 10], 1, mean))
segplot(reorder(factor(LIBCOM), MEAN)~ MIN+ MAX, length= 5, draw.bands= T,
        data= ww[order(ww$MEAN), ], center= MEAN, type= "o",
        unit = "mm", axis = axis.grid, col.symbol= "black", cex= 1, 
        xlab= "Min, Mean and Max of Ordinal Superiorty Measures")
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .6
#+RESULTS:
[[file:./Figures/ComEff.pdf]]

*** Correlation between /Communes/

#+begin_src R :results graphics :height 6 :width 9 :file "./Figures/ComCor.pdf"
library(plyr) ; library(ggrepel)
yy <- ddply(RRank@data, .(LIBCOM),
            function(x) weighted.mean(x$AOCc, x$Area))
zz <- merge(ww, yy, by= "LIBCOM")
m <- lm(V1~ MEAN, data= zz)
a <- signif(coef(m)[1], digits = 2)
b <- signif(coef(m)[2], digits = 2)
c <- signif(summary(m)$r.sq, digits = 2)
textlab <- paste("y = ", a, " + ", b, " x ", ", R2 = ", c, sep= "")
ggplot(zz, aes(MEAN, V1, label= LIBCOM)) +
    geom_smooth(method= lm, aes(MEAN, V1))+
    geom_text_repel(point.padding = NA) +
    annotate("text", x= -.75, y= 4, label= textlab, size= 4, parse= F)+
    xlab("Reputation (ordinal superiority)") +
    ylab("Average GI grade (between 0 and 5)")
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .6
#+RESULTS:
[[file:./Figures/ComCor.pdf]]

** Decomposition

   see appendix for the code of decompositions, latent un peu long à
   tourner.

#+begin_src R :wrap example
load("Inter/gamod.Rda") ; source("myFcts.R")
## latent <- sapply(gamod[ 1: 5* 2], function(x)
##     rowSums(predict(x, type= 'terms')[, -1]))
decomp <- apply(latent, 2, function(x)
    c(Signal= var(x), Noise= pi^2/ 3, jointSignal(x), jointNoise(x),
      rankSignal(x), rankResid(x), rankNoise(x),
      comSignal(x), comResid(x), comNoise(x)))
round(t(t(decomp)/ (pi^2/ 3+ decomp[1, ]))* 100, 1)
#+end_src

#+RESULTS:
#+begin_example
              gam100 gam300 gam500 gam700 gam900
Signal          84.8   94.7   95.9   96.8   97.6
Noise           15.2    5.3    4.1    3.2    2.4
Joint Signal    68.9   78.5   76.0   77.9   78.7
Joint Noise     16.0   16.2   20.0   18.9   18.9
Rank Signal     55.1   40.3   56.8   61.3   57.6
Rank Residual   13.8   38.2   19.2   16.5   21.2
Rank Noise      29.7   54.4   39.1   35.4   40.0
Com Signal      21.3   37.2   24.6   27.5   29.1
Com Residual    47.6   41.3   51.4   50.4   49.7
Com Noise       63.5   57.5   71.3   69.3   68.5
#+end_example

*** Olds Codes                               :noexport:

#+begin_src R
decomp(por1, RegRank)

## GENERAL NOISE
(noise1 <- 1/ (var(por1$lp)+ 1))

## RANKING NOISE FULL
dn1 <- var(por1$lp[RegRank$AOCc== 1])* mean(RegRank$AOCc== 1)+
    var(por1$lp[RegRank$AOCc== 2])*    mean(RegRank$AOCc== 2)+
    var(por1$lp[RegRank$AOCc== 3])*    mean(RegRank$AOCc== 3)+
    var(por1$lp[RegRank$AOCc== 4])*    mean(RegRank$AOCc== 4)+
    var(por1$lp[RegRank$AOCc== 5])*    mean(RegRank$AOCc== 5)
(discr1 <- dn1/ (var(por1$lp)+ 1))
## RANKING SIGNAL
1- noise1- discr1
siglvl1 <- var(ifelse(RegRank$AOCc== 1, mean(por1$lp[RegRank$AOCc== 1]),
               ifelse(RegRank$AOCc== 2, mean(por1$lp[RegRank$AOCc== 2]),
               ifelse(RegRank$AOCc== 3, mean(por1$lp[RegRank$AOCc== 3]),
               ifelse(RegRank$AOCc== 4, mean(por1$lp[RegRank$AOCc== 4]),
                      mean(por1$lp[RegRank$AOCc== 5]))))))/(var(por1$lp)+1)
siglvl1

(rr= summary(rrr <- lm(por1$lp~ factor(RegRank$AOCc)))$r.sq)* (1- noise1)
(1- rr)* (1- noise1)

## RANKING RESIDUALS
discret <- 0
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        tmp <- por1$lp[RegRank$AOCc== i & RegRank$LIBCOM== j]
        if (length(tmp)> 0)
        discret <- discret+
            var(tmp)* mean(RegRank$AOCc== i & RegRank$LIBCOM== j)
    }
}
(discr2 <- discret/ (var(por1$lp)+ 1))
## RANKING NOISE II
1- noise1-discr2-siglvl1
sig <- rep(0, nrow(RegRank))
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        sig[RegRank$AOCc== i & RegRank$LIBCOM== j] <-
            mean(por1$lp[RegRank$AOCc== i & RegRank$LIBCOM== j])
    }
}
sigg <- 0
for (j in levels(RegRank$LIBCOM)){
    sigg <- sigg+ var(sig[RegRank$LIBCOM== j])* mean(RegRank$LIBCOM== j)
}
(siglvl3 <- sigg/ (var(por1$lp)+ 1))



RR= summary(lm(rrr$resid~ 0+ factor(RegRank$LIBCOM)))$r.sq
RR* (1- noise1)



jj= summary(lm(linp~ factor(dat$AOCc)+ dat$LIBCOM))$r.sq

    cc= summary(ccc <- lm(linp~ factor(dat$LIBCOM)))$r.sq
    CC= summary(lm(ccc$resid~ factor(dat$AOCc)))$r.sq
    c(G.Signal= sgn, G.Noise= 1- sgn, J.Signal= jj, J.Noise= 1- jj,
      R.Signal= rr, R.Residual= RR, R.Noise= 1- rr- RR,
      C.Signal= cc, C.Residual= CC, C.Noise= 1- cc- CC)* 100

##
## POUR GAM1
##
decomp(gam1, RegRank)

gam3lp <- gam1$linear.predictors
## NOISE
(noise3 <- (pi^2/ 3)/ (var(gam3lp)+ (pi^2/ 3)))



## RANK NOISE FULL
dn3 <- var(gam3lp[RegRank$AOCc== 1])* mean(RegRank$AOCc== 1)+
    var(gam3lp[RegRank$AOCc== 2])*    mean(RegRank$AOCc== 2)+
    var(gam3lp[RegRank$AOCc== 3])*    mean(RegRank$AOCc== 3)+
    var(gam3lp[RegRank$AOCc== 4])*    mean(RegRank$AOCc== 4)+
    var(gam3lp[RegRank$AOCc== 5])*    mean(RegRank$AOCc== 5)
(discr3 <- dn3/ (var(gam3lp)+ (pi^2/ 3)))


## RANKING SIGNAL
1- noise3- discr3
siglvl3 <- var(ifelse(RegRank$AOCc== 1, mean(gam3lp[RegRank$AOCc== 1]),
               ifelse(RegRank$AOCc== 2, mean(gam3lp[RegRank$AOCc== 2]),
               ifelse(RegRank$AOCc== 3, mean(gam3lp[RegRank$AOCc== 3]),
               ifelse(RegRank$AOCc== 4, mean(gam3lp[RegRank$AOCc== 4]),
                      mean(gam3lp[RegRank$AOCc== 5]))))))/
    (var(gam3lp)+ (pi^2/ 3))
siglvl3

## RANKING RESIDUALS
discret <- 0
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        tmp <- gam3lp[RegRank$AOCc== i & RegRank$LIBCOM== j]
        if (length(tmp)> 0)
        discret <- discret+
            var(tmp)* mean(RegRank$AOCc== i & RegRank$LIBCOM== j)
    }
}
(discr4 <- discret/ (var(gam3lp)+ (pi^2/ 3)))
RR= summary(lm(rrr$resid~ 0+ factor(RegRank$LIBCOM)))$r.sq
RR
0.2607* (1- noise3)


## SIGNAL LEVEL
siglvl4 <- var(ifelse(RegRank$AOCc== 1, mean(gam3lp[RegRank$AOCc== 1]),
               ifelse(RegRank$AOCc== 2, mean(gam3lp[RegRank$AOCc== 2]),
               ifelse(RegRank$AOCc== 3, mean(gam3lp[RegRank$AOCc== 3]),
               ifelse(RegRank$AOCc== 4, mean(gam3lp[RegRank$AOCc== 4]),
                      mean(gam3lp[RegRank$AOCc== 5]))))))/
    (var(gam3lp)+ (pi^2/ 3))
siglvl4

sig <- rep(0, nrow(RegRank))
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        sig[RegRank$AOCc== i & RegRank$LIBCOM== j] <-
            mean(gam3lp[RegRank$AOCc== i & RegRank$LIBCOM== j])
    }
}
sigg <- 0
for (j in levels(RegRank$LIBCOM)){
    sigg <- sigg+ var(sig[RegRank$LIBCOM== j])* mean(RegRank$LIBCOM== j)
}
(siglvl5 <- sigg/ (var(gam3lp)+ (pi^2/ 3)))

## SIGNAL COMMUNE
siggg <- (var(sig[RegRank$AOCc== 1])* mean(RegRank$AOCc== 1)+
          var(sig[RegRank$AOCc== 2])* mean(RegRank$AOCc== 2)+
          var(sig[RegRank$AOCc== 3])* mean(RegRank$AOCc== 3)+
          var(sig[RegRank$AOCc== 4])* mean(RegRank$AOCc== 4)+
          var(sig[RegRank$AOCc== 5])* mean(RegRank$AOCc== 5))
(sigcom4 <- siggg/ (var(gam3lp)+ (pi^2/ 3)))

sigggg <- rep(0, nrow(RegRank))
for (j in levels(RegRank$LIBCOM)){
    sigggg[ RegRank$LIBCOM== j] <- mean(gam3lp[RegRank$LIBCOM== j])
}
(sigcom5 <- var(sigggg)/ (var(gam3lp)+ (pi^2/ 3)))


sigcom4+ noise4+ discr4+ siglvl4
sigcom4 ; noise4 ; discr4 ; siglvl4

sigcom5+ noise4+ discr4+ siglvl5
sigcom5 ; noise4 ; discr4 ; siglvl5




discret <- 0
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        tmp <- gam4lp[RegRank$AOCc== i & RegRank$LIBCOM== j]
        if (length(tmp)> 0)
        discret <- discret+
            var(tmp)* mean(RegRank$AOCc== i & RegRank$LIBCOM== j)
    }
}
(discr4 <- discret/ (var(gam4lp)+ 1))

## SIGNAL LEVEL
siglvl4 <- var(ifelse(RegRank$AOCc== 1, mean(gam4lp[RegRank$AOCc== 1]),
               ifelse(RegRank$AOCc== 2, mean(gam4lp[RegRank$AOCc== 2]),
               ifelse(RegRank$AOCc== 3, mean(gam4lp[RegRank$AOCc== 3]),
               ifelse(RegRank$AOCc== 4, mean(gam4lp[RegRank$AOCc== 4]),
                      mean(gam4lp[RegRank$AOCc== 5]))))))/(var(gam4lp)+1)
siglvl4

sig <- rep(0, nrow(RegRank))
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        sig[RegRank$AOCc== i & RegRank$LIBCOM== j] <-
            mean(gam4lp[RegRank$AOCc== i & RegRank$LIBCOM== j])
    }
}
sigg <- 0
for (j in levels(RegRank$LIBCOM)){
    sigg <- sigg+ var(sig[RegRank$LIBCOM== j])* mean(RegRank$LIBCOM== j)
}
(siglvl5 <- sigg/ (var(gam4lp)+ 1))

## SIGNAL COMMUNE
siggg <- (var(sig[RegRank$AOCc== 1])* mean(RegRank$AOCc== 1)+
          var(sig[RegRank$AOCc== 2])* mean(RegRank$AOCc== 2)+
          var(sig[RegRank$AOCc== 3])* mean(RegRank$AOCc== 3)+
          var(sig[RegRank$AOCc== 4])* mean(RegRank$AOCc== 4)+
          var(sig[RegRank$AOCc== 5])* mean(RegRank$AOCc== 5))
(sigcom4 <- siggg/ (var(gam4lp)+ 1))

sigggg <- rep(0, nrow(RegRank))
for (j in levels(RegRank$LIBCOM)){
    sigggg[ RegRank$LIBCOM== j] <- mean(gam4lp[RegRank$LIBCOM== j])
}
(sigcom5 <- var(sigggg)/ (var(gam4lp)+ 1))


sigcom4+ noise4+ discr4+ siglvl4
sigcom4 ; noise4 ; discr4 ; siglvl4

sigcom5+ noise4+ discr4+ siglvl5
sigcom5 ; noise4 ; discr4 ; siglvl5














discret <- 0
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        tmp <- por2$lp[RegRank$AOCc== i & RegRank$LIBCOM== j]
        if (length(tmp)> 0)
        discret <- discret+
            var(tmp)* mean(RegRank$AOCc== i & RegRank$LIBCOM== j)
    }
}
(discr2 <- discret/ (var(por2$lp)+ 1))


sig <- rep(0, nrow(RegRank))
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        sig[RegRank$AOCc== i & RegRank$LIBCOM== j] <-
            mean(por1$lp[RegRank$AOCc== i & RegRank$LIBCOM== j])
    }
}
sigg <- 0
for (j in levels(RegRank$LIBCOM)){
    sigg <- sigg+ var(sig[RegRank$LIBCOM== j])* mean(RegRank$LIBCOM== j)
}
(siglvl3 <- sigg/ (var(por2$lp)+ 1))


## SIGNAL LEVELS
siglvl2 <- var(ifelse(RegRank$AOCc== 1, mean(por2$lp[RegRank$AOCc== 1]),
               ifelse(RegRank$AOCc== 2, mean(por2$lp[RegRank$AOCc== 2]),
               ifelse(RegRank$AOCc== 3, mean(por2$lp[RegRank$AOCc== 3]),
               ifelse(RegRank$AOCc== 4, mean(por2$lp[RegRank$AOCc== 4]),
                      mean(por2$lp[RegRank$AOCc== 5]))))))/(var(por2$lp)+1)
siglvl2

sig <- rep(0, nrow(RegRank))
for (i in 1: 5){
    for (j in levels(RegRank$LIBCOM)){
        sig[RegRank$AOCc== i & RegRank$LIBCOM== j] <-
            mean(por2$lp[RegRank$AOCc== i & RegRank$LIBCOM== j])
    }
}
sigg <- 0
for (j in levels(RegRank$LIBCOM)){
    sigg <- sigg+ var(sig[RegRank$LIBCOM== j])* mean(RegRank$LIBCOM== j)
}
(siglvl3 <- sigg/ (var(por2$lp)+ 1))

## SIGNAL COMMUNE
siggg <- (var(sig[RegRank$AOCc== 1])* mean(RegRank$AOCc== 1)+
          var(sig[RegRank$AOCc== 2])* mean(RegRank$AOCc== 2)+
          var(sig[RegRank$AOCc== 3])* mean(RegRank$AOCc== 3)+
          var(sig[RegRank$AOCc== 4])* mean(RegRank$AOCc== 4)+
          var(sig[RegRank$AOCc== 5])* mean(RegRank$AOCc== 5))
(sigcom2 <- siggg/ (var(por2$lp)+ 1))

sigggg <- rep(0, nrow(RegRank))
for (j in levels(RegRank$LIBCOM)){
    sigggg[ RegRank$LIBCOM== j] <- mean(por2$lp[RegRank$LIBCOM== j])
}
(sigcom3 <- var(sigggg)/ (var(por2$lp)+ 1))



sigcom2+ noise2+ discr2+ siglvl2
sigcom2 ; noise2 ; discr2 ; siglvl2

sigcom3+ noise2+ discr2+ siglvl3
sigcom3 ; noise2 ; discr2 ; siglvl3




library(mgcv)



gam3lp <- gam1$linear.predictors
gam4lp <- gam2$linear.predictors


#+end_src

** Models for 1936 GIs
*** Descriptive stats

#+begin_src R :wrap example
Reg.Old <- subset(Reg.Rank, !is.na(Reg.Rank$AOC36lvl) &
                  !Reg.Rank$LIBCOM %in%
                  c("CHENOVE", "MARSANNAY-LA-COTE", "COUCHEY",
                    "COMBLANCHIEN","CORGOLOIN", "SAINT-ROMAIN"))
Reg.Old$LIBCOM <- factor(Reg.Old$LIBCOM)
Reg.Old$AOCo <- as.numeric(ifelse(Reg.Old$AOC36lvl== "0", 1,
                           ifelse(Reg.Old$AOC36lvl== "3", 2, 3)))
table(Reg.Old$AOC36lvl, Reg.Old$AOCc)
#table(Reg.Old$LIBCOM, Reg.Old$AOCo)
#+end_src

#+RESULTS:
#+begin_example   
        1     2     3     4     5
  0  7204 12605  4120   567    39
  3    15   662 15378  8017   261
  5     0     1    13     3  1604
#+end_example

*** Estimation
**** POL                                     :noheading:

#+begin_src R :wrap example
library(MASS)
por2 <- polr(factor(AOCo)~ 0+ LIBCOM+ EXPO
             + poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
             + poly(X, 3)* poly(Y, 3), data= Reg.Old, Hess= T)
por2a <- polr(factor(AOCo)~ 0+ EXPO
              + poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
              + poly(X, 3)* poly(Y, 3), data= Reg.Old, Hess= T)
por2b <- polr(factor(AOCo)~ 0+ LIBCOM+ EXPO
              + poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
            , data= Reg.Old, Hess= T)
#+end_src

**** OGAM                                    :noheading:

#+begin_src R :wrap example
library(mgcv)
listk <- c(50, 75, 100, 150, 200, 250, 300)
gamold <- vector("list", length(listk))
system.time(
for (i in 1: length(listk)){
    gamold[[ i]] <- gam(AOCo~ 0+ LIBCOM+ EXPO+ s(DEM)+ s(SLOPE)+ s(RAYAT)
                        + s(X, Y, k= listk[ i])
                      , data= Reg.Old, family= ocat(R= 3))
})
names(gamold) <- paste0("gam", listk)
save(gamold, file= "Inter/gamold.Rda")

gammold <- vector("list", length(listk))
system.time(
for (i in 1: length(listk)){
    gammold[[ i]] <- gam(AOCo~ 0+ EXPO+ s(DEM)+ s(SLOPE)+ s(RAYAT)
                         + s(X, Y, k= listk[ i])
                       , data= Reg.Old, family= ocat(R= 3))
})
names(gammold) <- paste0("gam", listk)
save(gammold, file= "Inter/gammold.Rda")
#+end_src

#+begin_example
utilisateur     système      écoulé 
    12259.5       144.1     12405.5 
utilisateur     système      écoulé 
    9582.37       78.69     9661.62 
#+end_example

*** Significance

#+begin_src R :wrap example
load("Inter/gamold.Rda")
res2a <- anova(por2, por2b)
res2 <- Anova(por2)
sapply(gamold[ 3: 7], resume)
#+end_src

#+RESULTS:
#+begin_example
          gam100  gam150  gam200  gam250  gam300
s(DEM)     499.8   647.4   702.3   541.9   344.5
             8.5     8.2     8.8     8.4     7.7
s(SLOPE)   387.3   314.0   254.4   244.3   153.0
             8.7     8.7     8.6     8.6     8.3
s(RAYAT)   242.0   160.1   127.1   122.9   105.2
             8.5     8.3     8.1     5.0     5.9
s(X,Y)   17520.5 20194.2 22301.7 23507.2 23801.4
            98.3   146.3   194.4   239.8   286.6
LIBCOM    2782.5  1843.0  1642.4  1283.0  1049.4
            25.0    25.0    25.0    25.0    25.0
EXPO       119.8    91.8    91.9    96.1    90.2
             7.0     7.0     7.0     7.0     7.0
#+end_example

*** Goodness of fit

#+begin_src R :wrap example
round(c(psR2(por2), AIC(por2)/ 1000,
        sum(diag(table(predict(por2), Reg.Old$AOCo)))/ nrow(Reg.Old)), 2)
rbind(sapply(gamold, pcgp), sapply(gamold, AIC))
#sapply(gamold, psR2)
#+end_src

#+RESULTS:
#+begin_example
[1]  0.38 51.29  0.79
        gam50   gam75   gam100   gam150   gam200  gam250   gam300
[1,]    84.34    85.9    87.08    89.26    90.28    91.4    92.54
[2,] 40789.58 36833.3 33810.36 30271.01 27574.12 24526.6 22482.20
#+end_example

*** Omitted variable
**** Bootstrap                               :noheading:

#+begin_src R :wrap example
library(lmtest) ; library(sandwich) ; library(sure)
wal3 <- 0 ; nsim= 100
for (i in 1: nsim){
    tmp <- surrogate(por2a)- por2a$lp
    wal3[ i] <- waldtest(lm(tmp~ Reg.Old$LIBCOM), . ~ 1, vcov= vcovHC)$F[ 2]
}
load("Inter/gammold.Rda") ; source("myFcts.R")
wal4 <- sapply(gammold, function(x) omitVar(x, old= T))
wold <- data.frame(logit= wal3, wal4)
apply(wold, 2, function(x) quantile(x, c(.05, .5, .95)))
#+end_src

#+RESULTS:
#+begin_example
    logit gam50  gam75 gam100 gam150 gam200 gam250 gam300
5%  168.1 7.408  7.340  4.714  3.498  2.057  1.178  1.091
50% 173.6 8.553  8.843  5.894  4.310  2.709  1.832  1.488
95% 179.8 9.958 10.501  6.858  5.396  3.851  2.495  2.057
#+end_example

**** Plot                                    :noheading:

#+begin_src R :results graphics :height 7 :width 10 :file "./Figures/SignifPold.pdf"
library(lattice)
poldat <- stack(wold)
bwplot(values~ ind, data= poldat, type=c("l","g"), horizontal= FALSE,
       xlab='Model of GI designation', ylab='Bootstraped F-statistics',
       par.settings = list(box.rectangle=list(col='black'),
                           plot.symbol = list(pch='.', cex = 0.1)),
       scales=list(y= list(log= TRUE)),
       panel = function(..., box.ratio) {
           panel.grid(h= -1, v = -11)
           panel.violin(..., col = "lightblue",
                        varwidth = FALSE, box.ratio = box.ratio)
           panel.bwplot(..., col='black',
                        cex=0.8, pch='|', fill='gray', box.ratio = .1)
           panel.abline(h= log(1.47), col= "red", lty= 3)
           panel.text(2, log(1.55), "F= 1.47: critical value at 5%")})
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .5
#+RESULTS:
[[file:./Figures/SignifPold.pdf]]

*** Specification
**** POL                                     :noheading:

     results not reported

#+begin_src R :exports code :results graphics :height 7 :width 12 :file "./Figures/Surroldgate.pdf"
library(sure) ; library(ggplot2) ; library(gridExtra)
var <- c("DEM", "SLOPE", "RAYAT", "EXPO", "LIBCOM", "X", "Y")
plots <- lapply(var, function(.x)
    autoplot(por2, what= "covariate", x= Reg.Old@data[, .x], xlab= .x))
(atp <- autoplot(por2, what= "qq"))
do.call(grid.arrange, c(list(atp), plots))
#+end_src

#+CAPTION: Surrogate for the model XX
#+ATTR_LATEX: :options scale= .5
#+RESULTS:
[[file:./Figures/Surroldgate.pdf]]

**** OGAM                                    :noheading:

#+begin_src R :exports code :results graphics :height 7 :width 12 :file "./Figures/Surroldgateb.pdf"
restmp <- suroldGAM(gamold$gam300)- gamold$gam300$line 
plot(qlogis(1: nrow(SRank)/ nrow(SRank), scale= 1), sort(restmp))
abline(0, 1)
var <- c("DEM", "SLOPE", "RAYAT", "EXPO", "LIBCOM", "X", "Y")
par(mfrow= c(3, 3)) ; for (i in var) pltSURE(restmp, SRank@data[, i], i)
#+end_src

#+CAPTION: Surrogate for the model XX
#+ATTR_LATEX: :options scale= .5
#+RESULTS:
[[file:./Figures/Surroldgateb.pdf]]

*** Marginal effects

#+begin_src R :results graphics :height 7 :width 12 :file "./Figures/Effectsold.pdf"
library(effects)
plot(predictorEffects(por2, ~ DEM+ SLOPE+ RAYAT+ EXPO, latent= TRUE,
                      xlevels=list(DEM= 200: 500,
                                   SLOPE= 0: 400/ 10, RAYAT= -60: 30/ 10)))
plot(gamold$gam300, pages= 1, scale= 0)
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .4
#+RESULTS:
[[file:./Figures/Effectsold.pdf]]

*** /Commune/ effects

#+begin_src R :results graphics :height 6 :width 9 :file "./Figures/ComEffOld.pdf"
xxx <- data.frame(sapply(gamold, function(x)
    2* plogi(I(x$coeff[ 1: 25]- mean(x$coeff[ 1: 25])))- 1))
www <- data.frame(xxx,
                  LIBCOM= substr(names(gamold[[ 1]]$coef[ 1: 25]), 7, 30),
                  MIN= apply(xxx[ 6: 7], 1, min),
                  MAX= apply(xxx[ 6: 7], 1, max),
                  MEAN= apply(xxx[ 6: 7], 1, mean))
segplot(reorder(factor(LIBCOM), MEAN)~ MIN+ MAX, length= 5, draw.bands= T,
        data= www[order(www$MEAN), ], center= MEAN, type= "o",
        unit = "mm", axis = axis.grid, col.symbol= "black", cex= 1, 
        xlab= "Min, Mean and Max of Ordinal Superiorty Measures")
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .6
#+RESULTS:
[[file:./Figures/ComEffOld.pdf]]

*** Dynamic /Communes/

#+begin_src R :results graphics :height 7 :width 9 :file "./Figures/ComDyn.pdf"
zzz <- merge(ww, www, by= "LIBCOM")
segplot(reorder(factor(LIBCOM), MEAN.x)~ MEAN.y+ MEAN.x, data= zzz,
        segments.fun = panel.arrows, length = 2, unit = "mm",
        draw.bands= F, axis = axis.grid,
        xlab= "Rate of variation for ordinal superiority")
#+end_src

#+CAPTION: Effects of model XX
#+ATTR_LATEX: :options scale= .6
#+RESULTS:
[[file:./Figures/ComDyn.pdf]]

** Counterfactual decomposition
*** Decomposition 1936 GIs

#+begin_src R :wrap example
load("Inter/gamold.Rda") ; source("myFcts.R")
latold <- sapply(gamold, function(x)
    rowSums(predict(x, type= 'terms')[, -1]))
decold <- apply(latold, 2, function(x)
    c(Signal= var(x), Noise= pi^2/ 3,
      jointSignal2(x, vert= "AOCo", dat= SRank@data),
      jointNoise2(x, vert= "AOCo", dat= SRank@data),
      rankSignal2(x, vert= "AOCo", dat= SRank@data),
      rankResid2(x, vert= "AOCo", dat= SRank@data),
      rankNoise2(x, vert= "AOCo", dat= SRank@data),
      comSignal2(x, dat= SRank@data),
      comResid2(x, dat= SRank@data), comNoise2(x, dat= SRank@data)))
round(t(t(decold)/ (pi^2/ 3+ decold[1, ]))* 100, 1)
#+end_src

#+RESULTS:
#+begin_example
              gam50 gam75 gam100 gam150 gam200 gam250 gam300
Signal         95.6  93.1   95.4   98.7   98.1   99.5   99.5
Noise           4.4   6.9    4.6    1.3    1.9    0.5    0.5
Joint Signal   78.7  63.2   55.3   75.2   47.9   75.0   45.1
Joint Noise    16.9  29.9   40.2   23.5   50.3   24.5   54.5
Rank Signal     5.8  18.1   24.1   16.4   20.6   14.9   22.7
Rank Noise     89.8  75.0   71.3   82.4   77.5   84.6   76.8
Rank Residual  72.9  45.1   31.2   58.8   27.3   60.1   22.4
Com Signal     67.5  39.6   29.4   62.3   24.0   62.7   22.6
Com Noise      28.1  53.5   66.0   36.4   74.1   36.8   77.0
Com Residual   16.0  33.3   43.7   20.9   35.3   20.6   43.7
#+end_example

*** Alternative GI designations
**** Change in latent                        :noheading:

#+begin_src R :wrap example
# prdd <- predict(gamod$gam900, type= 'terms')
thsld <- c(-Inf, gamod$gam900$family$getTheta(TRUE), Inf)
ltt0 <- mean(prdd[, 1])+ rowSums(prdd[, -1])-
    (surlGAM(gamod$gam900)- gamod$gam900$line)
ltt1 <- rowSums(prdd)
ltt2 <- mean(prdd[, 1])+ rowSums(prdd[, -1])-
    (surlGAM(gamod$gam800)- gamod$gam800$line)
ltt3 <- mean(prdd[, 1])+ rowSums(prdd[, -1])
Simu <- data.frame(RRank, OLD= RRank$AOCavt, S0= cut(ltt0, thsld),
                   SI= cut(ltt1, thsld), SII= cut(ltt2, thsld),
                   SIII= cut(ltt3, thsld))
table(Simu$AOCc, Simu$S0) ; table(Simu$AOCc, Simu$SI)
table(Simu$AOCc, Simu$SII) ; table(Simu$AOCc, Simu$SIII)
#+end_src

#+RESULTS:
#+begin_example
               OLD  CF1  CF2  CF3  CF4  CF5  CF6
Signal        97.1 97.1 97.1 97.1 97.1 97.1 97.1
Noise          2.9  2.9  2.9  2.9  2.9  2.9  2.9
Joint Signal  51.4 80.1 81.2 82.2 79.4 80.0 79.2
Joint Noise   45.8 17.1 15.9 15.0 17.7 17.1 18.0
Rank Signal   38.9 70.7 64.5 73.5 62.2 62.8 62.0
Rank Noise    58.2 26.4 32.6 23.6 34.9 34.3 35.1
Rank Residual 12.5  9.4 16.7  8.7 17.2 17.2 17.2
Com Signal    28.5 28.5 28.5 28.5 28.5 28.5 28.5
Com Noise     68.6 68.6 68.6 68.6 68.6 68.6 68.6
Com Residual  22.9 51.6 52.7 53.7 50.9 51.5 50.7
#+end_example

**** Creation new level                      :noheading:

#+begin_src R :wrap example
thrldBOUR <- mean(ltt1[RRank$AOCc== 2])
thrldVILL <- mean(ltt1[RRank$AOCc== 3])
thrldPCRU <- mean(ltt1[RRank$AOCc== 4])
Simv <- data.frame(Simu,
                    SIV= ifelse(RRank$AOCc< 2, RRank$AOCc,
                         ifelse(RRank$AOCc== 2 & ltt< thrldBOUR, 2,
                         ifelse(RRank$AOCc== 2 & ltt>= thrldBOUR, 3,
                                RRank$AOCc+ 1))),
                    SV = ifelse(RRank$AOCc< 3, RRank$AOCc,
                         ifelse(RRank$AOCc== 3 & ltt< thrldVILL, 3,
                         ifelse(RRank$AOCc== 3 & ltt>= thrldVILL, 4,
                                RRank$AOCc+ 1))),
                    SVI= ifelse(RRank$AOCc< 4, RRank$AOCc,
                         ifelse(RRank$AOCc== 4 & ltt< thrldPCRU, 4,
                         ifelse(RRank$AOCc== 4 & ltt>= thrldPCRU, 5,
                                RRank$AOCc+ 1))))
table(Simv$AOCc, Simv$SIV)
table(Simv$AOCc, Simv$SV) ; table(Simv$AOCc, Simv$SVI)
#+end_src

#+RESULTS:
#+begin_example
   
        1     2     3     4     5     6
  1  9759     0     0     0     0     0
  2     0  8931  6577     0     0     0
  3     0     0     0 24151     0     0
  4     0     0     0     0  8577     0
  5     0     0     0     0     0  1906
   
        1     2     3     4     5     6
  1  9759     0     0     0     0     0
  2     0 15508     0     0     0     0
  3     0     0 13275 10876     0     0
  4     0     0     0     0  8577     0
  5     0     0     0     0     0  1906
   
        1     2     3     4     5     6
  1  9759     0     0     0     0     0
  2     0 15508     0     0     0     0
  3     0     0 24151     0     0     0
  4     0     0     0  4970  3607     0
  5     0     0     0     0     0  1906
#+end_example

**** Tabular                                 :noheading:

#+begin_src R :wrap example
decf <- sapply(names(Simv)[ 100: 107], function(x)
    c(Signal= var(rowSums(prdd[, -1])), Noise= pi^2/ 3,
      jointSignal2(rowSums(prdd[, -1]), vert= x, dat= Simv),
      jointNoise2(rowSums(prdd[, -1]), vert= x, dat= Simv),
      rankSignal2(rowSums(prdd[, -1]), vert= x, dat= Simv),
      rankResid2(rowSums(prdd[, -1]), vert= x, dat= Simv),
      rankNoise2(rowSums(prdd[, -1]), vert= x, dat= Simv),
      comSignal2(rowSums(prdd[, -1]), dat= Simv),
      comResid2(rowSums(prdd[, -1]), vert= x, dat= Simv),
      comNoise2(rowSums(prdd[, -1]), dat= Simv)))
(tabpap <- round(t(t(decf)/ (pi^2/ 3+ decf[1, ]))* 100, 1))
#+end_src

#+RESULTS:
#+begin_example
               OLD   S0   SI  SII SIII  SIV   SV  SVI
Signal        97.6 97.6 97.6 97.6 97.6 97.6 97.6 97.6
Noise          2.4  2.4  2.4  2.4  2.4  2.4  2.4  2.4
Joint Signal  43.3 81.1 80.7 81.2 82.8 79.2 79.6 79.0
Joint Noise   54.3 16.4 16.8 16.4 14.8 18.4 18.0 18.6
Rank Signal   17.8 70.7 59.8 70.7 73.1 58.0 58.5 57.9
Rank Residual 25.4 10.4 21.0 10.5  9.7 21.1 21.0 21.1
Rank Noise    79.7 26.8 37.8 26.8 24.5 39.5 39.0 39.7
Com Signal    29.1 29.1 29.1 29.1 29.1 29.1 29.1 29.1
Com Residual  14.2 52.1 51.7 52.1 53.7 50.1 50.5 49.9
Com Noise     68.5 68.5 68.5 68.5 68.5 68.5 68.5 68.5
#+end_example

**** Clearpage                               :noheading:

#+LATEX: \clearpage

** Robustness Checks                         :noexport:
*** Parallel assumption
**** By binary models

#+begin_src R
fit.glm1 <- glm(BOUR~ poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
                 + EXPO+ Cg5+ Cp10+ poly(XREG, 2)* poly(YREG, 2)
                 , data= RegRank, family= binomial(link= "logit"))
fit.glm2 <- glm(VILL~ poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
                + EXPO+ Cg5+ Cp10+ poly(XREG, 2)* poly(YREG, 2)
              , data= RegRank, family= binomial(link= "logit"))
fit.glm3 <- glm(PCRU~ poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
                + EXPO+ Cg5+ Cp10+ poly(XREG, 2)* poly(YREG, 2)
              , data= RegRank, family= binomial(link= "logit"))
fit.glm4 <- glm(GCRU~ poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
                + EXPO+ Cg5+ Cp10+ poly(XREG, 2)* poly(YREG, 2)
              , data= RegRank, family= binomial(link= "logit"))

gg <- surrogate(fit.glm1)

library(effects) ; library(latticeExtra)
a <- plot(Effect("DEM", fit.glm1))
b <- plot(Effect("DEM", fit.glm2))
d <- plot(Effect("DEM", fit.glm3))
e <- plot(Effect("DEM", fit.glm4))
c(a, b, d, e, y.same= T)

a <- plot(Effect("SLOPE", fit.glm1))
b <- plot(Effect("SLOPE", fit.glm2))
d <- plot(Effect("SLOPE", fit.glm3))
e <- plot(Effect("SLOPE", fit.glm4))
c(a, b, d, e, y.same= T)

a <- plot(Effect("RAYAT", fit.glm1))
b <- plot(Effect("RAYAT", fit.glm2))
d <- plot(Effect("RAYAT", fit.glm3))
e <- plot(Effect("RAYAT", fit.glm4))
c(a, b, d, e, y.same= T)

a <- plot(Effect("EXPO", fit.glm1))
b <- plot(Effect("EXPO", fit.glm2))
d <- plot(Effect("EXPO", fit.glm3))
e <- plot(Effect("EXPO", fit.glm4))
c(a, b, d, e, y.same= T)


surlGLM <- function(mod, newd= NULL){
    if (mod$family$link!= "logit") stop("Logit required")
    if (is.null(newd)){
        g1 <- as.integer(mod$y)
        g6 <- mod$linear.predictors
    } else {
        g1 <- as.integer(newd[, "AOCc"])
        g6 <- predict(mod, newdata= newd, type= "link")
    }
    nn <- length(g1)
    ifelse(g1== 0,
           rtrunc(nn, spec= "logis", a= -Inf, b= 0, location= g6,
                  scale= 1),
           rtrunc(nn, spec= "logis", a= 0, b= Inf, location= g6,
                  scale= 1))
}
sur1 <- surlGLM(fit.glm1)
ff1 <- sur1- mean(sur1)
sur2 <- surlGLM(fit.glm2)
ff2 <- sur2- mean(sur2)


sur3 <- surlGLM(fit.glm3)
ff3 <- sur3- mean(sur3)
sur4 <- surlGLM(fit.glm4)
ff4 <- sur4- mean(sur4)
plot(density(sur4))
xyplot(sur1 ~ RegRank$DEM, 
       type = c("p", "smooth"), col.line= "black")

xyplot(ff1- ff2 ~ RegRank$DEM, 
       type = c("p", "smooth"), col.line= "black")
xyplot(ff2- ff3 ~ RegRank$SLOPE, 
       type = c("p", "smooth"), col.line= "black")
xyplot(ff3- ff4 ~ RegRank$SLOPE, 
       type = c("p", "smooth"), col.line= "black")
xyplot(ff2- sur4 ~ RegRank$DEM, 
       type = c("p", "smooth"), col.line= "black")

#+end_src

**** By constrains on coefficients

#+begin_src R
table(RegRank$LIBCOM, RegRank$AOCc)
table(RegRank$LIBCOM, RegRank$AOChst)

yop <- resids(fit.polr)

yap <- surlOLR(fit.polr)
plot(yap- mean(yap), yop)

library(VGAM)
fit.vglm <- vglm(AOCo~ bs(DEM, 4)+ bs(SLOPE, 5)+ bs(ASPECT, 5)
                 + bs(RAYAT, 5)+ bs(PERMEABILITY, 4)
                 + bs(DISTCHF, 4)
                 + bs(XREG, 4)* bs(YREG, 4)
               , propodds, data= RegRank)
##                link= "Aranda-Ordaz",
##                control= list(method= "optim", iter.max= 1000,
##                              maxIter= 1000))
summary(fit.vglm)
autoplot(fit.vglm, what= "qq")

clist <- list("(Intercept)"= diag(4),
              "bs(DEM, 3)"= nctr, "SLOPE"= nctr,
              "poly(ASPECT, 2)"= nctr, "poly(RAYAT, 2)"= nctr,
              "poly(PERMEABILITY, 2)"= nctr,
              "poly(XREG, 2)"= nctr, "poly(YREG, 2)"= nctr,
              "poly(XREG, 2):poly(YREG, 2)"= nctr,
              "LIBCOM"= nctr2)
fit.vglm1 <- vglm(AOCo~ bs(DEM, 3)+ SLOPE+ poly(ASPECT, 2)
                  + poly(RAYAT, 2)+ poly(PERMEABILITY, 2)
                  + poly(XREG, 2)* poly(YREG, 2)
                  + LIBCOM
                , family= cumulative(reverse= T,
                                     parallel= FALSE~ 1+LIBCOM)
                , constraints= clist
                , data= RegRank)
(ctest <- constraints(fit.vglm1))

fit.vglm2 <- vglm(AOCo~ bs(DEM, 3)+ SLOPE+ poly(ASPECT, 2)
                  + poly(RAYAT, 2)+ poly(PERMEABILITY, 2)
                  + poly(XREG, 2)* poly(YREG, 2)
                  + LIBCOM
                , family= cumulative(reverse= T)
                , constraints= clist
                , data= RegRank)
constraints(fit.vglm2)
yap <- data.frame(predict(fit.vglm, type= "response"))
yup <- factor(names(yap)[apply(yap, 1, which.max)],
              ordered= T, levels= c("BGOR", "BOUR",
                                    "VILL", "PCRU", "GCRU"))
sum(diag(table(Y, yup)))/ nrow(RegRank)

coefficients(fit.rs, matrix= TRUE)
par(mfrow= c(1, 5))
plot(as(fit.rs, "vgam"), se = TRUE, scol = "blue", which.term= 2)
gg <- predict(fit.ss)
summary(gg)


autoplot(fit.vglm2, what= "qq")
autoplot(fit.vglm2, what= "covariate", x= RegRank$LIBCOM)+
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
coefficients(fit.vglm2, matrix= TRUE)
plot(gof(fit.vglm, nsim= 100, test= "ks"))

fit.clmr1 <- clm(AOCo~ poly(DEM, 2)+ poly(SLOPE, 2)+ poly(ASPECT, 2)
                + poly(RAYAT, 2)+ poly(PERMEABILITY, 2)
                + poly(DISTCHF, 2)
                + poly(XREG, 2)* poly(YREG, 2)
              , nominal= ~ DEM,
              , scale= ~ DEM+ SLOPE+ ASPECT+ RAYAT+ DISTCHF
              , data= RegRank
              , control= list(method= "Newton", maxIter= 1000L, 
                              maxLineIter= 1000L))
nominal_test(fit.clmr1)
summary(fit.clmr1)
anova(fit.clmr1, fit.clmr)

fit.molr4 <- vglm(AOCo~ poly(DEM, 2)+ SLOPE,
                  family= cumulative(link= probit, reverse= TRUE),
                  data= RankReg)
anova(fit.molr3, fit.molr4, type= "I")
1- pchisq(deviance(fit.molr3)- deviance(fit.molr4),
          df= df.residual(fit.molr3)- df.residual(fit.molr4))
hdeff(fit.molr)


#+end_src

**** By surrogate

#+begin_src R
prldat1 <- RegRank
table(prldat1$AOCc <- ifelse(prldat1$AOCc> 3, 3, prldat1$AOCc))
por1a <- polr(factor(AOCc)~ bs(DEM, 3)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
              + EXPO+ Cg5+ Cp10+ poly(XREG, 2)* poly(YREG, 2)
            , data= prldat1, Hess= TRUE)

prldat2 <- RegRank
table(prldat2$AOCc <- ifelse(prldat1$AOCc< 3, 3, prldat2$AOCc))
por1b <- polr(factor(AOCc)~ bs(DEM, 3)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
              + EXPO+ Cg5+ Cp10+ poly(XREG, 2)* poly(YREG, 2)
            , data= prldat2, Hess= TRUE)


s1 <- surrogate(por1a)
s2 <- surrogate(por1b)
library(ggplot2)
ggplot(data.frame(D = s1 - s2- mean(s1 - s2),
                  x = RegRank$DEM) , aes(x = x, y = D)) +
geom_point(color = "#444444", shape = 19, size = 2) +
geom_smooth(se = FALSE, size = 1.2, color = "red")

summary(por1a)
summary(por1b)
gg1 <- surlOLR(por1)
, newd= prldat1)
gg2 <- surlOLR(por2)
, newd= prldat2)

plot(RegRank$DEM, gg1- gg2)
#+end_src

*** Specification

    attention geologie/ pedologie

#+begin_src R
library(ordinalNet)

library(splines)
eq1 <- factor(AOCc)~  CODEp+ CODEg+ bs(XREG, 10)* bs(YREG, 10)+
    (poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2))* EXPO+ LIBCOM

fit.onet <- ordinalNet(model.matrix(eq1, data= RegRank),
                       factor(RegRank$AOCc),
                       family= "cumulative", reverse= T, link= "logit")
fit.onet
ss <- predict(fit.onet, type= "class")
sum(diag(table(RegRank$AOCc, ss)))/ nrow(RegRank)

rr <- predict(fit.onet, type ="link")
summary(rr[, 1]- rr[, 2])
coefficients(fit.onet)[ 2]- coefficients(fit.onet)[ 1]

summary(fit.onet)
coef(fit.onet, matrix= TRUE)

pts <- data.frame(RegRank[, c("XL93", "YL93")])
km <-  kmeans(pts, 300, nstart= 10, iter.max= 100)
ctr <- data.frame(X1= km$center[, 1], X2= km$center[, 2])
coordinates(ctr) <- ~ X1+ X2
voronoipolygons = function(layer) {
    require(deldir)
    crds = layer@coords
    z = deldir(crds[,1], crds[,2])
    w = tile.list(z)
    polys = vector(mode='list', length=length(w))
    require(sp)
    for (i in seq(along=polys)) {
        pcrds = cbind(w[[i]]$x, w[[i]]$y)
        pcrds = rbind(pcrds, pcrds[1,])
        polys[[i]] = Polygons(list(Polygon(pcrds)), ID=as.character(i))
    }
    SP = SpatialPolygons(polys)
    voronoi = SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1], 
        y=crds[,2], row.names=sapply(slot(SP, 'polygons'), 
        function(x) slot(x, 'ID'))))
}
PolyVP <- voronoipolygons(ctr)
proj4string(PolyVP) <- proj4string(AocRank)
RegRank$KCLUST <- factor(km$cluster)

## library(raster)
## polyVPsel <- intersect(Bord.Area, PolyVP)
## polyVPsel$KCLUST <- as.numeric(row.names(polyVPsel))
length(levels(RegRank$KCLUST))
eq2 <- factor(AOCc)~  KCLUST+ LIBCOM

fit.twot <- ordinalNet(x= model.matrix(eq2, data= RegRank),
                       y= factor(RegRank$AOCc),
                       family= "cumulative", reverse= T, link= "logit")
ss <- predict(fit.twot, type= "class")
sum(diag(table(RegRank$AOCc, ss)))/ nrow(RegRank)
fit.twot
coefficients(fit.twot, matrix= T)

fit.pnet <- ordinalNet(X, Y,
                       family= "cumulative", reverse= T, link= "probit",
                       parallelTerms= TRUE, nonparallelTerms= TRUE)
summary(fit.pnet)
coef(fit2, matrix= TRUE)
1- (-60594/ logLik(update(fit.ogam, . ~ + 1)))
pp <- predict(fit.pnet, type= "class")
sum(diag(table(Y, pp)))/ nrow(RegRank)
#+end_src

*** Heteroskedasticity

#+begin_src R
library(ordinal)
fit.clmr <- clm(AOCo~ bs(DEM, 4)+ bs(SLOPE, 5)+ bs(ASPECT, 5)
                + bs(RAYAT, 5)+ bs(PERMEABILITY, 4)
                + bs(DISTCHF, 4)
                + bs(XREG, 4)* bs(YREG, 4)
              , data= RegRank)
##                link= "Aranda-Ordaz",
##                control= list(method= "optim", iter.max= 1000,
##                              maxIter= 1000))
summary(fit.clmr)
autoplot(fit.clmr, what= "qq")
library(ordinal)
fit.clmr <- clm(AOCo~ bs(DEM, 4)+ bs(SLOPE, 5)+ bs(ASPECT, 5)
                + bs(RAYAT, 5)+ bs(PERMEABILITY, 4)
                + bs(DISTCHF, 4)
                + bs(XREG, 4)* bs(YREG, 4)
              , scale= ~ DEM+ SLOPE+ ASPECT+ RAYAT+ DISTCHF
              , data= RegRank
              , control= list(method= "Newton", maxIter= 1000L, 
                              maxLineIter= 1000L))
summary(fit.clmr)
autoplot(fit.clmr, what= "qq")
autoplot(fit.clmr, what= "covariate", x= RegRank$DEM)
autoplot(fit.clmr, what= "covariate", x= RegRank$DISTCHF)
#+end_src

*** Sample choices

    Cote de Beaune / Cote de Nuits, with other land uses.

    Multivariate probit

#+begin_src R
AocRank$AOCo <- factor(ifelse(AocRank$GCRU== 1, "GCRU",
                       ifelse(AocRank$PCRU== 1, "PCRU",
                       ifelse(AocRank$VILL== 1 | AocRank$COMM== 1, "VILL",
                       ifelse(AocRank$BOUR== 1, "BOUR",
                       ifelse(AocRank$BGOR== 1 | AocRank$BPTG== 1, "BGOR",
                              "NONE"))))), ordered= TRUE,
                       levels= c("NONE", "BGOR", "BOUR",
                                 "VILL", "PCRU", "GCRU"))
#+end_src

*** Spatial Autocorrelation                  :noexport:

#+begin_src R
load("Inter/AocRank.Rda")
SpRank <- subset(AocRank, AocRank$PAOC!= 0 &
                          !is.na(AocRank$DEM) & !is.na(AocRank$CODEg))
library(spdep)
DtrYo <- tri2nb(SpRank) ## triangulation pour le moment
BctYo <- nb2listw(DtrYo, style= "W")

DstReg <- dnearneigh(coordinates(SpRank), d1= 0, d2= 500)
dst <- nbdists(DstReg, coordinates(SpRank))
gl2 <- lapply(dst, function(x) 1e6/ (x^2))
BdsReg <- nb2listw(DstReg, glist= gl2, style= "W")

library("Inter/gamod2.Rda")
fff <- surlGAM(gamod2$gam50)- gamod2$gam50$line
moran.test(fff, BctYo)
#moran.test(fff, BdsReg)
moran.plot(as.numeric(fff), BctYo, labels= FALSE)

fff <- surlGAM(gamod2$gam400)- gamod2$gam400$line
moran.test(fff, BctYo)
#moran.test(fff, BdsReg)
moran.plot(as.numeric(fff), BctYo, labels= FALSE)


library("Inter/gamod3.Rda")
fff <- surlGAM(gamod3$gam800)- gamod3$gam800$line
moran.test(fff, BctYo)
#moran.test(fff, BdsReg)
moran.plot(as.numeric(fff), BctYo, labels= FALSE)

fff <- surlGAM(gamod3$gam700)- gamod3$gam700$line
moran.test(fff, BctYo)
moran.plot(as.numeric(fff), BctYo, labels= FALSE)


moran.test(ggam2, BctYo)
moran.test(ggam2, BdsReg)
moran.plot(as.numeric(ggam2), BctYo, labels= FALSE)
moran.plot(as.numeric(ggam2), BdsReg, labels= FALSE)

j1 <- predict(fit.ogam2, type= "response")
j2 <- rowSums(t(apply(j1, 1, function(x) x* 1: 5)))
j3 <- rowSums(t(apply(j1, 1, function(x) x* c(1: 5)^2))- j2^2)
res <- (RegRank$AOCc- j2)/ j3
summary(res)
plot(density(res))
moran.test(res, BctYo)
moran.plot(res, BctYo)

head(tmp)
head(j2)
#+end_src

** Session information

#+begin_src R :wrap example
sessionInfo()
#+end_src

#+RESULTS:
#+begin_example
R version 3.5.3 (2019-03-11)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.2 LTS

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=fr_FR.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=fr_FR.UTF-8        LC_COLLATE=fr_FR.UTF-8    
 [5] LC_MONETARY=fr_FR.UTF-8    LC_MESSAGES=fr_FR.UTF-8   
 [7] LC_PAPER=fr_FR.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets 
[7] methods   base     

other attached packages:
 [1] gridExtra_2.3       xtable_1.8-3        ggrepel_0.8.0      
 [4] ggplot2_3.1.0       plyr_1.8.4          latticeExtra_0.6-28
 [7] RColorBrewer_1.1-2  effects_4.0-3       lattice_0.20-38    
[10] truncdist_1.0-2     evd_2.3-3           sure_0.2.0         
[13] sandwich_2.5-0      lmtest_0.9-36       zoo_1.8-4          
[16] mgcv_1.8-28         nlme_3.1-137        car_3.0-2          
[19] carData_3.0-1       MASS_7.3-51.1       sp_1.3-1           

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.0        assertthat_0.2.0  R6_2.3.0         
 [4] cellranger_1.1.0  survey_3.33-2     pillar_1.3.0     
 [7] rlang_0.3.0.1     lazyeval_0.2.1    curl_3.2         
[10] readxl_1.1.0      minqa_1.2.4       data.table_1.11.4
[13] nloptr_1.0.4      Matrix_1.2-17     labeling_0.3     
[16] splines_3.5.3     rgdal_1.3-6       lme4_1.1-18-1    
[19] foreign_0.8-71    munsell_0.5.0     compiler_3.5.3   
[22] pkgconfig_2.0.2   nnet_7.3-12       tidyselect_0.2.5 
[25] tibble_1.4.2      rio_0.5.10        crayon_1.3.4     
[28] dplyr_0.7.8       withr_2.1.2       grid_3.5.3       
[31] gtable_0.2.0      magrittr_1.5      scales_1.0.0     
[34] zip_1.0.0         bindrcpp_0.2.2    openxlsx_4.1.0   
[37] tools_3.5.3       forcats_0.3.0     glue_1.3.0       
[40] purrr_0.2.5       hms_0.4.2         abind_1.4-5      
[43] survival_2.43-3   colorspace_1.3-2  bindr_0.1.1      
[46] haven_1.1.2
#+end_example

#+LATEX: \appendix

** Functions
*** Surrogate
**** Plot                                    :noheading:

#+begin_src R :tangle ./myFcts.R
pltSURE <- function(resid, xvar, lab){
    plot(xvar, resid, xlab= lab, main= paste("Surrogate Analysis", lab))
    abline(h= 0, col= "red", lty= 3, lwd= 2)
    lines(smooth.spline(resid ~ xvar), lwd= 3, col= "blue")
}
#+end_src

**** Ordered Logit                           :noheading:
***** function

#+begin_src R :tangle ./myFcts.R
surlOLR <- function(mod, newd= NULL){
    if (mod$method!= "logistic") stop("Logistic required")
    gg <- as.numeric(mod$zeta)
    if (is.null(newd)){
        g1 <- unname(as.integer(model.response(model.frame(mod))))
        g6 <- mod$lp
    } else {
        g1 <- as.integer(newd[, "AOCc"])
        g6 <- gg[ 1]-qlogis(predict(mod, newdata= newd, type= 'probs')[, 1])
    }
    nn <- length(g1)
    suls <- sapply(g1, switch,
                   "1"= c(-Inf  , gg[ 1]), "2"= c(gg[ 1], gg[ 2]),
                   "3"= c(gg[ 2], gg[ 3]), "4"= c(gg[ 3], gg[ 4]),
                   "5"= c(gg[ 4], Inf   ))
    sls <- data.frame(unlist(t(suls)))
    rtrunc(nn, spec= "logis", a= sls[, 1], b= sls[, 2],
           location= g6, scale= 1)
}
#+end_src

***** test

#+begin_src R
summary(por1)
#+end_src

**** Ordered Probit                          :noheading:
***** function                               :noheading:

#+begin_src R :tangle ./myFcts.R
library(sure)
library(truncdist)
surpOLR <- function(mod, newd= NULL){
    if (mod$method!= "probit") stop("Probit required")
    gg <- as.numeric(mod$zeta)
    if (is.null(newd)){
        g1 <- unname(as.integer(model.response(model.frame(mod))))
        g6 <- mod$lp
    } else {
        g1 <- as.integer(newd[, "AOCc"])
        g6 <- gg[ 1]-qnorm(predict(mod, newdata= newd, type= 'probs')[, 1])
    }
    nn <- length(g1)
    suls <- sapply(g1, switch,
                   "1"= c(-Inf  , gg[ 1]), "2"= c(gg[ 1], gg[ 2]),
                   "3"= c(gg[ 2], gg[ 3]), "4"= c(gg[ 3], gg[ 4]),
                   "5"= c(gg[ 4], Inf   ))
    sls <- data.frame(unlist(t(suls)))
    rtrunc(nn, spec= "norm", a= sls[, 1], b= sls[, 2],
           mean= g6, sd= sqrt(1+ var(g6)))
}
#+end_src

***** test                                   :noheading:

#+begin_src R
kk <- surrogate(por1)+ por1$zeta[ 1]
hh <- surpOLR(por1)
plot(kk, hh)
abline(h= gg)
abline(v= gg)
abline(0, 1, col= "blue")

ll <- surrogate(por1)+ gg[ 1]
plot(kk, ll)
abline(h= gg)
abline(v= gg)
abline(0, 1, col= "blue")

oo <- surpOLR(por1, newd= RegRank)
plot(oo, ll)
abline(h= gg)
abline(v= gg)
abline(0, 1, col= "blue")
#+end_src

**** Ordered Additive                        :noheading:
***** function                               :noheading:

#+begin_src R :tangle ./myFcts.R
surlGAM <- function(mod, newd= NULL){
    gg <- as.numeric(mod$family$getTheta(TRUE))
    if (is.null(newd)){
        g1 <- as.integer(mod$y)
        g6 <- mod$linear.predictors
    } else {
        g1 <- as.integer(newd[, "AOCc"])
        g6 <- predict(mod, newdata= newd)
    }
    nn <- length(g1)
    suls <- sapply(g1, switch,
                   "1"= c(-Inf  , gg[ 1]), "2"= c(gg[ 1], gg[ 2]),
                   "3"= c(gg[ 2], gg[ 3]), "4"= c(gg[ 3], gg[ 4]),
                   "5"= c(gg[ 4], Inf   ))
    sls <- data.frame(unlist(t(suls)))
    rtrunc(nn, spec= "logis", a= sls[, 1], b= sls[, 2], location= g6)
}
suroldGAM <- function(mod, newd= NULL){
    gg <- as.numeric(mod$family$getTheta(TRUE))
    if (is.null(newd)){
        g1 <- as.integer(mod$y)
        g6 <- mod$linear.predictors
    } else {
        g1 <- as.integer(newd[, "AOCavt"])
        g6 <- predict(mod, newdata= newd)
    }
    nn <- length(g1)
    suls <- sapply(g1, switch,
                   "1"= c(-Inf  , gg[ 1]), "2"= c(gg[ 1], gg[ 2]),
                   "3"= c(gg[ 2], Inf   ))
    sls <- data.frame(unlist(t(suls)))
    rtrunc(nn, spec= "logis", a= sls[, 1], b= sls[, 2], location= g6)
}
#+end_src

***** test                                   :noheading:

#+begin_src R
fit.ogam <- gam(AOCc~ poly(DEM, 2)+ poly(SLOPE, 2)
                + poly(RAYAT, 2)+ poly(ASPECT, 2)+ poly(PERMEABILITY, 2)
              , family= ocat(R= 5), data= RegRank)
fit.oglm <- polr(factor(AOCc)~ poly(DEM, 2)+ poly(SLOPE, 2)
                + poly(RAYAT, 2)+ poly(ASPECT, 2)+ poly(PERMEABILITY, 2)
              , method= "logistic", data= RegRank)
plot(fit.ogam$line, fit.oglm$lp-fit.oglm$zeta[1]- 1)
abline(0, 1)

hh <- surrogate(fit.oglm)+ fit.oglm$zeta[ 1]+ 1
gg <- surlGAM(fit.ogam)
plot(gg, hh)
abline(v= fit.ogam$family$getTheta(TRUE))
abline(h= fit.oglm$zeta+ 1)
abline(0, 1, col= "blue")
kk <- surlGAM(fit.ogam, newd= RegRank)
plot(kk, hh)
abline(v= fit.ogam$family$getTheta(TRUE))
abline(h= fit.oglm$zeta+ 1)
abline(0, 1, col= "blue")

#+end_src

**** Logit                                   :noheading:
***** function

#+begin_src R
surlGLM <- function(mod, newd= NULL){
    if (mod$family$link!= "logit") stop("Logit required")
    if (is.null(newd)){
        g1 <- as.integer(mod$y)
        g6 <- mod$linear.predictors
    } else {
        g1 <- as.integer(newd[, "AOCc"])
        g6 <- predict(mod, newdata= newd, type= "link")
    }
    nn <- length(g1)
    ifelse(g1== 0,
           rtrunc(nn, spec= "logis", a= -Inf, b= 0, location= g6,
                  scale= 1),
           rtrunc(nn, spec= "logis", a= 0, b=  Inf, location= g6,
                  scale= 1))
}
#+end_src

***** test
**** Probit                                  :noheading:
***** function                               :noheading:

#+begin_src R :tangle ./myFcts.R
surpGLM <- function(mod, newd= NULL){
    if (mod$family$link!= "probit") stop("Probit required")
    if (is.null(newd)){
        g1 <- as.integer(mod$y)
        g6 <- mod$linear.predictors
    } else {
        g1 <- as.integer(newd[, "AOCc"])
        g6 <- predict(mod, newdata= newd, type= "link")
    }
    nn <- length(g1)
    ifelse(g1== 0, rtrunc(nn, spec= "norm", a= -Inf, b= 0, mean= g6),
           rtrunc(nn, spec= "norm", a= 0, b=  Inf, mean= g6))
}
#+end_src

***** test                                   :noheading:

**** Current package                         :noexport:

       Pour les glm, la fonction getBounds.glm devrait se baser sur 1
       ou 2 plutôt que 0 ou 1. En plus, plutôt que de garder du 1 ou 2
       (issu de
       as.integer(as.factor(model.response(model.frame(fit.glm1))))),
       il serait plus logique d'utilise la partie y de l'objet, ce que
       je fais dans mes fonctions.

       Pourquoi on fait 2 colonnes pour les proba prédites, le cas
       particulier pour les glm dans les fonctions workhorse ne me
       semble pas nécessaire. C'est de là que viendrait l'erreur que
       l'on trouve avec le package.

       Pour avoir du newdata, il suffirait de remplacer (comme je le
       fais) les fitted.values et linear predictors par la fonction
       predict. (ça risque d'être plus long)

       Il y a une partie du code (les trois fonctions ci-dessous que
       je ne capte pas bien)

#+begin_src R
library(sure)
bad <- surrogate(fit.glm1) ## MARCHE PAS POUR GLM
better <- surrogate(fit.polr)
mean(better) ; mean(fit.polr$lp) ## but not in the scale
mean(fit.polr$lp- fit.polr$zeta[ 1]) ## good

.rtrunc <- function (n, spec, a = -Inf, b = Inf, ...) {
  .qtrunc(runif(n, min = 0, max = 1), spec, a = a, b = b, ...)
}

.qtrunc <- function (p, spec, a = -Inf, b = Inf, ...) {
  tt <- p
  G <- get(paste("p", spec, sep = ""), mode = "function")
  Gin <- get(paste("q", spec, sep = ""), mode = "function")
  G.a <- G(a, ...)
  G.b <- G(b, ...)
  pmin(pmax(a, Gin(G(a, ...) + p * (G(b, ...) - G(a, ...)), ...)), b)
}

sim_trunc <- function(n, distribution, a, b, location = 0, scale = 1) {
  if (distribution == "norm") {
    .rtrunc(n, spec = distribution, a = a, b = b,
            mean = location, sd = scale)
  } else {
    .rtrunc(n, spec = distribution, a = a, b = b,
            location = location, scale = scale)
  }
}
#+end_src

*** Decomposition
**** Joint Noise                             :noheading:

#+begin_src R :tangle ./myFcts.R
jointNoise <- function(latent, DAT= RegRank){
    jN <- 0
    for (i in 1: 5){
        for (j in levels(DAT$LIBCOM)){
            tmp <- latent[DAT$AOCc== i & DAT$LIBCOM== j]
            if (length(tmp)> 0)
                jN <- jN+ var(tmp)* mean(DAT$AOCc== i & DAT$LIBCOM== j)
        }
    }
    c("Joint Noise"= jN)
}
jointNoise2 <- function(latent, vert= "AOCc", horiz= "LIBCOM", dat= RRank){
    jN <- 0
    for (i in levels(factor(dat[, vert]))){
        for (j in levels(factor(dat[, horiz]))){
            tmp <- latent[dat[, vert]== i & dat[, horiz]== j]
            if (length(tmp)> 1)
                jN <- jN+
                    var(tmp)* mean(dat[, vert]== i & dat[, horiz]== j)
        }
    }
    c("Joint Noise"= jN)
}
#+end_src

**** Joint Signal                            :noheading:

#+begin_src R :tangle ./myFcts.R
jointSignal <- function(latent, DAT= RegRank){
    jS <- rep(0, nrow(DAT))
    for (i in 1: 5){
        for (j in levels(DAT$LIBCOM)){
            jS[DAT$AOCc== i & DAT$LIBCOM== j] <-
                mean(latent[DAT$AOCc== i & DAT$LIBCOM== j])
        }
    }
    c("Joint Signal"= var(jS))
}
jointSignal2 <- function(latent, vert="AOCc", horiz="LIBCOM", dat= RRank){
    jS <- rep(0, nrow(dat))
    for (i in levels(factor(dat[, vert]))){
        for (j in levels(factor(dat[, horiz]))){
            ind <- dat[, vert]== i & dat[, horiz]== j 
            jS[ ind] <- mean(latent[ ind])
        }
    }
    c("Joint Signal"= var(jS))
}
#+end_src

**** Rank Signal                             :noheading:

#+begin_src R :tangle ./myFcts.R
rankSignal <- function(latent, DAT= RegRank){
    rS <- var(ifelse(DAT$AOCc== 1, mean(latent[DAT$AOCc== 1]),
              ifelse(DAT$AOCc== 2, mean(latent[DAT$AOCc== 2]),
              ifelse(DAT$AOCc== 3, mean(latent[DAT$AOCc== 3]),
              ifelse(DAT$AOCc== 4, mean(latent[DAT$AOCc== 4]),
                     mean(latent[DAT$AOCc== 5]))))))
    c("Rank Signal"= rS)
}
rankSignal2 <- function(latent, vert= "AOCc", horiz= "LIBCOM", dat= RRank){
    rS <- rep(NA, nrow(dat))
    for (i in levels(factor(dat[, vert]))){
        rS[ dat[, vert]== i] <- mean(latent[dat[, vert]== i])
    }
    c("Rank Signal"= var(rS))
}
#+end_src

**** Rank Noise                              :noheading:

#+begin_src R :tangle ./myFcts.R
rankNoise <- function(latent, DAT= RegRank){
    rN <- var(latent[DAT$AOCc== 1])* mean(DAT$AOCc== 1)+
        var(latent[DAT$AOCc== 2])*   mean(DAT$AOCc== 2)+
        var(latent[DAT$AOCc== 3])*    mean(DAT$AOCc== 3)+
        var(latent[DAT$AOCc== 4])*    mean(DAT$AOCc== 4)+
        var(latent[DAT$AOCc== 5])*    mean(DAT$AOCc== 5)
    c("Rank Noise"= rN)
}
rankNoise2 <- function(latent, vert= "AOCc", dat= RRank){
    rN <- 0
    for (i in levels(factor(dat[, vert]))){
        rN <- rN+ var(latent[dat[, vert]== i])* mean(dat[, vert]== i)
    }
    c("Rank Noise"= rN)
}
#+end_src

**** Rank Residuals                          :noheading:

#+begin_src R :tangle ./myFcts.R
rankResid <- function(latent, DAT= RegRank){
    sig <- rep(0, nrow(DAT))
    for (i in 1: 5){
        for (j in levels(DAT$LIBCOM)){
            sig[DAT$AOCc== i & DAT$LIBCOM== j] <-
                mean(latent[DAT$AOCc== i & DAT$LIBCOM== j])
        }
    }
    rR <- (var(sig[DAT$AOCc== 1])* mean(DAT$AOCc== 1)+
           var(sig[DAT$AOCc== 2])* mean(DAT$AOCc== 2)+
           var(sig[DAT$AOCc== 3])* mean(DAT$AOCc== 3)+
           var(sig[DAT$AOCc== 4])* mean(DAT$AOCc== 4)+
           var(sig[DAT$AOCc== 5])* mean(DAT$AOCc== 5))
    c("Rank Residual"= rR)
}
rankResid2 <- function(latent, vert= "AOCc", horiz= "LIBCOM", dat= RRank){
    sig <- rep(0, nrow(dat)) ; rR <- 0
    for (i in levels(factor(dat[, vert]))){
        for (j in levels(factor(dat[, horiz]))){
            ind <- dat[, vert]== i & dat[, horiz]== j 
            sig[ ind] <- mean(latent[ ind])
        }
    }
    for (i in levels(factor(dat[, vert]))){
        rR <- rR+ var(sig[dat[, vert]== i])* mean(dat[, vert]== i)
    }
    c("Rank Residual"= rR)
}
#+end_src

**** Commune Signal                          :noheading:

#+begin_src R :tangle ./myFcts.R
comSignal <- function(latent, DAT= RegRank){
    cS <- rep(0, nrow(DAT))
    for (j in levels(DAT$LIBCOM)){
        cS[ DAT$LIBCOM== j] <- mean(latent[DAT$LIBCOM== j])
    }
    c("Com Signal"= var(cS))
}
comSignal2 <- function(latent, horiz= "LIBCOM", dat= RRank){
    cS <- rep(0, nrow(dat))
    for (j in levels(factor(dat[, "LIBCOM"]))){
        cS[ dat[, "LIBCOM"]== j] <- mean(latent[dat[, "LIBCOM"]== j])
    }
    c("Com Signal"= var(cS))
}
#+end_src

**** Commune Noise                           :noheading:

#+begin_src R :tangle ./myFcts.R
comNoise <- function(latent, DAT= RegRank){
    cN <- 0
    for (j in levels(DAT$LIBCOM)){
        cN <- cN+ (var(latent[DAT$LIBCOM== j])* mean(DAT$LIBCOM== j)) 
    }
    c("Com Noise"= cN)
}
comNoise2 <- function(latent, horiz= "LIBCOM", dat= RRank){
    cN <- 0
    for (j in levels(factor(dat[, horiz]))){
        cN <- cN+ (var(latent[dat[, horiz]== j])* mean(dat[, horiz]== j)) 
    }
    c("Com Noise"= cN)
}
#+end_src

**** Commune Residual                        :noheading:

#+begin_src R :tangle ./myFcts.R
comResid <- function(latent, DAT= RegRank){
    sig <- rep(0, nrow(DAT))
    for (i in 1: 5){
        for (j in levels(DAT$LIBCOM)){
            sig[DAT$AOCc== i & DAT$LIBCOM== j] <-
                mean(latent[DAT$AOCc== i & DAT$LIBCOM== j])
        }
    }
    cR <- 0
    for (j in levels(DAT$LIBCOM)){
        cR <- cR+ var(sig[DAT$LIBCOM== j])* mean(DAT$LIBCOM== j)
    }
    c("Com Residual"= cR)
}
comResid2 <- function(latent, vert= "AOCc", horiz= "LIBCOM", dat= RRank){
    sig <- rep(0, nrow(dat))
    for (i in levels(factor(dat[, vert]))){
        for (j in levels(factor(dat[, horiz]))){
            sig[dat[, vert]== i & dat[, horiz]== j] <-
                mean(latent[dat[, vert]== i & dat[, horiz]== j])
        }
    }
    cR <- 0
    for (j in levels(factor(dat[, horiz]))){
        cR <- cR+ var(sig[dat[, horiz]== j])* mean(dat[, horiz]== j)
    }
    c("Com Residual"= cR)
}
#+end_src

** Test of R packages                        :noexport:
*** Multinomial model

    Hors sujet

#+begin_src R
library(nnet)
RegRank <- subset(AocRank@data, !is.na(AocRank$DEM))
fit.mnl <- multinom(AOCo ~ poly(DEM, 2)+ poly(SLOPE, 2)+ poly(ASPECT, 2)
                    + poly(SOLAR, 2)+ poly(PERMEABILITY, 2)
                    + poly(XL93, 3)* poly(YL93, 3),
                    data= RegRank, maxit= 300)
1- (logLik(fit.mnl)/ logLik(update(fit.mnl, . ~ + 1)))
sum(diag(table(RegRank$AOCo, predict(fit.mnl))))/ nrow(RegRank)
table(RegRank$AOCo, predict(fit.mnl))


library(effects)
plot(predictorEffects(fit.mnl, ~ DEM+ SLOPE),
     axes=list(grid=TRUE, x=list(rug=FALSE)),
     lattice=list(key.args=list(columns=1)),
     lines=list(multiline=TRUE, col=c("blue", "red", "orange")))
plot(predictorEffects(fit.mnl, ~ DEM+ SLOPE),
     axes=list(grid=TRUE, x=list(rug=FALSE), y= list(style= "stacked")),
     lattice=list(key.args=list(columns=1)),
     lines=list(multiline=TRUE))

yop1 <- predict(fit.mnl, type= "probs")
plot(data.frame(yop1))

gg <- t(apply(yop1, 1, cumsum))
ff <- gg[order(gg[, 1]), ]
plot(ff[, 1], type= "l")
par(new= T)
plot(ff[, 2], col= "blue")

ff$D1 <- ff[, 2]- ff[, 1]

summary(ff$D1)
#+end_src

*** SURE for residuals

#+begin_src R
## On utilise le probit uniquement sur AOC
autoplot(fit.golr, what= "covariate", x= RankReg$DEM,
         method= "jitter", jitter.scale= "response")

summary(prs)


plot(prs, prq$R)
library(ggplot2) # for plotting
p1 <- ggplot(data.frame(x = RankReg$DEM, y = prq$R), aes(x, y)) +
    geom_point(color = "#444444", shape = 19, size = 2, alpha = 0.5) +
    geom_smooth(color = "red", se = FALSE) +
    ylab("Probability-scale residual")
p2 <- ggplot(data.frame(y = prq$R), aes(sample = y)) +
    stat_qq(distribution = qunif, dparams = list(min = -1, max = 1), alpha = 0.5) +
    xlab("Sample quantile") +
    ylab("Theoretical quantile")
grid.arrange(p1, p2, ncol = 2) # Figure 1

sres <- resids(fit.polr)
plot(prs, sres)
p1 <- autoplot(sres, what= "covariate", x= RankReg$SLOPE)
p2 <- autoplot(sres, what= "qq", distribution= qnorm)
grid.arrange(p1, p2, ncol = 2) # Figure 2

sprd <- surrogate(fit.polr)
var(sprd)


fit.polr2 <- update(fit.polr, .~ DEM)
sprd2 <- surrogate(fit.polr2)
var(sprd2)

autoplot(fit.polr2, what= "covariate", x= df1$x)

prq <- NormRes(predict(fit.polr2, type= "probs"), df1$y)
p1 <- ggplot(data.frame(x = df1$x, y = prq$R), aes(x, y)) +
    geom_point(color = "#444444", shape = 19, size = 2, alpha = 0.5) +
    geom_smooth(color = "red", se = FALSE) +
    ylab("Probability-scale residual")
p2 <- ggplot(data.frame(y = prq$R), aes(sample = y)) +
    stat_qq(distribution = qnorm, alpha = 0.5) +
    xlab("Sample quantile") +
    ylab("Theoretical quantile")
grid.arrange(p1, p2, ncol = 2)

prq <- NormRes(predict(fit.orm, type= "fitted.ind"), df2$y)
p2 <- ggplot(data.frame(x = df1$x, y = prq$R), aes(x, y)) +
    geom_point(color = "#444444", shape = 19, size = 2, alpha = 0.5) +
    geom_smooth(color = "red", se = FALSE) +
    ylab("Probability-scale residual")
grid.arrange(p1, p2, ncol = 2)

resids # residuals
surrogate # surrogate response values
autoplot # diagnostic plots
gof # goodness of fit

#+end_src

*** OrdinalNet

#+begin_src R
load("Inter/AocRank.Rda")
AocRank$AOCo <- factor(ifelse(AocRank$GCRU== 1, "GCRU",
                       ifelse(AocRank$PCRU== 1, "PCRU",
                       ifelse(AocRank$VILL== 1 | AocRank$COMM== 1, "VILL",
                       ifelse(AocRank$BOUR== 1, "BOUR",
                       ifelse(AocRank$BGOR== 1 | AocRank$BPTG== 1, "BGOR",
                              "NONE"))))), ordered= TRUE,
                       levels= c("NONE", "BGOR", "BOUR",
                                 "VILL", "PCRU", "GCRU"))
spl <- round(seq(1, nrow(AocRank), length.out= 10000))
RegSpl <- subset(AocRank@data[spl, ],
                 !is.na(AocRank$DEM[spl])& !is.na(AocRank$CODEg[spl]))
RegSpl$LIBCOM <- factor(RegSpl$LIBCOM)
library(MASS)
fit.polr <- polr(AOCo~ poly(DEM, 2)+ poly(SLOPE, 2)+ poly(ASPECT, 2)
                 + poly(SOLAR, 2)+ PERMEABILITY,#+ LIBCOM,
                 data= RegSpl, method= "probit")
1- (logLik(fit.polr)/ logLik(update(fit.polr, . ~ + 1)))
head(rr)
ss <- predict(fit.polr, type= "class")
table(rr, ss)
summary(fit1)
coef(fit1, matrix= TRUE)

fit2 <- ordinalNet(X, Y, family= "cumulative", reverse= T, link= "logit",
                   parallelTerms= TRUE, nonparallelTerms= TRUE)
summary(fit2)
coef(fit2, matrix= TRUE)

head(tt)
## A APPLIQUER SUR UNE SOUS-ECHANTILLON DE MA BASE
library(ordinalgmifs)
data(hccframe) ; dim(hccframe)
X <- model.matrix(~ ., data= hccframe[, -1])
Y <- factor(hccframe[, 1])
fit1 <- ordinalNet(X, Y, family= "cumulative", link= "logit")
summary(fit1)
head(coef(fit1, matrix= TRUE))

fit2 <- ordinalNet(X, Y, family= "cumulative", link= "logit",
                   parallelTerms= TRUE, nonparallelTerms= TRUE, warn= F)
summary(fit2)
coef(fit2, matrix= TRUE)

fit3 <- ordinalNet(X, Y, family= "cumulative", link= "logit",
                   parallelTerms= FALSE, nonparallelTerms= TRUE, warn= F)
summary(fit3)
head(coef(fit2, matrix= TRUE))

fit2_tune <- ordinalNetTune(X, Y, family= "cumulative", link= "logit",
                            parallelTerms= TRUE, nonparallelTerms= TRUE,
                            warn= FALSE, printProgress= FALSE)
head(fit2_tune$loglik)
bastLambda <- which.max(rowMeans(fit2_tune$loglik))
coef(fit2_tune$fit, matrix= TRUE, whichLambda= bastLambda)
#+end_src

*** Multinomial Shrink (from Raja, Julie)
**** Estimations

# see also https://rdrr.io/cran/mgcv/man/multinom.html

#+begin_src R :results output exemple
library(glmnet)
Ter.Reg <- subset(Ter.Fin, !is.na(Ter.Fin$POP99))
MX <- model.matrix(U03~ 0+ Uinit+ scale(RTFO03)+ scale(PXGL03)
                      + scale(PXLB03)+ scale(POP99)+ scale(TMOY03)
                      + scale(PCUM03)+ scale(BdAlti)+ scale(BdPente)
                      + scale(rumoy1km)+ scale(promoy1km), data= Ter.Reg)
Las0 <- glmnet(MX, Ter.Reg$U03, family= "multinomial", alpha= 1)
Rid0 <- glmnet(MX, Ter.Reg$U03, family= "multinomial", alpha= 0)
Net0 <- glmnet(MX, Ter.Reg$U03, family= "multinomial", alpha= .5)
Srk0 <- list("Las0"= Las0, "Rid0"= Rid0, "Net0"= Net0)
#+end_src

**** LASSO

#+Name: Lst:LMNL0
#+Header: :width 7 :height 9
#+begin_src R :results graphics :exports code :file "Figures/LassoMNL0.pdf"
load("./Res/Srk0.Rda") ; bL0 <- coef(Srk0$Las0)
par(mfrow= c(4, 2), mar= c(2, 2, 2, 1))
for (i in names(bL0)){
    ## FOR THE GENERAL PLOT
    cf1 <- bL0[[ i]][-1, ] ; yop <- (1/ 5): (dim(cf1)[ 2]/ 5)* 5
    matplot(yop, t(cf1)[yop ,], type= "o", lty= 1, pch= 19, col= "blue",
            xlim= c(0, max(yop)+ 12),
            xlab= "Step", ylab= "Coefficients", main= paste(i, "GENERAL"))
    text(max(yop)+ 8, cf1[1: 4, max(yop)],
         substr(rownames(cf1[1: 4, ]), 6, 20), cew= .75)
    ## FOR THE ZOOM PLOT
    cf2 <- bL0[[ i]][-c(1: 5), ]
    deb <- min(I(1: max(yop))[colMeans(cf2)!= 0])- 1
    yop <- (deb/ 5): (dim(cf2)[ 2]/ 5)* 5
    matplot(yop, t(cf2)[yop ,], type= "o", lty= 1, pch= 19, col= "blue",
            xlim= c(deb, max(yop+ 10)),
            xlab= "Step", ylab= "Coefficients", main= paste(i , "ZOOM"))
    text(max(yop)+ 5, cf2[, max(yop)],
         substr(rownames(cf2), 6, 20), cex= .75)
}
#+end_src

 #+Name: Fig:LMNL0
 #+ATTR_LaTeX: :options scale= .8
 #+Caption: Coefficients of variables from Lasso models on the specification 0
 #+RESULTS: Lst:LMNL0
 [[file:Figures/LassoMNL0.pdf]]

     Figure in the appendix.

**** RIDGE

#+Name: Lst:RMNL0
#+Header: :width 7 :height 9
#+begin_src R :results graphics :exports code :file "Figures/RidgeMNL0.pdf"
load("./Res/Srk0.Rda") ; bR0 <- coef(Srk0$Rid0)
par(mfrow= c(4, 2), mar= c(2, 2, 2, 1))
for (i in names(bR0)){    
    ## FOR THE GENERAL PLOT
    cf1 <- bR0[[ i]][-1, ]; yop <- round(seq(1, dim(cf1)[ 2], lengt= 10))
    matplot(yop, t(cf1)[yop ,], type= "o", lty= 1, pch= 19, col= "blue",
            xlim= c(0, max(yop)+ 12),
            xlab= "Step", ylab= "Coefficients", main= paste(i, "GENERAL"))
    text(max(yop)+ 8, cf1[1: 4, max(yop)],
         substr(rownames(cf1[1: 4, ]), 6, 20), cew= .75)
    ## FOR THE ZOOM PLOT
    cf2 <- bR0[[ i]][-c(1: 5), ] ; deb= 1
    yop <- (deb/ 5): (dim(cf2)[ 2]/ 5)* 5
    matplot(yop, t(cf2)[yop ,], type= "o", lty= 1, pch= 19, col= "blue",
            xlim= c(deb, max(yop+ 10)),
            xlab= "Step", ylab= "Coefficients", main= paste(i , "ZOOM"))
    text(max(yop)+ 5, cf2[, max(yop)],
         substr(rownames(cf2), 6, 20), cex= .75)
}
#+end_src

#+Name: Fig:RMNL0
#+ATTR_LaTeX: :options scale= .8
#+Caption: Coefficients of variables from Ridge models on the specification 0
#+RESULTS: Lst:RMNL0
[[file:Figures/RidgeMNL0.pdf]]

     Figure in the appendix.

**** ELASTIC NET \alpha= .5

#+Name: Lst:NMNL0
#+Header: :width 7 :height 9
#+begin_src R :results graphics :exports code :file "Figures/NetMNL0.pdf"
load("./Res/Srk0.Rda") ; bN0 <- coef(Srk0$Net0)
par(mfrow= c(4, 2), mar= c(2, 2, 2, 1))
for (i in names(bN0)){
    ## FOR THE GENERAL PLOT
    cf1 <- bN0[[ i]][-1, ]; yop <- round(seq(1, dim(cf1)[ 2], lengt= 10))
    matplot(yop, t(cf1)[yop ,], type= "o", lty= 1, pch= 19, col= "blue",
            xlim= c(0, max(yop)+ 12),
            xlab= "Step", ylab= "Coefficients", main= paste(i, "GENERAL"))
    text(max(yop)+ 8, cf1[1: 4, max(yop)],
         substr(rownames(cf1[1: 4, ]), 6, 20), cew= .75)
    ## FOR THE ZOOM PLOT
    cf2 <- bN0[[ i]][-c(1: 5), ]
    deb <- min(I(1: max(yop))[colMeans(cf2)!= 0])- 1
    yop <- (deb/ 5): (dim(cf2)[ 2]/ 5)* 5
    matplot(yop, t(cf2)[yop ,], type= "o", lty= 1, pch= 19, col= "blue",
            xlim= c(deb, max(yop+ 10)),
            xlab= "Step", ylab= "Coefficients", main= paste(i , "ZOOM"))
    text(max(yop)+ 5, cf2[, max(yop)],
         substr(rownames(cf2), 6, 20), cex= .75)
}
#+end_src

#+Name: Fig:NMNL0
#+ATTR_LaTeX: :options scale= .8 :placement [!h]
#+Caption: Coefficients of variables from Elastic Net models on the specification 0
#+RESULTS: Lst:NMNL0
[[file:Figures/NetMNL0.pdf]]

     Figure in the appendix.

*** mvord

#+begin_src R
load("Inter/AocRank.Rda")
library(ordinal)
AocRank$AOCo <- factor(ifelse(AocRank$GCRU== 1, "GCRU",
                       ifelse(AocRank$PCRU== 1, "PCRU",
                       ifelse(AocRank$VILL== 1 | AocRank$COMM== 1, "VILL",
                       ifelse(AocRank$BOUR== 1, "BOUR",
                       ifelse(AocRank$BGOR== 1 | AocRank$BPTG== 1, "BGOR",
                              "NONE"))))), ordered= TRUE,
                       levels= c("NONE", "BGOR", "BOUR",
                                 "VILL", "PCRU", "GCRU"))
names(AocRank)
RegRank <- subset(AocRank@data, !is.na(AocRank$DEM)& !is.na(AocRank$CODEg))


library(mvord)
data(data_mvord_toy)
## CONVERT TO LONG FORMAT NECESSAIRE SI ON VEUT DES RELATIONS D'EXCLUSION
res <- mvord(MMO2(Y1, Y2)~ 0+ X1+ X2, data= data_mvord_toy)
summary(res)

names_constraints(Y~ 0+ X1+ X2+ f2, data= data_mvord_toy)

ff <- predict(res)
length(ff)
table(data_mvord_toy$Y1)

data(data_cr)
res_cor_probit_simple <- mvord(MMO2(rater1, rater2, rater3, rater4)~
                                   0+ LR+ LEV+ PR+ RSIZE+ BETA,
                               data= data_cr)
summary(res_cor_probit_simple, call= FALSE)
#+end_src

* Tables
** Descriptive statistics

#+begin_src R :results value :exports code :file "Tables/StatDes.tex"
RRank$bgor <- ifelse(RRank$AOCc== 1, 1, 0) 
RRank$bour <- ifelse(RRank$AOCc== 2, 1, 0) 
RRank$vill <- ifelse(RRank$AOCc== 3, 1, 0)
RRank$pcru <- ifelse(RRank$AOCc== 4, 1, 0)
RRank$gcru <- ifelse(RRank$AOCc== 5, 1, 0)
RRank$X0t45    <- ifelse(RRank$EXPO== "0-45"   , 1, 0)
RRank$X45t90   <- ifelse(RRank$EXPO== "45-90"  , 1, 0)
RRank$X90t135  <- ifelse(RRank$EXPO== "90-135" , 1, 0)
RRank$X135t180 <- ifelse(RRank$EXPO== "135-180", 1, 0)
RRank$X180t225 <- ifelse(RRank$EXPO== "180-225", 1, 0)
RRank$X225t270 <- ifelse(RRank$EXPO== "225-270", 1, 0)
RRank$X270t315 <- ifelse(RRank$EXPO== "270-315", 1, 0)
RRank$X315t360 <- ifelse(RRank$EXPO== "315-360", 1, 0)
RRank$REGavt <- ifelse(RRank$AOCavt== "0", 1, 0)
RRank$VILavt <- ifelse(RRank$AOCavt== "3", 1, 0)
RRank$GCRavt <- ifelse(RRank$AOCavt== "5", 1, 0)
RRank$AREA <- RRank$Area/ 1000
RRank$Altitude <- RRank$DEM/ 1000
lab1 <- c("Acreage [1000 m$^2$]", "Elevation [1000 m]", "Slope [degree]",
          "Solar radiation [scaled]",
          "Longitude [degree]", "Latitude [degree]",
          "Current GI [\\emph{Coteaux}]",
          "Current GI [\\emph{Régional}]", "Current GI [\\emph{Village}]",
          "Current GI [\\emph{Premier Cru}]",
          "Current GI [\\emph{Grand Cru}]",
          "Past GI [\\emph{Régional}]", "Past GI [\\emph{Village}]",
          "Past GI [\\emph{Grand Cru}]",
          "Aspect [$0-45$]", "Aspect [$45-90$]", "Aspect [$90-135$]",
          "Aspect [$135-180$]", "Aspect [$180-225$]", "Aspect [$225-270$]",
          "Aspect [$270-315$]", "Aspect [$315-360$]") 
library(stargazer)          
stargazer(RRank@data[, c("AREA", "Altitude", "SLOPE", "RAYAT", "X", "Y",
                         "bgor", "bour", "vill", "pcru", "gcru",
                         "REGavt", "VILavt", "GCRavt",
                         "X0t45", "X45t90", "X90t135", "X135t180",
                         "X180t225", "X225t270", "X270t315", "X315t360")],
          covariate.labels= lab1, column.sep.width= "0pt", float= F,
	  digit.separate= c(0, 3))
#+end_src

#+RESULTS:
[[file:Tables/StatDes.tex]]

** Variable significance New AOCs

#+begin_src R :results value :exports code :file "Tables/VarSign1.tex"
load("Inter/gamod.Rda") ; load("Inter/gammod.Rda")
sign <- function(x) paste0(format(x,digits=5,big.mark=" "), "$^{**}$")
eedf <- function(x) paste0("[ ", format(x,digits=4), " ]")
ligne1 <- c(res1[3: 5, "LR Chisq"], res1a[2, 6], res1[ 2: 1, "LR Chisq"],
            nrow(RRank), 1-(logLik(por1)/ logLik(update(por1, . ~ + 1))),
            sum(diag(table(predict(por1), RRank$AOCc)))/nrow(RRank),
            AIC(por1), mean(wal1))
lig1 <- c(res1[3: 5, "Df"], res1a[2, "   Df"], res1[ 2: 1, "Df"])

ligneGAM <- function(numMod){
    res= anova(gamod[[ numMod]])
    prd= predict(gamod[[ numMod]], type= "response")
    mpb= factor(c(1: 5)[apply(prd, 1, which.max)], levels= 1:5, ordered= T)
    pp <- c(sign(res$chi.sq[ 1]), eedf(res$edf[ 1]),
            sign(res$chi.sq[ 2]), eedf(res$edf[ 2]),
            sign(res$chi.sq[ 3]), eedf(res$edf[ 3]),
            sign(res$chi.sq[ 4]), eedf(res$edf[ 4]),
            sign(res$pTerms.chi.sq[ 2]), eedf(res$pTerms.df[ 2]),
            sign(res$pTerms.chi.sq[ 1]), eedf(res$pTerms.df[ 1]),
            format(round(nrow(RRank), 0), big.mark=" "),
            round((1-logLik(gamod[[ numMod]])/
                   logLik(update(gamod[[ numMod]],.~ + 1)))* 100, 2),
            round(sum(diag(table(RRank$AOCc, mpb)))/ nrow(RRank)* 100, 2),
            round(AIC(gamod[[ numMod]])/ 1000, 2),
            round(wal2[2, names(gamod[ numMod])], 2))
    return(pp)
}

## library(mgcv)
## Tabb <- data.frame(c("Elevation" , "", "Slope", "", "Solar Radiation", "",
##                      "Spatial Coords", "", "Exposition", "", "Commune", "",
##                      "Nb Observ.", "McFadden R$^2$", "Pc good pred.",
##                      "Akaike IC", "Surrogate F"),
##                    c(sign(ligne1[ 1]), eedf(lig1[ 1]),
##                      sign(ligne1[ 2]), eedf(lig1[ 2]),
##                      sign(ligne1[ 3]), eedf(lig1[ 3]),
##                      sign(ligne1[ 4]), eedf(lig1[ 4]),
##                      sign(ligne1[ 5]), eedf(lig1[ 5]),
##                      sign(ligne1[ 6]), eedf(lig1[ 6]),
##                      format(round(ligne1[ 7], 0), big.mark=" "),
##                             round(ligne1[ 8]* 100, 2),
##                      round(ligne1[ 9]* 100, 2), round(ligne1[ 10]/1000),
##                      round(ligne1[ 11], 2)), lapply(1: 5* 2, ligneGAM))

names(Tabb) <- c("Variable", "( 0 )", "( I )", "( II )",
                 "( III )", "( IV )", " ( V )")
library(xtable)
print(xtable(Tabb, alig= "llYYYYYY"), hline.after = NULL,
      include.rownames= F,
      add.to.row = list(pos = list(-1, 0, 12, nrow(Tabb)),
          command = c("\\hline\\hline\\toprule\n", rep("\\midrule\n", 2),
                      "\\bottomrule\\hline\n")),
      tabular.environment = "tabularx", width="\\textwidth",
      sanitize.text.function = identity, floating= F)
#+end_src

#+RESULTS:
[[file:Tables/VarSign1.tex]]

** Variable significance Old AOCs

#+begin_src R :results value :exports code :file "Tables/VarSign2.tex"
load("Inter/gamold.Rda") ; load("Inter/gammold.Rda")
ligne2 <- c(res2[3: 5, "LR Chisq"], res2a[2, 6], res2[ 2: 1, "LR Chisq"],
            nrow(SRank), 1-(logLik(por2)/ logLik(update(por2, . ~ + 1))),
            sum(diag(table(predict(por2), SRank$AOCavt)))/ nrow(SRank),
            AIC(por2), mean(wal3))
lig2 <- c(res2[3: 5, "Df"], res2a[2, "   Df"], res2[ 2: 1, "Df"])

oldigneGAM <- function(numMod){
    res= anova(gamold[[ numMod]])
    prd= predict(gamold[[ numMod]], type= "response")
    mpb= factor(c(1: 3)[apply(prd, 1, which.max)], levels= 1:3, ordered= T)
    pp <- c(sign(res$chi.sq[ 1]), eedf(res$edf[ 1]),
            sign(res$chi.sq[ 2]), eedf(res$edf[ 2]),
            sign(res$chi.sq[ 3]), eedf(res$edf[ 3]),
            sign(res$chi.sq[ 4]), eedf(res$edf[ 4]),
            sign(res$pTerms.chi.sq[ 2]), eedf(res$pTerms.df[ 2]),
            sign(res$pTerms.chi.sq[ 1]), eedf(res$pTerms.df[ 1]),
            format(round(nrow(SRank), 0), big.mark=" "),
            round((1-logLik(gamold[[ numMod]])/
                   logLik(update(gamold[[ numMod]],.~ + 1)))* 100, 2),
            round(sum(diag(table(SRank$AOCavt, mpb)))/nrow(SRank)* 100, 2),
            round(AIC(gamold[[ numMod]])/ 1000, 2),
            round(wal4[2, names(gamold[ numMod])], 2))
    return(pp)
}

## Tabc <- data.frame(c("Elevation" , "", "Slope", "", "Solar Radiation", "",
##                      "Spatial Coords", "", "Exposition", "", "Commune", "",
##                      "Nb Observ.", "McFadden R$^2$", "Pc good pred.",
##                      "Akaike IC", "Surrogate F"),
##                    c(sign(ligne2[ 1]), eedf(lig2[ 1]),
##                      sign(ligne2[ 2]), eedf(lig2[ 2]),
##                      sign(ligne2[ 3]), eedf(lig2[ 3]),
##                      sign(ligne2[ 4]), eedf(lig2[ 4]),
##                      sign(ligne2[ 5]), eedf(lig2[ 5]),
##                      sign(ligne2[ 6]), eedf(lig2[ 6]),
##                      format(round(ligne2[ 7], 0), big.mark=" "),
##                             round(ligne2[ 8]* 100, 2),
##                      round(ligne2[ 9]* 100, 2), round(ligne2[ 10]/1000),
##                      round(ligne2[ 11], 2)), lapply(3: 7, oldigneGAM))

names(Tabc) <- c("Variable", "( 0 )", "( I )", "( II )",
                 "( III )", "( IV )", " ( V )")
library(xtable)
print(xtable(Tabc, alig= "llYYYYYY"), hline.after = NULL,
      include.rownames= F,
      add.to.row = list(pos = list(-1, 0, 12, nrow(Tabb)),
          command = c("\\hline\\hline\\toprule\n", rep("\\midrule\n", 2),
                      "\\bottomrule\\hline\n")),
      tabular.environment = "tabularx", width="\\textwidth",
      sanitize.text.function = identity, floating= F)

#+end_src

#+RESULTS:
[[file:Tables/VarSign2.tex]]

** Decomposition New AOC

#+begin_src R :results value :exports code :file "Tables/Decomp.tex"
load("Inter/gamod.Rda") ; source("myFcts.R") ; library(xtable)
## latent <- sapply(gamod[ 1: 5* 2], function(x)
##     rowSums(predict(x, type= 'terms')[, -1]))
decomp <- apply(latent, 2, function(x)
    c(Signal= var(x), Noise= pi^2/ 3, jointSignal(x), jointNoise(x),
      rankSignal(x), rankResid(x), rankNoise(x),
      comSignal(x), comResid(x), comNoise(x)))
yop <- data.frame(Decomp.= c("Total", "", "Joint", "",
                             "Vertical", "", "", "Horizontal", "", ""),
                  Term= c(rep(c("Signal", "Noise"), 2),
                       rep(c("Signal", "Residual", "Noise"), 2)),
                  t(t(decomp)/ (pi^2/ 3+ decomp[1, ]))* 100)
names(yop)[ 3: 7] <- paste0("(", sapply(gamod[ 1: 5* 2], function(x)
    round(summary(x)$edf[ 4])), ")")
ctmp <- "\\hline\\hline\\toprule\n&& \\multicolumn{5}{c}{\\emph{Effective degrees of freedom for spatial smoothing}}\\\\[.25cm]\n"
print(xtable(yop, align= c("@{\\extracolsep{\\fill}} l", rep("X", 7))),
      add.to.row= list(pos= list(-1, 0, 2, 4, 7, 10),
                       command= c(ctmp, rep("\\midrule\n", 4),
                                  "\\bottomrule\\hline\n")),
      tabular.environment= "tabularx", width= "\\textwidth",
      include.rownames= FALSE, hline.after = NULL, floating= FALSE)
#+end_src

#+RESULTS:
[[file:Tables/Decomp.tex]]

** Decomposition Counterfactual AOC

#+begin_src R :results value :exports code :file "Tables/Decoldmp.tex"
yap <- data.frame(Decomp.= c("Total", "", "Joint", "",
                             "Vertical", "", "", "Horizontal", "", ""),
                  Term= c(rep(c("Signal", "Noise"), 2),
                          rep(c("Signal", "Residual", "Noise"), 2)),
                  tabpap)
names(yap)[ 3: 10] <- c("1936", "S.0", "S.I", "S.II", "S.III",
                        "S.IV", "S.V", "S.VI")
ctmp <- "\\hline\\hline\\toprule\n&& \\multicolumn{7}{c}{\\emph{Alternative scenarios of GI designations}}\\\\[.25cm]\n"
print(xtable(yap, align= c("@{\\extracolsep{\\fill}} l", "l", "l", rep("X", 8))),
      add.to.row= list(pos= list(-1, 0, 2, 4, 7, 10),
                       command= c(ctmp, rep("\\midrule\n", 4),
                                  "\\bottomrule\\hline\n")),
      tabular.environment= "tabularx", width= "\\textwidth",
      include.rownames= FALSE, hline.after = NULL, floating= FALSE)
#+end_src

#+RESULTS:
[[file:Tables/Decoldmp.tex]]

* Figures
** Commune descriptive map
*** Elevation file

    Pas besoin de tourner à chaque fois

#+begin_src R
library(data.table) ; library(raster)
Dat.Dem <- fread("Data/VITI_JSA_MH/vitidem.csv")
r <- rasterFromXYZ(Dat.Dem[, c('XL93', 'YL93', 'DEM')])
proj4string(r) <- proj4string(MapCom)
ss <- aggregate(r, fact= 10, mean)
bks <- seq(180, 580, length.out= 9)
library(SpatialPosition)
Grid.Dem <- rasterToContourPoly(ss, breaks= bks, mask= Bord.Area)
GDem <- spTransform(Grid.Dem, CRS("+proj=longlat +ellps=WGS84"))
class(GDem)
save(GDem, file= "Inter/GDem.Rda")
#+end_src

*** Map 1

#+begin_src R
library(rgdal)
MapCom <- readOGR("Carto/", "MapCom")
library(maptools) ; library(sp) ; library(sf)
Bord.Area <- unionSpatialPolygons(MapCom, rep(1, nrow(MapCom)))
MCom <- spTransform(MapCom, CRS("+proj=longlat +ellps=WGS84"))
BArea <- spTransform(Bord.Area, CRS("+proj=longlat +ellps=WGS84"))
ff <- readOGR("Carto/", "COML93")
gg <- subset(ff, !CODE_DEPT %in% c("2A", "2B"))
Fr.Area <- unionSpatialPolygons(gg, rep(1, nrow(gg)))
hh <- subset(ff, CODE_DEPT== "21")
Cd.Area <- unionSpatialPolygons(hh, rep(1, nrow(hh)))
FArea <- spTransform(Fr.Area, CRS("+proj=longlat +ellps=WGS84"))
CArea <- spTransform(Cd.Area, CRS("+proj=longlat +ellps=WGS84"))

pdf("Figures/MapCom1.pdf", width= 7, height= 9)
par(mar = c(0, 0, 0, 0))
plot(as(BArea, "Spatial"), expandBB= c(0, 0, 0, 0))
plot(gl <- gridlines(BArea, easts= c(4.7, 4.8, 4.9, 5),
                     norths= c(47.0, 47.1, 47.2, 47.3)),
     add= TRUE, col = grey(.8), lty= 2)
text(labels(gl), col = grey(.5))
load("Inter/GDem.Rda") ; k <- st_as_sf(GDem)
k <- k[order(k$center),]
library(RColorBrewer)
cols <- brewer.pal(n = 9, name = "Greys")

for (i in 1: nrow(k)){
    p <- st_geometry(k[i,])
    plot(p+ c(-.001, .001), add= T, border= "#ffffff90", col= "#ffffff90")
    plot(p+ c(.001, -.001), add=T, col= "#00000090", border= "#00000090")
    plot(p, col = cols[ i], border = "NA", add= T)  
}
library(cartography)
bks <- seq(180, 580, length.out= 9)
legendChoro(pos = "right", breaks = bks, col = cols, nodata = F,
            title.txt = "Elevation\n (meters)", horiz= FALSE,
            cex= 1, values.cex= 1, title.cex= 1)
library(TeachingDemos) ; library(prettymapr)
addscalebar(plotepsg= "4326", lwd= 1.2, padin= c(1, 0.5),
            widthhint= .1, style= "ticks", pos= "bottomright")
addnortharrow(pos= "bottomright", padin= c(1, 1), scale= .8)
plot(MCom, add= TRUE, lty= 4)
text(coordinates(MCom[MCom$REGION== "Ouche Dij" ,]), "DIJON")
plot(BArea, add= TRUE)
par(fig = c(c(.15, .5), c(.65, .9)), mar = c(0,0,0,0), new = TRUE)
plot(as(FArea, "Spatial"), expandBB= c(.1, .25, 0, .05),
     bg= "white", col= "white")
plot(gridlines(FArea), add= TRUE, col = grey(.8), lty= 2)
text(labels(gridlines(FArea)), col = grey(.5), cex= .75)
box(col = "grey20", lwd = 2, bg= "white")
plot(FArea, add= TRUE)
plot(BArea, add= TRUE, col= "black")
plot(CArea, add= TRUE)
##text(coordinates(CArea)- c(3.8, 0), "Côte d'Or")
points(rbind(c(2.217999, 48.512381), c(4.508372, 45.4550555)),
       pch= 10, cex= .5)
text(2.21, 48.51+ .5, "Paris", cex= .75)
text(4.508372, 45.4550555- .5, "Lyon", cex= .75)
dev.off()
#+end_src

*** Map 2

#+begin_src R
load("Inter/GeoRas.Rda")
Geo.Ras$AOCc <- ifelse(Geo.Ras$GCRU== 1, 5,
                ifelse(Geo.Ras$PCRU== 1, 4,
                ifelse(Geo.Ras$VILL== 1 | Geo.Ras$COMM== 1, 3,
                ifelse(Geo.Ras$BOUR== 1, 2, 1))))
library(rgeos)
tmp_geo <- gBuffer(Geo.Ras, byid= TRUE, width= 0)
Poly.Ras <- unionSpatialPolygons(tmp_geo, Geo.Ras$AOCc)
Poly.ras <- spTransform(Poly.Ras, CRS("+proj=longlat +ellps=WGS84"))
Poly.ras$AOC <- as.character(row.names(Poly.ras))

pdf("Figures/MapCom2.pdf", width= 9, height= 9)

par(mar = c(0, 0, 0, 0))
plot(as(BArea, "Spatial"), expandBB= c(0, 0, 0, 0))
plot(gl <- gridlines(BArea, easts= c(4.7, 4.8, 4.9, 5),
                     norths= c(47.0, 47.1, 47.2, 47.3)),
     add= TRUE, col = grey(.8), lty= 2)
text(labels(gl), col = grey(.5))
my.palette <- brewer.pal(n = 5, name = "BuPu")
Poly.ras$COLOR <- ifelse(Poly.ras$AOC== 1, my.palette[ 1],
                  ifelse(Poly.ras$AOC== 2, my.palette[ 2],
                  ifelse(Poly.ras$AOC== 3, my.palette[ 3],
                  ifelse(Poly.ras$AOC== 4, my.palette[ 4],
                         my.palette[ 5]))))
plot(Poly.ras, col= Poly.ras$COLOR, border= NA, add= TRUE)

CDN <- subset(MCom, REGION== "CDN")
text(4.85, 47.305, bquote(~ underline("CÔTE DE NUITS")), adj= 1)
text(4.85, 47.305- 1: nrow(CDN)/ 85,
     paste(CDN$NOM_COMM[order(CDN$Y_CENTROID, decreasing= TRUE)],
           "-", 1: nrow(CDN)), adj= 1)
## FUNCTION AT THE BOTTOM
shadowtext(coordinates(CDN)[order(CDN$Y_CENTROID, decreasing= TRUE), ],
           labels=  1: nrow(CDN), bg= "white", r=.1, col="black", cex= 1)
plot(CDN, add= TRUE, lty= 2)
CDB <- subset(MCom, REGION== "CDB")
text(5, 47.1, bquote(~underline("CÔTE DE BEAUNE")), adj= 0)
text(5, 47.1- 1: nrow(CDB)/ 85 , paste(nrow(CDN)+ 1: nrow(CDB), "-",
     CDB$NOM_COMM[order(CDB$Y_CENTROID, decreasing= TRUE)]), adj= 0)
shadowtext(coordinates(CDB)[order(CDB$Y_CENTROID, decreasing= TRUE), ],
           labels= nrow(CDN)+ 1: nrow(CDB), bg= "white", r= .1,
           col= "black", cex= 1)
plot(CDB, add= TRUE, lty= 2)
plot(BArea, add= TRUE, col= NA, lwd= 2)
text(coordinates(MCom[MCom$REGION== "Ouche Dij" ,]), "DIJON")
legend(5.04, 47.28, c("Côteaux Bourguignons", "Bourgogne Régional",
                    "Village","Premier Cru","Grand Cru"), cex= 1.2,
       fill= my.palette, title= "GI: vertical dimension", bty= "n")
dev.off()
## segments(rep(4.855, nrow(CDN)), 47.305- 1: nrow(CDN)/ 85,
##          coordinates(CDN)[order(CDN$Y_CENTROID, decreasing= TRUE), 1],
##          coordinates(CDN)[order(CDN$Y_CENTROID, decreasing= TRUE), 2])
## segments(rep(4.995, nrow(CDB)), 47.1- 1: nrow(CDB)/ 85,
##          coordinates(CDB)[order(CDB$Y_CENTROID, decreasing= TRUE), 1],
##          coordinates(CDB)[order(CDB$Y_CENTROID, decreasing= TRUE), 2])
##plot(ARank[ARank$AOC!= "NONE", ], add= TRUE, col= "blue", pch= 15, cex= .1)
## library(viridis)
## plot(ss, col= inferno(256, alpha= 1))
## slope = terrain(ss, opt='slope')
## aspect = terrain(ss, opt='aspect')
## hill = hillShade(slope, aspect, 40, 270)
## plot(hill, col=grey(0:100/100), legend=FALSE, main='Switzerland')
## shadowtext <- function(x, y=NULL, labels, col='white', bg='black',
##                     theta= seq(pi/4, 2*pi, length.out=8), r=0.1, ... ) {
##    xy <- xy.coords(x,y)
##    xo <- r*strwidth('x')
##    yo <- r*strheight('x')
 
##    for (i in theta) {
##      text( xy$x + cos(i)*xo, xy$y + sin(i)*yo, labels, col=bg, ... )
##    }
##    text(xy$x, xy$y, labels, col=col, ... )
##  }
#+end_src

#+RESULTS:
: X11cairo 
:        2

** Multi gam effects New AOCs

#+begin_src R 
load("Inter/gamod.Rda") ; library(Hmisc)
por1c <- polr(factor(AOCc)~ LIBCOM+ EXPO
              + poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
              + poly(X, 3)* poly(Y, 3)
            , data= RRank, Hess= T)

prdTerms <- lapply(gamod, function(x) predict(x, type= "terms", se= TRUE))
grcol <- rev(gray.colors(length(gamod)))

pdf("Figures/PltEff.pdf", width= 6, height= 8)
par(mfrow= c(3, 1), mar= c(2, 4, 2, 2))
plot(0, type= "n", xlim= c(219, 450), ylim= c(-15, 6.5), xlab= "",
     main= "", ylab= "Marginal Effect (centered)")
legend("topleft", "A - Elevation (meter)", cex= 1.2, bty= "n")
dem.for <- order(RRank$DEM)
for (i in 1: length(prdTerms)){
    lines(RRank$DEM[dem.for ], prdTerms[[ i]]$fit[dem.for, "s(DEM)"],
          col= grcol[ i], lwd= 1.2)
}
prdDem <- data.frame(DEM= RRank$DEM, SLOPE= mean(RRank$SLOPE),
                     RAYAT= 0, EXPO= "0-45", LIBCOM= "FIXIN",
                     X= mean(RRank$X), Y= mean(RRank$Y))
gg <- -qlogis(predict(por1c, newdata= prdDem, type= 'probs')[, 1])
lines(RRank$DEM[dem.for ], gg[dem.for ]- mean(gg),
      col= "#1F78B4", lwd= 1.2, lty= 2)
histSpike(RRank$DEM, add=TRUE, frac= .2, lwd = 4, nint= 120)

plot(0, type= "n", xlim= c(0, 35), ylim= c(-2.5, 2.5), xlab= "", 
     main= "", ylab= "Marginal Effect (centered)")
legend("topleft", "B - Slope (degree)", cex= 1.2, bty= "n")
slp.for <- order(RRank$SLOPE)
for (i in 1: length(prdTerms)){
    lines(RRank$SLOPE[slp.for ], prdTerms[[ i]]$fit[slp.for, "s(SLOPE)"],
          col= grcol[ i], lwd= 1.2)
}
prdSlp <- data.frame(DEM= mean(RRank$DEM), SLOPE= RRank$SLOPE,
                     RAYAT= 0, EXPO= "0-45", LIBCOM= "FIXIN",
                     X= mean(RRank$X), Y= mean(RRank$Y))
gg <- -qlogis(predict(por1c, newdata= prdSlp, type= 'probs')[, 1])
lines(RRank$SLOPE[slp.for ], gg[slp.for ]- mean(gg),
      col= "#1F78B4", lwd= 1.2, lty= 2)
histSpike(RRank$SLOPE, add=TRUE, frac= .2, lwd = 4, nint= 110) 

plot(0, type= "n", xlim= c(-4, 3.25), ylim= c(-3.5, 1.5), xlab= "",
     main= "",ylab="Marginal effect (centered)")
legend("topleft", "C- Solar Radiation (scaled)", cex= 1.2, bty= "n")
ray.for <- order(RRank$RAYAT)
for (i in 1: length(prdTerms)){
    lines(RRank$RAYAT[ray.for ], prdTerms[[ i]]$fit[ray.for, "s(RAYAT)"],
          col= grcol[ i], lwd= 1.2)
}
prdRay <- data.frame(DEM= mean(RRank$DEM), SLOPE= mean(RRank$SLOPE),
                     RAYAT= RRank$RAYAT, EXPO= "0-45", LIBCOM= "FIXIN",
                     X= mean(RRank$X), Y= mean(RRank$Y))
gg <- -qlogis(predict(por1c, newdata= prdRay, type= 'probs')[, 1])
lines(RRank$RAYAT[ray.for ], gg[ray.for ]- mean(gg),
      col= "#1F78B4", lwd= 1.2, lty= 2)
histSpike(RRank$RAYAT, add=TRUE, frac= .2, lwd = 4, nint= 175) 
dev.off()
## lcl <- fit - 1.96 * se
## ucl <- fit + 1.96 * se
## x.polygon <- c(RRank$DEM[i.for ], RRank$DEM[i.back ])
## y.polygon <- c(ucl[i.for ], lcl[i.back ] )
## polygon(x.polygon, y.polygon, col= "#A6CEE3", border= NA)
#+end_src

#+RESULTS:
: X11cairo 
:        2

** Multi gam effects Old AOCs

#+begin_src R 
## load("Inter/gamold.Rda") ; library(Hmisc)
## por2c <- polr(factor(AOCavt)~ LIBCOM+ EXPO
##               + poly(DEM, 2)+ poly(SLOPE, 2)+ poly(RAYAT, 2)
##               + poly(X, 3)* poly(Y, 3)
##             , data= SRank, Hess= T)
## prdTerms <- lapply(gamold, function(x) predict(x, type= "terms", se= TRUE))
## grcol <- rev(gray.colors(length(gamold)))

pdf("Figures/PltEffOld.pdf", width= 6, height= 8)
par(mfrow= c(3, 1), mar= c(2, 4, 2, 2))
plot(0, type= "n", xlim= c(219, 450), ylim= c(-15, 6.5), xlab= "",
     main= "", ylab= "Marginal Effect (centered)")
legend("topleft", "A - Elevation (meter)", cex= 1.2, bty= "n")
dem.for <- order(SRank$DEM)
for (i in 1: length(prdTerms)){
    lines(SRank$DEM[dem.for ], prdTerms[[ i]]$fit[dem.for, "s(DEM)"],
          col= grcol[ i], lwd= 1.2)
}
prdDem <- data.frame(DEM= SRank$DEM, SLOPE= mean(SRank$SLOPE),
                     RAYAT= 0, EXPO= "45-90", LIBCOM= "VOUGEOT",
                     X= mean(SRank$X), Y= mean(SRank$Y))
gg <- -qlogis(predict(por2c, newdata= prdDem, type= 'probs')[, 1])
lines(SRank$DEM[dem.for ], gg[dem.for ]- mean(gg),
      col= "#1F78B4", lwd= 1.2, lty= 2)
histSpike(SRank$DEM, add=TRUE, frac= .2, lwd = 4, nint= 120)

plot(0, type= "n", xlim= c(0, 35), ylim= c(-2.5, 2.5), xlab= "", 
     main= "", ylab= "Marginal Effect (centered)")
legend("topleft", "B - Slope (degree)", cex= 1.2, bty= "n")
slp.for <- order(SRank$SLOPE)
for (i in 1: length(prdTerms)){
    lines(SRank$SLOPE[slp.for ], prdTerms[[ i]]$fit[slp.for, "s(SLOPE)"],
          col= grcol[ i], lwd= 1.2)
}
prdSlp <- data.frame(DEM= mean(SRank$DEM), SLOPE= SRank$SLOPE,
                     RAYAT= 0, EXPO= "0-45", LIBCOM= "FIXIN",
                     X= mean(SRank$X), Y= mean(SRank$Y))
gg <- -qlogis(predict(por2c, newdata= prdSlp, type= 'probs')[, 1])
lines(SRank$SLOPE[slp.for ], gg[slp.for ]- mean(gg),
      col= "#1F78B4", lwd= 1.2, lty= 2)
histSpike(RRank$SLOPE, add=TRUE, frac= .2, lwd = 4, nint= 110) 

plot(0, type= "n", xlim= c(-4, 3.25), ylim= c(-3.5, 1.5), xlab= "",
     main= "",ylab="Marginal effect (centered)")
legend("topleft", "C- Solar Radiation (scaled)", cex= 1.2, bty= "n")
ray.for <- order(SRank$RAYAT)
for (i in 1: length(prdTerms)){
    lines(SRank$RAYAT[ray.for ], prdTerms[[ i]]$fit[ray.for, "s(RAYAT)"],
          col= grcol[ i], lwd= 1.2)
}
prdRay <- data.frame(DEM= mean(SRank$DEM), SLOPE= mean(SRank$SLOPE),
                     RAYAT= SRank$RAYAT, EXPO= "0-45", LIBCOM= "FIXIN",
                     X= mean(SRank$X), Y= mean(SRank$Y))
gg <- -qlogis(predict(por2c, newdata= prdRay, type= 'probs')[, 1])
lines(SRank$RAYAT[ray.for ], gg[ray.for ]- mean(gg),
      col= "#1F78B4", lwd= 1.2, lty= 2)
histSpike(SRank$RAYAT, add=TRUE, frac= .2, lwd = 4, nint= 175) 
dev.off()
## lcl <- fit - 1.96 * se
## ucl <- fit + 1.96 * se
## x.polygon <- c(RRank$DEM[i.for ], RRank$DEM[i.back ])
## y.polygon <- c(ucl[i.for ], lcl[i.back ] )
## polygon(x.polygon, y.polygon, col= "#A6CEE3", border= NA)
#+end_src

#+RESULTS:
: X11cairo 
:        2

** Smoothed gam surface New AOCs

#+begin_src R
library(rgdal) ; library(maptools) ; library(sp)
MapCom <- readOGR("Carto/", "MapCom")
Bord.Area <- unionSpatialPolygons(MapCom[MapCom$NOM_COMM!= "DIJON", ],
                                  rep(1, nrow(MapCom)- 1))
MCom <- spTransform(MapCom, CRS("+proj=longlat +ellps=WGS84"))
BArea <- spTransform(Bord.Area, CRS("+proj=longlat +ellps=WGS84"))
i= .1
GG <- data.frame(expand.grid(X= seq(min(RRank$X)- i,
                                    max(RRank$X)+ i, length.out= 100),
                             Y= seq(min(RRank$Y)- i,
                                    max(RRank$Y)+ i, length.out= 100)),
                 "VOUGEOT",mean(RRank$DEM), mean(RRank$SLOPE), 0, "90-135")
names(GG)[ 3: 7] <- c("LIBCOM", "DEM", "SLOPE", "RAYAT", "EXPO")

tmp <- -qlogis(predict(por1c, newdata= GG, type= "probs")[, 3]+ 1e-6)
GG$por1 <- (tmp- min(tmp))/ (max(tmp)- min(tmp))
GG$por1 <- 0.5+ GG$por1/ 2

fctPrd <- function(mod){
    tmp <- predict(mod, newdata= GG)
    (tmp- min(tmp))/ (max(tmp)- min(tmp))
}
HH <- cbind(GG, sapply(gamod[ 1: 5* 2], fctPrd))
hh <- SpatialPixelsDataFrame(HH[, c("X", "Y")], HH,
                             proj4string=CRS("+proj=longlat +ellps=WGS84"))
library(viridis)

ttl <- paste0("Model ( ", c("0", "I", "II", "III", "IV", "V"), " ) - ")
names(ttl) <- names(hh)[ 8: 13]

pdf("Figures/SmoothMap.pdf", width= 12, height= 8)
par(mar= c(0, 0, 0, 0))
layout(rbind(c(1, 2, 3, 7),
             c(4, 5, 6, 7)), widths = c(4,4,4,1))
for (i in names(hh)[ 8: 13]){
    plot(hh[!is.na(over(hh, BArea)), i],
         xlim= c(4.65, 5.1), what= "image", axes= TRUE, zlim= c(.5, 1),
         ylim= c(46.9, 47.31), col= inferno(256, alpha= 1))
    contour(hh[!is.na(over(hh, BArea)), i], add= TRUE, col= "white")
    plot(BArea, add= TRUE, lwd= 2) ; box()
    if (i== "por1") { title(paste0(ttl[ i], " Quadratic parametric"))
    } else {
            title(paste0(ttl[ i], "Effective degree of freedom : ",
                         round(summary(gamod[[ i]])$edf[ 4], 2)))}
}
plot(hh[, "gam100"],
     what= "scale", scale.size = lcm(1.4), zlim= c(.5, 1),
     ylim= c(46.9, 47.31), col= inferno(256, alpha= 1))
dev.off()
#+end_src

** Smoothed gam surface Old AOCs

#+begin_src R
library(rgdal) ; library(maptools) ; library(sp)
MapCom <- readOGR("Carto/", "MapCom")
Bord.Area <- unionSpatialPolygons(MapCom[MapCom$NOM_COMM!= "DIJON", ],
                                  rep(1, nrow(MapCom)- 1))
MCom <- spTransform(MapCom, CRS("+proj=longlat +ellps=WGS84"))
BArea <- spTransform(Bord.Area, CRS("+proj=longlat +ellps=WGS84"))
i= .1
GG <- data.frame(expand.grid(X= seq(min(SRank$X)- i,
                                    max(SRank$X)+ i, length.out= 100),
                             Y= seq(min(SRank$Y)- i,
                                    max(SRank$Y)+ i, length.out= 100)),
                 "VOUGEOT",mean(SRank$DEM), mean(SRank$SLOPE), 0, "90-135")
names(GG)[ 3: 7] <- c("LIBCOM", "DEM", "SLOPE", "RAYAT", "EXPO")

tmp <- -qlogis(predict(por2c, newdata= GG, type= "probs")[, 2]+1e-10)
GG$por2 <- (tmp- min(tmp))/ (max(tmp)- min(tmp))
GG$por2 <- 0.5+ GG$por2/ 2

load("Inter/gamold.Rda")
fctPrd <- function(mod){
    tmp <- predict(mod, newdata= GG)
    (tmp- min(tmp))/ (max(tmp)- min(tmp))
}
HH <- cbind(GG, sapply(gamold[ 3: 7], fctPrd))
hh <- SpatialPixelsDataFrame(HH[, c("X", "Y")], HH,
                             proj4string=CRS("+proj=longlat +ellps=WGS84"))

library(viridis)
pdf("Figures/SmoothMapOld.pdf", width= 12, height= 8)
par(mar= c(0, 0, 0, 0))
layout(rbind(c(1, 2, 3, 7), c(4, 5, 6, 7)), widths = c(4,4,4,1))
for (i in names(hh)[ 8: 13]){
    plot(hh[!is.na(over(hh, BArea)), i],
         xlim= c(4.65, 5.1), what= "image", axes= TRUE, zlim= c(.5, 1.01),
         ylim= c(46.9, 47.31), col= inferno(256, alpha= 1))
    contour(hh[!is.na(over(hh, BArea)), i], add= TRUE, col= "white")
    plot(BArea, add= TRUE, lwd= 2) ; box()
    if (i== "por2") { title("Quadratic parametric")
    } else {
            title(paste0("Effective degree of freedom : ",
                         round(summary(gamold[[ i]])$edf[ 4], 2)))}
}
plot(hh[, "gam100"],
     what= "scale", scale.size = lcm(0.4), zlim= c(.5, 1),
     ylim= c(46.9, 47.31), col= inferno(256, alpha= 1))
dev.off()
#+end_src

*** OLD smoothed gam surfaces
**** New GIs

#+begin_src R
library(rgdal)
MapCom <- readOGR("Carto/", "MapCom")
library(maptools) ; library(sp)
Bord.Area <- unionSpatialPolygons(MapCom[MapCom$NOM_COMM!= "DIJON", ],
                                  rep(1, nrow(MapCom)- 1))
MCom <- spTransform(MapCom, CRS("+proj=longlat +ellps=WGS84"))
BArea <- spTransform(Bord.Area, CRS("+proj=longlat +ellps=WGS84"))
gl = gridlines(BArea, easts= c(4.7, 4.8, 4.9, 5),
               norths= c(47.0, 47.1, 47.2, 47.3))
gll = labels(gl)

load("Inter/AocRank.Rda")
RegRank <- subset(AocRank, AocRank$PAOC!= 0 &
                  !is.na(AocRank$DEM) & !is.na(AocRank$CODEg))
RegRank$AOCc <- ifelse(RegRank$GCRU== 1, 5,
                ifelse(RegRank$PCRU== 1, 4,
                ifelse(RegRank$VILL== 1 | RegRank$COMM== 1, 3,
                ifelse(RegRank$BOUR== 1, 2, 1))))
RegRank$RAYAT <- with(RegRank@data, (SOLAR- mean(SOLAR))/ sd(SOLAR))

RegRank$EXPO <- factor(ifelse(RegRank$ASPECT< 45, "0-45",
                       ifelse(RegRank$ASPECT< 90, "45-90",
                       ifelse(RegRank$ASPECT<135, "90-135",
                       ifelse(RegRank$ASPECT<180, "135-180",
                       ifelse(RegRank$ASPECT<225, "180-225",
                       ifelse(RegRank$ASPECT<270, "225-270",
                       ifelse(RegRank$ASPECT<315, "270-315", "315-360"))))))),
                       levels= c("0-45", "45-90", "90-135", "135-180",
                                 "180-225","225-270","270-315","315-360"))
RRank <- spTransform(RegRank, CRS("+proj=longlat +ellps=WGS84"))
SSank <- as(RRank, "data.frame")
RRank$X= SSank$coords.x1
RRank$Y= SSank$coords.x2

load("Inter/gamod2.Rda")
i= .1
GG <- data.frame(expand.grid(X= seq(min(RRank$X)- i,
                                    max(RRank$X)+ i, length.out= 100),
                             Y= seq(min(RRank$Y)- i,
                                    max(RRank$Y)+ i, length.out= 100)),
                 LIBCOM= "FIXIN", DEM= mean(RRank$DEM),
                 SLOPE= mean(RRank$SLOPE), RAYAT= 0, EXPO= "180-225")
GG$gam50 <- predict(gamod2[[1]], newdata= GG)
GG$gam100 <- predict(gamod2[[2]], newdata= GG)
GG$gam200 <- predict(gamod2[[3]], newdata= GG)
GG$gam300 <- predict(gamod2[[4]], newdata= GG)
GG$gam400 <- predict(gamod2[[5]], newdata= GG)
GG$gam500 <- predict(gamod2[[6]], newdata= GG)
GG$gam600 <- predict(gamod2[[7]], newdata= GG)


GG$gam50N <- (GG$gam50- min(GG$gam50))/ (max(GG$gam50)- min(GG$gam50))
GG$gam100N <- (GG$gam100- min(GG$gam100))/ (max(GG$gam100)- min(GG$gam100))
GG$gam200N <- (GG$gam200- min(GG$gam200))/ (max(GG$gam200)- min(GG$gam200))
GG$gam300N <- (GG$gam300- min(GG$gam300))/ (max(GG$gam300)- min(GG$gam300))
GG$gam400N <- (GG$gam400- min(GG$gam400))/ (max(GG$gam400)- min(GG$gam400))
GG$gam500N <- (GG$gam500- min(GG$gam500))/ (max(GG$gam500)- min(GG$gam500))
GG$gam600N <- (GG$gam600- min(GG$gam600))/ (max(GG$gam600)- min(GG$gam600))


## GRID DATA FRAME
hh <- SpatialPixelsDataFrame(GG[, c("X", "Y")], GG,
                             proj4string=CRS("+proj=longlat +ellps=WGS84"))

BORD <- list(sp.polygons, MCom, lwd= 2, col= "black", cex= 1.2)

par(mar = c(0, 0, 0, 0), mfrow= c(2, 3))
plot(as(BArea, "Spatial"), expandBB= c(.1, 0, 0, 0))
plot(gl, add= TRUE, col = grey(.8), lty= 2)
text(gll, col = grey(.5))
plot(MCom, add= TRUE)
library(viridis)
plot(hh[!is.na(over(hh, BArea)), "gam200N"],
     col= inferno(256, alpha= 1), add= TRUE)
contour(hh[!is.na(over(hh, BArea)), "gam100N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)

pdf("Figures/SmoothMap.pdf")
par(mar= c(0, 0, 0, 0))
plot(hh[!is.na(over(hh, BArea)), "gam100N"], col= inferno(256, alpha= 1))
contour(hh[!is.na(over(hh, BArea)), "gam100N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
plot(hh[!is.na(over(hh, BArea)), "gam200N"], col= inferno(256, alpha= 1))
contour(hh[!is.na(over(hh, BArea)), "gam200N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
plot(hh[!is.na(over(hh, BArea)), "gam300N"], col= inferno(256, alpha= 1))
contour(hh[!is.na(over(hh, BArea)), "gam300N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
plot(hh[!is.na(over(hh, BArea)), "gam400N"], col= inferno(256, alpha= 1))
contour(hh[!is.na(over(hh, BArea)), "gam400N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
plot(hh[!is.na(over(hh, BArea)), "gam500N"], col= inferno(256, alpha= 1))
contour(hh[!is.na(over(hh, BArea)), "gam500N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
plot(hh[!is.na(over(hh, BArea)), "gam600N"], col= inferno(256, alpha= 1))
contour(hh[!is.na(over(hh, BArea)), "gam600N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
dev.off()



library(RColorBrewer)

spplot(hh[!is.na(over(hh, BArea)), ], "gam50N")

spplot(hh[!is.na(over(hh, BArea)), ], "gam600N")

library(dichromat)
library(RColorBrewer)
spplot(hh[!is.na(over(hh, BArea)), ], "gam300N",
       col.regions= rev(brewer.pal(n = 9, name = "BuPu")))

my.palette <- brewer.pal(n = 9, name = "BuPu")

spplot(hh[!is.na(over(hh, BArea)), ], c("gam50N", "gam200N"),
       col.regions = plasma(256),
       panel = function(x,y, ...){ 
           panel.gridplot(x,y, ...) 
           sp.polygons(MCom, col=1,fill=0, lwd= 2)
       }) 

#+end_src

**** Old GIs

#+begin_src R
library(rgdal)
MapCom <- readOGR("Carto/", "MapCom")
library(maptools) ; library(sp)
Bord.Area <- unionSpatialPolygons(MapCom[MapCom$NOM_COMM!= "DIJON", ],
                                  rep(1, nrow(MapCom)- 1))
MCom <- spTransform(MapCom, CRS("+proj=longlat +ellps=WGS84"))
BArea <- spTransform(Bord.Area, CRS("+proj=longlat +ellps=WGS84"))
gl = gridlines(BArea, easts= c(4.7, 4.8, 4.9, 5),
               norths= c(47.0, 47.1, 47.2, 47.3))
gll = labels(gl)


load("Inter/gamod4.Rda")
i= .1
GG <- data.frame(expand.grid(X= seq(min(SRank$X)- i,
                                    max(SRank$X)+ i, length.out= 100),
                             Y= seq(min(SRank$Y)- i,
                                    max(SRank$Y)+ i, length.out= 100)),
                 LIBCOM= "FIXIN", DEM= mean(SRank$DEM),
                 SLOPE= mean(SRank$SLOPE), RAYAT= 0, EXPO= "180-225")
GG$gam50 <- predict(gamod4[[1]], newdata= GG)
GG$gam100 <- predict(gamod4[[2]], newdata= GG)
GG$gam200 <- predict(gamod4[[3]], newdata= GG)
GG$gam300 <- predict(gamod4[[4]], newdata= GG)
GG$gam400 <- predict(gamod4[[5]], newdata= GG)
GG$gam500 <- predict(gamod4[[6]], newdata= GG)
GG$gam600 <- predict(gamod4[[7]], newdata= GG)


GG$gam50N <- (GG$gam50- min(GG$gam50))   / (max(GG$gam50)- min(GG$gam50))
GG$gam100N <- (GG$gam100- min(GG$gam100))/ (max(GG$gam100)- min(GG$gam100))
GG$gam200N <- (GG$gam200- min(GG$gam200))/ (max(GG$gam200)- min(GG$gam200))
GG$gam300N <- (GG$gam300- min(GG$gam300))/ (max(GG$gam300)- min(GG$gam300))
GG$gam400N <- (GG$gam400- min(GG$gam400))/ (max(GG$gam400)- min(GG$gam400))
GG$gam500N <- (GG$gam500- min(GG$gam500))/ (max(GG$gam500)- min(GG$gam500))
GG$gam600N <- (GG$gam600- min(GG$gam600))/ (max(GG$gam600)- min(GG$gam600))


hh <- SpatialPixelsDataFrame(GG[, c("X", "Y")], GG,
                             proj4string=CRS("+proj=longlat +ellps=WGS84"))
class(GG)

BORD <- list(sp.polygons, MCom, lwd= 2, col= "black", cex= 1.2)

par(mar = c(0, 0, 0, 0), mfrow= c(2, 3))
plot(as(BArea, "Spatial"), expandBB= c(.1, 0, 0, 0))
plot(gl, add= TRUE, col = grey(.8), lty= 2)
text(gll, col = grey(.5))
plot(MCom, add= TRUE)
library(viridis)
plot(BArea)
plot(hh[!is.na(over(hh, BArea)), "gam200N"],
     col= inferno(256, alpha= 1), add= TRUE)
contour(hh[!is.na(over(hh, BArea)), "gam100N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)


pdf("Figures/SmoothMapOldGI.pdf")
par(mar= c(0, 0, 0, 0))
layout(rbind(c(1, 2, 3, 7),
             c(4, 5, 6, 7)), widths = c(4,4,4,.5))

plot(hh[!is.na(over(hh, BArea)), "gam100N"], what= "scale", zlim= c(.5,1))


plot(hh[!is.na(over(hh, BArea)), "gam100N"],
     xlim= c(4.65, 5.1), what= "image",
     ylim= c(46.9, 47.35), col= inferno(256, alpha= 1), zlim= c(.5, 1))
contour(hh[!is.na(over(hh, BArea)), "gam100N"], add= TRUE, col= "white")
plot(MCom, add= TRUE) ; title("yopla (normalized)") ; box()

plot(hh[!is.na(over(hh, BArea)), "gam200N"],
     col= inferno(256, alpha= 1), zlim= c(.5, 1))
contour(hh[!is.na(over(hh, BArea)), "gam200N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)

plot(hh[!is.na(over(hh, BArea)), "gam300N"],
     col= inferno(256, alpha= 1), zlim= c(.5, 1))
contour(hh[!is.na(over(hh, BArea)), "gam300N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
plot(hh[!is.na(over(hh, BArea)), "gam400N"],
     col= inferno(256, alpha= 1), zlim= c(.5, 1))
contour(hh[!is.na(over(hh, BArea)), "gam400N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
plot(hh[!is.na(over(hh, BArea)), "gam500N"],
     col= inferno(256, alpha= 1), zlim= c(.5, 1))
contour(hh[!is.na(over(hh, BArea)), "gam500N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
plot(hh[!is.na(over(hh, BArea)), "gam600N"],
     col= inferno(256, alpha= 1), zlim= c(.5, 1))
contour(hh[!is.na(over(hh, BArea)), "gam600N"], add= TRUE, col= "white")
plot(MCom, add= TRUE)
dev.off()

#+end_src

* Working Paper
  :PROPERTIES:
  :EXPORT_FILE_NAME:    WorkingPaper.pdf
  :EXPORT_LATEX_CLASS:  WorkinPap
  :EXPORT_LANGUAGE:     en
  :EXPORT_OPTIONS:      TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc toc:nil H:3
  :EXPORT_TITLE:        @@latex: \vspace{-1cm} The informational content of geographical indications@@
  :EXPORT_AUTHOR:       @@latex:  Jean-Sauveur AY\footnote{ Contact: \url{jsay@inra.fr}, UMR CESAER with AgroSup Dijon, INRA, Université de Bourgogne Franche-Comté.  Adress: 25 boulevard Docteur Petitjean, 21000 Dijon (France).  Data and R codes are available from the repository \url{Github//yop}.} \\ INRA UMR CESAER @@
  :EXPORT_DATE:         Working Paper Version 0.1 : \today
  :EXPORT_LATEX_HEADER: \usepackage[T1]{fontenc} \usepackage[doublespacing]{setspace} \usepackage{tabularx, rotating, booktabs, pdflscape, amssymb, amsmath, amsthm, bbm, eurosym, pdflscape, txfonts, rotfloat, caption}\usepackage[para,online,flushleft]{threeparttable} 
  :END:
** Abstract                                  :noheading:
#+BEGIN_abstract
Geographical indications (GIs) convey information about the place of
production as a proxy for the quality of agricultural products.  The
quality of the GI proxy depends on its underlying sources of
variations, among tangible (topography, geology of land plots),
intangible (reputation, influence of landowners) and idiosyncratic
(random) determinants.  We propose to disentangle this informational
content for wine-related GIs of the /Côte d'Or/ region (Burgundy,
France).  Thanks to their hierarchical and nested structure, GIs are
shown to have a high informational content (a signal to noise ratio of
about 4) which could explain their support by the wine market.  We
apply an original signal decomposition to actual and alternative wine
classifications of the region (from history and from counterfactual
simulations) to show significant improvements of GIs in the last
century and potential guidelines for better designed GIs in the
future.\\

\textbf{Keywords}: Certification, wine production, strategic quality
disclosure, variance decomposition, ordered models.

\textbf{J.E.L. Codes:} C24, L15, Q13.\\
#+END_abstract
** Introduction
*** Importance of information                :noheading:

    Using the place of production to signal the quality of
    agricultural products is not consensual in trade relations
    citep:Josl06,USTR17.  It is nevertheless well recognized that
    distinguishing products of good quality from bad is fundamental
    for consumers and producers when the quality cannot be assessed
    before buying and selling choices are made citep:Aker70,Nels70.
    Thus, one stumble point in the debate is the extend to which
    geographical indications (GIs) provide information about product
    quality citep:WMCl05,YBMZ17.  We study this informational content
    of GIs through the econometric relationship between the natural
    and human characteristics of vineyards and the wine-related GIs of
    the /Côte d'Or/ region (Burgundy, France).

*** Why wine in Burgundy?                    :noheading:

    Wine is an emblematic agricultural product whose quality strongly
    depends on the natural conditions prevailing on production sites
    citep:JLom93,BTRM14,KKFG15,VLRR18.  Wine is also an experience
    good well-suited to study the transmission of quality information
    between producers and consumers citep:CLVi97,ANau07,Ashe08,Stor12.
    In Burgundy, the ranking of vineyards according to their quality
    potential for wine production has a long history that date back to
    the middle age, with numerous modifications that have resulted to
    the actual scheme citep:Jull16,More31,Lava55,Dang92,Garc11,WJac18.
    In short -- more details will be given in the next section -- the
    GIs that we study are fully based on the fine-scale location of
    the vineyard plots, with both a vertical and a horizontal
    dimension of differentiation.  The vertical dimension is a quality
    ranking with 5 items: /Côteaux Bourguignons/ < /Bourgogne
    Régional/ < /Bourgogne Village/ < /Premier Cru/ < /Grand Cru/.
    The horizontal dimension is the name of one among the 31
    /communes/ (i.e., administrative municipalities) without an
    explicit hierarchy between them : /Beaune/, /Gevrey-Chambertin/,
    /Pommard/, /Fixin/ for example.  Such a hierarchical and nested
    structure is now quite usual for wine-related GIs in France
    (Bordeaux, Rhône Valley, see citealp:GLRW17) and other
    wine-producing countries (Germany, United States and Italy, see
    citealp:Stor05,CMCG10,CSCa19).

*** Our contribution                         :noheading:

    Our main contribution is to identify the informational content of
    actual, past and counterfactual GI designation schemes for about
    $60\,000$ vineyard plots.  The informational content of GIs is
    defined as their ability to describe natural characteristics of
    production sites, according to the property that more informative
    signals lead to greater variability of conditional expectations
    citep:GPen10.  We propose to distinguish tangible, intangible and
    random information about production sites by decomposing the
    sources of variation of GIs citep:BSwa12.  The first set of
    tangible information relates to the natural attributes of vineyard
    plots that are known to impact wine quality: topography
    (elevation, slope, aspect), geology (subsoil material, soil depth,
    soil humidity) and climate (solar radiation, longitude, latitude).
    The quality of vineyard plots is revealed from the vertical
    differentiation of GIs by an econometric model that account for
    this ordered structure.  The second set of information relates to
    the human characteristics that have historically impacted the GI
    designation process.  Through the reputation of landowners, their
    influence with the decision makers or their collective actions,
    some administrative units have had a differential treatment that
    could bias the quality signal conveyed by the horizontal dimension
    of GIs.  Knowing the geographical co-variations between tangible
    and intangible variables and the difficulty to control for all
    tangible variables that impact vineyard quality (i.e., /terroir/
    variables), the major empirical challenge is to disentangle these
    two sources of variations.  We propose a semiparametric approach
    that exploits the precise location of vineyard plots to control
    for the unobserved spatial heterogeneity from /terroir/ through
    smooth functions of geographical coordinates citep:WPSa16.  The
    empirical strategy is based on the structural difference between
    the spatial continuity of /terroir/ and the discontinuity of
    administrative borders according to the axiom that nature makes no
    jumps.

*** Literature reputation                    :noheading:
    
    Our approach is related to the literature about reputation,
    quality disclosure and strategic certification that provides some
    guidance for the question at hand (see citealp:Bagw01,DJin10 for
    reviews).  The vineyard quality gradient that we study is based on
    characteristics given by the nature, contrary to models where
    quality is strategically chosen by producers
    citep:Shap82,BDWh87,ALiz01,JLes03,DMDi14.  The resulting
    exogeneity of these variables allows the empirical identification
    to be more transparent and to focus our analysis on the historical
    process that lead to the actual GI information put on wine
    bottles.  We argue that the long history of GIs designations
    allows to neglect the role of actual wine producers and their
    undoubtedly impact on wine quality.  In effect, as generations of
    producers succeed each other with numerous vineyards bought and
    sold, the informational content of GIs is a collective reputation
    issued from history dependence citep:Tiro96 and reasonably
    independent to actual individual reputations of producers.  This
    long run vineyard quality relies exclusively on the unchangeable
    location of productions sites, which precludes spurious
    correlation from the assortative matching between qualities and
    names as in cite:Tade99 (i.e., a GI name can not be sold without
    its associated vineyard natural quality).

*** Literature quality disclosure            :noheading:

    A large body of literature about wine quality disclosure is
    concerned with expert reviews and the use of this information by
    consumers.  Such ratings are shown to have mainly short run
    effects, both on the demand citep:FGro12 and the price of wines
    citep:ALVi08,DNau10.  The major problems about the aggregation
    citep:AQua99 and the relevance citep:CSto10,Bodi17 of these
    signals put some doubts about their own interest for consumers
    citep:AJon13.  Ratings by experts, judges or websites are also
    shown to be significantly divergent from historical GIs for
    Bordeaux wines citep:TMut11 probably because of their fundamental
    differences.  Ratings are exogenous paying year-to-year sources of
    information, while GIs are long run public certifications
    voluntarily put on bottle labels by producers.  This remark adds
    the tedious question of the endogenous adoption of quality
    disclosure such as GIs that could produce unintended economic
    consequences citep:HMDO99,BZJL18.  For wine-related GIs in
    Burgundy, their economic citep:CLVi00,CFlo10,SNCS13 and historical
    citep:MSwi18 importance is such that, to the best of our
    knowledge, the entirety of wine producers and sellers in the
    region puts the GIs as the main information message on bottle
    labels.

*** Literature certification                 :noheading:

    We find a high informational content of actual GIs in terms of the
    underlying tangible vineyard quality, with a variance of the
    signal 4 times higher than the variance of the noise (this
    corresponds to a R$^2$ of about 80 %).  This high informational
    content gets along with the evidence of some signal bias due to
    the intangible variations of GI designations.  Nevertheless, this
    bias has decreased since the creation of GIs in 1936 trough
    continuous evolution that happened.  This decreasing bias of GI
    designation schemes from history could be an illustration of the
    theory developed by cite:BLar92 about strategic information
    transmission.  We show that some administrative units have
    profited from their private information about vineyard quality to
    manipulate the GI signal and extract rents through undeserved high
    rated vineyards.  However, the hierarchical GI certification
    appears increasingly less biased, or more efficient in the sens of
    cite:DNab91: the probability that a vineyard plot gets classified
    at least in its category becomes higher than the probability of
    lower quality plots being classified in that category.  We also
    show that a monopolistic certifying party discloses useful
    information in the form of rank orderings as predicted by the
    theory of cite:Guer01.  This contrasts with models that found weak
    (if any) welfare gains associated to the information conveyed by a
    monopolistic certifying party citep:Shap86,Lizz99.  These two
    results suggest that the high informational content of GIs and
    their actual economic importance in Burgundy comes from their long
    history and their independent management.

*** Outline                                  :noheading:

    The following Section [[#Sec:1]] presents in greater details the
    historical and regional contexts, jointly with the data used.
    Section [[#Sec:2]] presents the data generating process under
    consideration (also called the population structural model), the
    signal decomposition framework and the econometric strategy.
    Section [[#Sec:3]] presents the results and Section [[#Sec:4]] concludes.

** Data
  :PROPERTIES:
  :CUSTOM_ID: Sec:1
  :END:
*** The /Côte d'Or/ region
   :PROPERTIES:
   :CUSTOM_ID: Sec:11
   :END:
**** Natural characteristics                 :noheading:

     The /Côte d'Or/ (literally, slope of gold) is a northeastern
     French administrative unit (/département/) included in the larger
     wine-producing region of Burgundy (\autoref{Fig:1}).  We study a
     subset of the most famous vineyards of this region that was
     granted World Heritage Status by UNESCO in 2015
     (https://whc.unesco.org/fr/list/1425).  The area under
     consideration is a strip of about 65 km on the north-south
     gradient of at most 5 km from east to west, located between
     latitudes 46.9 and 47.3 and longitudes 4.7 and 5 (World Geodetic
     System 1984).  The main natural attributes of vineyards in the
     area are illustrated by the distribution of elevation in the left
     panel of \autoref{Fig:1}.  The presence of /combes/ (dry valley)
     produces some rounded patterns with fine-scale variations of the
     typical topographical variables (elevation, slope and exposition)
     that are known to have some direct and indirect impacts on
     vineyard and wine quality.  Firstly, elevation is expected to
     determine wine quality principally through its indirect
     correlation with temperatures and atmospheric outcomes.
     Temperatures during the growing season and the harvest are
     determinant for the grape maturity cycle, sugar content and
     structure of aromas. The latitude position of vineyards also
     contents some information about temperature variations along the
     north-south gradient.  Secondly, slope is expected to have both a
     direct effect through the drainage capacity of vineyard plots and
     an indirect effect through the correlated soil characteristics
     (steeper soils are in general thinner).  The longitude variable
     is indirectly related to precipitations, as the hill at the west
     provides a protective barrier that limits rains and,
     consequently, soil moisture.  Thirdly, the exposition is expected
     to have a direct effect through sunshine cycles and indirect
     effect through its correlation with the wind, which is known to
     have a strong importance to dry grapes and to concentrate aromas.
     
# Local particularity in terms of (i) temperature hail and frost. the
# region less precipitation than its neighbors (less than 700mm/ year,
# up to 1000mm/year). Although this northern position compared to
# other French vineyards such as Bordeaux and Rhône Valley high solar
# with about 1300 and 1400 hours of sun between April and September.

**** Map                                     :noheading:

# Peut-être faire apparaître si les communes contiennent une AOC communale.
#+begin_export latex
\vspace{.5cm}
\begin{figure}[!h]
  \caption{\textbf{Vineyards of the \emph{Côte d'Or}, topography
      (left) and geographical indications (right)}\\[.1cm]
    \footnotesize Notes: Elevation on the left side map is decretized
    in 8 classes of 50 m intervals.  From the east to the west, the
    elevation is first convex then concave, which means that highest
    slopes are for average elevations.  GIs on the right side map are
    located on these highest slopes.  The spatial precision of the
    vertical dimension of GIs is such that, best vineyards classified
    as \emph{Grands Crus} are not visually well separated from just
    below \emph{Premiers Crus}.  The right panel also reports the
    names of the 31 \emph{communes} of the area, the horinzontal
    dimension of GIs.}\label{Fig:1}
  \centering\hspace{-2cm}
\begin{minipage}{.5\textwidth}
  \centering
 \includegraphics[scale= .4]{./Figures/MapCom1}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
 \includegraphics[scale= .4]{./Figures/MapCom2}
\end{minipage}
\end{figure}
#+end_export

*** Historical context
**** Until Lavalle                           :noheading:

    Some archaeological evidences locate the first vineyards in this
    region in the antiquity citep:Garc14.  The first written evidences
    date from the 7th century, with abbeys archives that describe the
    donation of vineyards between groups of Benedictines monks whose
    names are still used in actual GI classifications (/Abbayes de
    Bèze/, /de Saint-Vivant/ for instance).  The origin of Burgundy's
    vineyard classification can be found in the work of the
    Cistercians monks who delineate plots of land that produced wine
    of distinct character (12th century, citealp:Lava55).  However,
    the first exhaustive spatial delineation of the region is the
    administrative separation of /communes/ following the decree of
    1789 after the french revolution.  What we consider as the
    horizontal dimension happened before the vertical dimension of
    actual GIs (citealp:Garc11, p.40).  The delineation of /communes/
    was based on the spatial distribution of churches (usually built
    in the 9th-12th centuries) without the goal of signaling wine or
    vineyard quality.  The first exhaustive classification scheme
    about the quality of vineyards is due to cite:Lava55, a Professor
    of natural and medical history from Dijon university inspired from
    previous writings of other scientists cite:Jull16 and cite:More31.
    He provides a ranking of vineyards in 4 levels, from the best
    /Tête de Cuvée/ to /Première/, /Deuxième/ and /Troisième Cuvées/.
    The interaction between the horizontal and vertical dimension is
    of particular matter in his work, as he write (p.162, translation
    from the author) "I have studied the wines of each of the
    /communes/ of the /Côte/ as if the other /communes/ had not
    existed and the classification that I give is true only for each
    /commune/ taken in isolation."

**** After Lavalle                           :noheading:

     These two spatial delineations were merged in a map of the region
     in 1860 by the /Comité d'Agriculture et de Viticulture de
     l'Arrondissement de Beaune/, the local organization of wine
     producers of the time.  This map contains small modifications
     from the initial 1789 and 1855 classifications citep:WJac18 and
     was extensively used afterward as a legal basis to regulate wine
     trade in the region.  It opens an avenue for court trials,
     collective actions and lobbying about the right to use the names
     of both dimensions that are not yet called GIs to label the
     wines.  As it is well documented by cite:Jacq09, the capacity of
     producers and owners to negotiate or influence the judgments and
     the delineations was determinate by the /commune/ to which they
     belong, in particular regarding their reputation.  The author
     shows that there was an unequal treatment between /communes/ in
     terms of the vertical differentiation of vineyards, whereas the
     separation between advantaged and disadvantaged /communes/ is not
     well established as "the reputation of the wine-growing
     /communes/ of Burgundy is not an objectively measurable
     phenomenon" (p.189 of citealp:Jacq09, translation from the
     author).  In 1936, a French national institute was created (INAO)
     to legally manage what become the GIs of all wine regions of the
     country on a harmonized basis.  In Burgundy, the first official
     GIs are principally based on the map of 1860, jointly with the
     jurisprudence which has taken place since then.  Some important
     modifications are implemented during the 20th century with the
     creation of /Premiers Crus/ in 1943 and the fine-scale
     digitalization of plot-level delineation in a Geographical
     Information System after 2000.  The GIs are called /Appellation
     d'Origine Contrôlée/ in France since this period and corresponds
     to Protected Designation of Origin for the European Union
     (https://ec.europa.eu/agriculture/quality/schemes_en).

*** Actual GI classifications
**** Description                             :noheading:

    Actual GIs are a nest between a vertical quality ranking in 5
    items and a horizontal differentiation scheme through the name of
    one among the 31 administrative municipalities (/communes/) that
    are shown in the right panel of \autoref{Fig:1}.  The
    highest-quality vineyards are labeled /Grands Crus/, each of which
    has its own independent appellation title (ex: "/Clos de la
    Roche/" or "/Chevalier-Montrachet/").  There are 32 /Grands Crus/
    on the area, XX in the /Côte de Beaune/ (southern part) and XX in
    the /Côte de Nuits/ (northern part) for a total area of XX ha (XX
    %).  It follows in the hierarchy 532 /Premiers Crus/ which have to
    be associated with their /commune/ names on bottle labels (ex:
    "/Les Chaumes/" from /Vosne-Romanée/ or "/La Chapelle/" from
    /Auxey-Duresse/).  There are XX ha of /Premiers Crus/ in the /Côte
    de Beaune/ (XX %) and XX ha in the /Côte de Nuits/ (XX %).  The
    third vertical level corresponds to /Bourgogne Village/ with or
    without the name of the administrative /commune/ (ex: /Pommard
    Village/ or /Côte de Nuits Village/).  The vertical
    differentiation of GIs ends with /Bourgogne Réginal/ (XX ha, 25.9
    %) and /Coteaux Bourguignons/ (Xx ha, 16.3 %) that are sometimes
    grouped in a same /régional/ level.  Putting the name of the
    /commune/ where the vineyard is located is forbidden for these
    GIs.  The difference between these 2 lasts GIs was initially
    justified in terms of grape varieties (/Pinot noir/ or
    /Chardonnay/ for /Bourgogne Régional/ and /Gamay noir/ or
    /Aligoté/ for /Côteaux Bourguignons/) but this distinction is less
    and less relevant as /Pinot noir/ becomes the main variety in the
    region.

**** Confusion                               :noheading:

    The picture of actual GIs is not complete without the mention of
    the complexities that exists between the vertical and the
    horizontal dimensions, which lead to strong difficulties for
    actual consumers to distinguish their respective information
    signal.  It is important to note that the terms /commune/ and
    /village/ are often used as synonymous for rural areas of France,
    whereas the first is related to the horizontal dimension and the
    second for the vertical dimension.  In addition, some vertical
    items from /Grands Crus/, /Premiers Crus/ or even /Villages/
    dimensions can be located on two different contiguous /communes/:
    the /Grand Cru/ "/Bonnes Mares/" is shared between the /communes/
    of /Chambolle-Musigny/ and /Morey-Saint-Denis/, the /Fixin Premier
    Cru/ "/Clos de la Perrière/" is shared between the /communes/ of
    /Brochon/ and /Fixin/, the /Vosnes-Romanée/ /Village/ is shared
    between the /communes/ of /Vosnes-Romanée/ and /Flagey-Echézeaux/.
    Moreover, at the beginning of the 20th century, 10 /communes/ have
    chosen to add the names of their most famous /Grand Cru/ to their
    administrative names, for example /Aloxe-Corton/ or
    /Gevrey-Chambertin/.  This complexity reaches its climax in the
    two administrative /communes/ of /Chassagne-Montrachet/ and
    /Puligny-Montrachet/ that share the same /Grand Cru/
    "/Montrachet/" and have chosen to add it to their names.  However,
    the legal obligation to mention in large font the vertical items
    /Grands Crus/, /Premier Crus/, /Village/, /Régional/ on wine
    bottle labels suggests that this information is clearly
    identifiable to consumers.

*** Summary Statistics

     The region under study is quite homogeneous in terms of wine
     varieties (/Pinot Noir/ for red wines and /Chardonnay/ for white
     wines) and in terms of the actual economic structures of wine
     production, with the co-existence of small producers and
     wine-trader (/négociants/) located in bigger /communes/ of
     /Beaune/ and /Nuits-St-Georges/.  As shown by \autoref{Fig:1},
     the balanced distribution of topographic variables between and
     within the /communes/ is fundamental for the econometric analysis
     that follows.  It appears from the left panel that each /commune/
     approximately contains the whole range of elevation, slope and
     exposition.  The right panel shows that administrative
     delineations of /communes/ articulate with each other on the
     north-south gradient, which ensures sharp climatic differences.
     The \autoref{Tab:SD} of Appendix [[#App:A]] presents some descriptive
     statistics about the exhaustive plot-level data on the 31
     /communes/ of the area.  For about $60\,000$ vineyard plots of a
     small average size of $2\,000$ m$^2$ (about $0.5$ acres), the
     elevation is distributed between 200 and 500 m with an average of
     286 m.  Slopes have an average of 5.73 degrees with a high
     standard deviation (coefficient of variation of about 100 %).
     The solar radiation is scaled for numerical stability in
     econometric estimations, it is initially distributed from 0.5 to
     1.23 millions Joules with an average of 1 millions J.  To add
     flexibility in the estimations the aspect variable is discretized
     in 8 dummy variables for different radians ranges, which shows
     that more the 50 % of vineyard plots have a south-eastern
     exposition with radians between 90 and 180 degrees.  Our data
     contains both the current GIs both with the vertical dimension
     (named Current GI in the Table) and the horizontal dimension (not
     reported).  Les villages sont dans les communaux, we also have
     geological and pedological discrete vraibles not significant for
     our empirical strategy see RM.

** Models
   :PROPERTIES:
   :CUSTOM_ID: Sec:2
   :END:

   We first present the structural model of GI designation that is
   assumed to be the data generating process.  Secondly, we describe
   the decomposition of the vineyard quality signal from the GI
   information available to consumers.  Thirdly, we discuss the
   empirical challenge to separate the /terroir/ effects from the
   human influences and the specification procedure that we propose.

*** Structure of GIs 
**** Latent structure of quality             :noheading:

    The variation in soil and climate (i.e., /terroir/) between
    vineyard sites is the basis of the GI classification system.
    Vineyard quality signal in the long run of history is supposed to
    be an unknown function $q:\mathbb{R}^{K^*}\mapsto\mathbb{R}$ of
    the $K^*$ natural characteristics $X^*$ of each vineyard plots.
    From this scalar quality, GIs are designated through a continuous
    latent variable $y^*$ defined as the difference between the long
    run quality signal and an idiosyncratic random term $\xi$ that we
    call the designation noise:
#+begin_export latex
\begin{equation}
y^*= q(X^*)- \xi.
\end{equation}
#+end_export
    This mapping between the tangible /terroir/ characteristics $X^*$
    and the objective quality represents the accumulate knowledge from
    informed people that have contributed to the vineyard
    classification on the long run of history.  At this stage, we
    consider the latent variable as an unbiased (while not perfect)
    signal of the quality of vineyards with $\mathbb{E}(\xi\mid
    X^*)=0$.  The designation noise could be attributed to imperfect
    knowledge or anecdotal facts that cause random deviations around
    the signal.  The presence of designation noise is due to the
    absence of a deterministic rule between vineyard natural
    characteristics and the GIs, hence the orthogonality of the
    designation noise is more a definition than an assumption.  The
    adequacy between this quality signal and consumer preferences for
    the taste of wines and the related question of the value of the GI
    information would require economic data about wine prices or
    declared preferences that we do not use here.  Instead, we propose
    to evaluate the relevance of the GI information according to this
    long run quality signal which is different than evaluating the
    relevance of the quality signal itself.  The ordered structure of
    the vertical dimension of GIs explains our reference to vineyard
    and wine qualities.

**** Dimensions of GIs                       :noheading:

     The hierarchical structure of GIs is modeled through the
     multi-valued scalar $y \in \{ 1, \dots, 5\}$ that represents the
     vertical differentiation of GIs: /Côteaux Bourguignons/ <
     /Bourgogne Régional/ < /Bourgogne Village/ < /Premier Cru/ <
     /Grand Cru/.  The GI of a given vineyard plot is a crude
     measurement of the underlying latent variable through a
     threshold-crossing relationship:
#+begin_export latex
\begin{equation}
y= j \;\;\;\mbox{ $\Leftrightarrow$ }\;\;\; \alpha^{c}_{j-1}< y^*< \alpha^{c}_{j},\;\;\;\mbox{ for }\;\;\; j= 1, \dots, 5,\label{Eq:STR}
\end{equation}
#+end_export
     with $\alpha_0^c= -\infty < \alpha_1^c< \cdots < \alpha_5^c=
     +\infty$ for all $c\in\{1, \dots, 31\}$ by construction.  The
     exponent $c$ on the thresholds marks the /communes/ in which the
     vineyard are located among the 31 /communes/ of the area under
     consideration, i.e., the horizontal dimension of GIs.  The
     variations in the thresholds between /communes/ correspond to the
     differential treatments between administrative units that have
     been documented by historians and presented above.  For instance,
     a /commune/ $c_1$ has a preferential treatment in terms of
     /Premier Cru/ ($j=4$) if its corresponding thresholds are smaller
     than those of another given /commune/ $c_2$: $\alpha^{c_1}_{3}<
     \alpha^{c_2}_{3}$ and $\alpha^{c_1}_{4}< \alpha^{c_2}_{4}$.  This
     means that the quality requirements for /Premier Cru/ of the
     /commune/ $c_1$ are less stringent and, consequently, the average
     vineyard quality is smaller: $\mathbb{E}(y^*\mid y= 4, c= c_1)<
     \mathbb{E}(y^*\mid y= 4, c= c_2)$.@@latex:\footnote{The link with
     average quality from this last inequality requires the addtional
     assumption that $\mathbb{E}(\xi\mid X^*, c)= 0$, i.e., that the
     random part of the latent variable is unrelated between
     \emph{communes}.  We make this assumption in the rest of the
     paper, which has the same rationale than the orthogonality of
     designation noise in regard to \emph{terroir} variables presented
     above and implies it by the law of iterated expectations:
     $\mathbb{E}(\xi\mid X^*)= \mathbb{E}[\mathbb{E}(\xi\mid X^*,
     c)\mid X^*]=0$.}@@

**** Efficient case                          :noheading:

     Within a given /commune/, the ordered structure of GIs provides
     an efficient certification process according to the definition of
     cite:DNab91: the probability with which a vineyard get classified
     into at least its own quality category is higher than the
     probability with which another vineyard with lower quality levels
     will get classified into at least that category.  For two
     vineyard plots $1$ and $2$ with differentiated natural
     characteristics such that $q(X_1^*)> q(X_2^*)$ and located within
     the same /commune/ $c_0$, one can show that
     $\mbox{Prob}(y_{1}\geqslant j)> \mbox{Prob}(y_{2}\geqslant j)$
     for all $j$ because:
#+begin_export latex
\begin{equation}
\mbox{Prob}(y_{i}\geqslant j)= F\left[q(X_i^*)- \alpha_{j-1}^{c_0}\right],
           \;\;\;\mbox{ for }\;\;\; i= 1, 2.\label{eq:SM}
\end{equation}
#+end_export
     where $F$ is the strictly increasing cumulative distribution
     function of the designation noise $\xi$.  The efficiency of the
     GI designation scheme is also verified in the absence of
     threshold variations between /communes/ ($\alpha_j^c$ constant
     among $c$ for each $j$) which is equivalent to GI signal
     unbiasedness.

**** Ordinal superiority                     :noheading:

     The efficiency property and the absence of bias are no longer
     true for vineyard plots located in different /communes/, say
     $c_1$ and $c_2$ to continue with the same example.  The vineyard
     plot $2$ of lesser quality has a higher probability of being
     classified into at least $j_1$ (the GI quality category of $1$)
     if $\alpha_{j_1}^{c_2}- \alpha_{j_1}^{c_1}> q(X_1^*)- q(X_2^*)$.
     In this case, the preferential treatment accorded to the
     /commune/ $c_2$ is a source of bias in the GI classification that
     contradicts the efficiency of the vertical GI
     differentiation.@@latex:\footnote{$\alpha_{j_1}^{c_2}>
     \alpha_{j_1}^{c_1}$ is a necessary condition to have a higher
     probability for the vineyard plot $2$.}@@ In particular, the
     probability that another given plot 3 of the same quality that
     plot 1 while from another /commune/ $c_3$ is higher in the GI
     classification scheme corresponds to the ordinal superiority
     measure defined by cite:AKat17:
#+begin_export latex
\begin{equation}
\gamma^{j_1}_{3\mid 1}\equiv \mbox{Prob}(y_{3}> y_{1}\mid X^*_1)= F\left(\frac{\alpha_{j_1}^{c_3}- \alpha_{j_1}^{c_1}}{\sqrt{2}}\right).\label{Eq:OS}
\end{equation}
#+end_export
     We use the approximation that the cdf of the normalized
     difference between designation noises is equal to the marginal
     cdf (this approximation is exact in the case of a Gaussian
     distribution).  An appealing property of this measure of ordinal
     superiority is that it does not depend on the conditioning
     tangible characteristics $X^*_1$ of vineyard plots.  This allows
     a direct comparison between the horizontal dimension of GIs (the
     /communes/ $c$) for each vertical level $j$.  For a given
     /commune/ of reference (as $c_1$ in \autoref{Eq:OS}), this
     implies $30 \times 5= 150$ measures of ordinal superiority.
     Hence, we assume an additive separability between the horizontal
     and vertical intercepts to simplify a bit more: $\alpha^c_{j}=
     \alpha_{j}- \mu_c$.  The ordinal superiority measure between 2
     given /communes/ A and B becomes $\gamma_{A\mid B}=
     F\left[(\mu_{c_B}- \mu_{c_A})/ \sqrt{2}\right]$ regardless of
     $j$, which allows to divide by 5 the number of ordinal
     superiority statistics.  These 30 statistics provide some
     objective measures of the differential treatments that have been
     applied between /communes/ according to the GI vertical
     classification of their vineyards.

*** Informational content
**** General decomposition                   :noheading:

     Our formal analysis about the informational content of GIs is
     based on the framework of cite:GPen10 about information signal
     ordering, in addition to the variance decomposition formulas
     provided by cite:BSwa12.  According to the former paper, we
     consider GIs as an information structure, i.e., a joint
     distribution between the states of the world (unobserved long run
     vineyard qualities) and the GIs (respectively noted $y$ and $c$
     for their vertical and horizontal dimensions).  We propose to
     evaluate to what extend the observation of $y$ and $c$ from the
     labels of bottle allows the consumers to recover vineyard
     quality, with the precision criteria that a more informative
     signal leads to a more disperse distribution of expectations of
     the state of the world conditionally to the signal.  Contrary to
     cite:GPen10, we measure the dispersion through conditional
     variance of the signals as it is allowed by the work of
     cite:BSwa12.  This leads to 4 nested variance decomposition:
#+begin_export latex
\begin{align}
\mbox{\emph{Total decomposition :} }& \mathbb{V}(y^*)= \mathbb{V}[q(X^*)]+ \mathbb{V}[\xi]  \label{eq:dec1}\\
\mbox{\emph{Joint decomposition :} }& \mathbb{V}[q(X^*)]= \mathbb{V}\big\{\,\mathbb{E}[q(X^*)\mid y, c]\,\big\}
                                                          + \mathbb{E}\big\{\,\mathbb{V}[q(X^*)\mid y, c]\,\big\} \label{eq:dec2}\\
\mbox{\emph{Vertical decomposition :} }& \mathbb{V}\big\{\,\mathbb{E}[q(X^*)\mid y, c]\,\big\}=
                                                          \mathbb{V}\big\{\,\mathbb{E}[q(X^*)\mid y]\,\big\}
			                                + \mathbb{E}\big\{\,\mathbb{V}[\mathbb{E}(q(X^*)\mid y, c)\mid y]\,\big\} \label{eq:dec3}\\
\mbox{\emph{Horizontal decomposition :} }& \mathbb{V}\big\{\,\mathbb{E}[q(X^*)\mid y, c]\,\big\}=
                                                          \mathbb{V}\big\{\,\mathbb{E}[q(X^*)\mid c]\,\big\}
                                                        + \mathbb{E}\big\{\,\mathbb{V}[\mathbb{E}(q(X^*)\mid y, c)\mid c]\,\big\} \label{eq:dec4}
\end{align}
#+end_export

    The /total decomposition/ of \autoref{eq:dec1} comes from the law
    of total variance, the law of iterated expectations and the
    definition of designation errors by $\mathbb{E}(\xi\mid X^*)=0$.
    It describes the variance of the latent GI variable as the sum of
    a /signal variance/ and a /noise variance/ defined from the data
    generating process.  The signal to noise ratio
    $\mathbb{V}[q(X^*)]/\mathbb{V}[\xi]$ gives the proportion of
    relevant information conveyed by the continuous quality grade
    $q(X^*)$ in terms of the irrelevant information from the noise
    $\xi$.  This decomposition represents the maximum informational
    content that GIs can reach for the data generating process under
    consideration, which corresponds to the case where the continuous
    quality grade (or all tangible variables $X^*$) are conveyed to
    consumers through the label of bottle.

**** Joint decomposition                     :noheading:

     The /joint decomposition/ of \autoref{eq:dec2} comes from the law
     of total variance applied to the continuous quality grade
     citep:BSwa12.  It separates the part of the signal that is
     conveyed jointly by the vertical and the horizontal dimensions of
     GIs (the /joint signal/, which is the variance of the
     expectation) and the part that is lost due to this simplification
     of the continuous quality information (the /joint noise/, which
     is the expectation of the variance).  If the continuous quality
     grade $q(X^*)$ would be observable, the share of the /joint
     signal/ in terms of the /total signal/ defined previously would
     be the R$^2$ of the regression of $q(X^*)$ on the full set of
     dummy variables from $y$ and $c$.  According to the nested
     structure of the /total/ and /joint/ decomposition, we define the
     /joint informational content/ of horizontal and vertical
     dimensions of GIs as $\mathbb{V}\big\{\,\mathbb{E}[q(X^*)\mid y,
     c]\,\big\}/ \big(\mathbb{E}\big\{\,\mathbb{V}[q(X^*)\mid y,
     c]\,\big\}+ \mathbb{V}[\xi]\big)$.  This statistic measures the
     share of the vineyard quality information that is conveyed to
     consumers through both $y$ and $c$ dimensions of GIs.

**** Vertical decomposition                  :noheading:

     The /vertical decomposition/ of \autoref{eq:dec3} separates the
     /joint signal/ between the part that is conveyed through the
     vertical dimension of GIs (the /vertical signal/, the variance of
     the expectation) and the residual part that remains to the
     horizontal dimension (the /vertical residual/).  The first term
     represents the variance of the quality information that can be
     assessed by consumers only through the vertical dimension $y$ of
     GIs.  Consumers may choose to favor this dimension by choice
     based on their experience or they can have a bounded rationality
     due to limited cognitive ability to understand the full structure
     of GIs.  An important point is that in the absence of
     preferential treatment between /communes/ in the GI designation
     scheme, the residual part of this decomposition (the /vertical
     residual/) would tend to zero.  In such a case, the vertical
     dimension is unbiased and provide all the relevant information
     about vineyard quality available to consumers.  The only loss in
     information is due to the discretization of the continuous
     quality grade and the /joint signal/ is equal to the /vertical
     signal/.  We also propose to define a /vertical noise/ as the sum
     of the /vertical residual/ and the /joint noise/.  This
     corresponds to the information loss of using only the vertical
     dimension:
#+begin_export latex
\begin{align}
\mbox{\emph{Vertical noise :} }& \mathbb{E}\big\{\,\mathbb{V}[q(X^*)\mid y]\,\big\}=
\mathbb{E}\big\{\,\mathbb{V}[q(X^*)\mid y, c]\,\big\}+\mathbb{E}\big\{\,\mathbb{V}[\mathbb{E}(q(X^*)\mid y, c)\mid y]
\end{align}
#+end_export

**** Horizontal decomposition                :noheading:

     The last /horizontal decomposition/ of \autoref{eq:dec4} is the
     symmetric of the previous one as it defines a /horizontal signal/
     and a /horizontal residual/.  This means that the decomposition
     of the /joint signal/ between a /vertical/ and a /horizontal/
     part is non-unique, depending on the GI dimension that is
     privileged.  The first /horizontal signal/ measures the
     dispersion of the expectation of vineyard quality conditionally
     on the /commune/ of the vineyards.  This informational content is
     due both to the incidental spatial correlation between vineyard
     quality and /commune/ delineations, and to the historical factors
     that have made GI thresholds to depend on the /communes/.  In the
     absence of preferential treatment of certain /communes/, this
     signal is reliable as it indicates that some /communes/ have
     better tangible conditions to make wines of better quality.  As
     before, the residual part of the decomposition is the marginal
     gain of using the vertical dimension of GIs for consumers that
     rely only on the horizontal dimension.  We also define the
     /horizontal noise/ as the sum of the /joint noise/ and the
     /horizontal residual/, it corresponds to the loss in GIs signal
     of using only the horizontal dimension of GIs:
#+begin_export latex
\begin{align}
\mbox{\emph{Horizontal noise :} }& \mathbb{E}\big\{\,\mathbb{V}[q(X^*)\mid c]\,\big\}=
     \mathbb{E}\big\{\,\mathbb{V}[\mathbb{E}(q(X^*)\mid y, c)\mid c]+
     \mathbb{E}\big\{\,\mathbb{V}[q(X^*)\mid y, c]\,\big\}
\end{align}
#+end_export

*** Ordered Generalized Additive Model
**** General                                 :noheading:

     The identification of the unknown function $q(\cdot)$ that
     relates tangible attributes of vineyards to the underlying long
     run GI quality grade is subject to 2 empirical challenges that we
     consider jointly: the specification of the functional form for
     the effect on a given tangible variable $x_k$ and the presence of
     unobserved /terroir/ variables that impact vineyard quality.
     These unobserved effects from the econometrician point of view
     are taken into account in GI designations by observations on the
     field and knowledge of people involved in GI designations.  These
     are serious econometric concerns due to the potential confounding
     effects that such variables could have through their spurious
     correlations with /commune/ delineations that group together
     adjacent vineyard plots.  Identifying the information conveyed by
     GIs about tangible variables requires that all these /terroir/
     variables would be observable, which is unfortunately not the
     case and probably never will be.  We propose instead to estimate
     an Ordered Generalized Additive Model (OGAM,
     citealp:WPSa16,Wood17 with citealp:KWan03,LVEP15 for
     applications) that allows to specify semiparametrically the
     effect of each observed tangible variables and to control for
     omitted /terroir/ variables through a bivariate smoothing of
     geographical coordinates.  This identification strategy is based
     on our definition of /terroir/ as the full set of natural
     variables that impact long run vineyard quality.  As coming from
     natural processes, we consider them as spatially continuous
     according to the axiom that nature makes no jumps, in contrast to
     the discontinuities introduced by /commune/ administrative
     delineations related to intangible human determinants of GIs.

**** Reduced form                            :noheading:

     Consider that we only observe the realizations of a subset $X_i
     \subset X_i^*$ of the whole /terroir/ variables that are taken
     into account in the GI designation for a given vineyard plot $i=
     1, \dots, N$.  These observed tangible variables are elevation,
     slope, exposition solar radiation and geographical coordinates
     that are described to have both direct and indirect effects on
     vineyard quality.  By noting $C_i$ the row vector of dimension 31
     with $c_{ih}$ equals to 1 if the vineyard $i$ is located in the
     /commune/ $h$ and 0 otherwise, the specification of a logistic
     distribution for the reduced-form errors leads to a
     semiparametric ordered logit model that can be estimated by
     maximum likelihood:
#+begin_export latex
\begin{equation}
\mbox{Prob}(y_{i}> j\mid X_i, C_i)= \Lambda\big[ B(X_i)^\top\beta+ C_i^\top\mu- \alpha_{j}\big]\label{Eq:Mod}
\end{equation}
#+end_export
     where $\Lambda$ is the logistic cdf.  The intangible determinants
     that impact GIs through varying designation thresholds -- noted
     $\mu_c$ previously -- are taken into account by the dummy
     variables $C_i$ which work as /commune/ fixed effects.  In the
     absence of theoretical priors about the effects of all observed
     tangible variables $X_i$, we specify them through a series of
     functional transformations noted $B(\cdot)$ with an associated
     vector of coefficients $\beta$.  From an initial set of $K$
     observed tangible variables (with $K<K^*$) the series and the
     vector of coefficients are of dimension $\widetilde{K}=
     \sum\nolimits_k L_k$ where $L_k$ is the number of transformations
     used to specify the effect of each variable $x_k$.  For instance,
     a second-order polynomial specification for all observed tangible
     variables is noted $B(X_i)= [x_{1i}\; x_{1i}^2\; x_{2i} \;
     x_{2i}^2 \; \cdots \; x_{Ki} \; x_{Ki}^2]$ with a set of
     $\widetilde{K}= 2\times K$ coefficients to estimate.

**** Method of estimation                    :noheading:

     Polynomial specifications are shown empirically to have a limited
     performance to account for the complex interactions between
     natural characteristics of vineyards and the continuous quality
     grade used in GI designations.  Hence, we turn to semiparametric
     thin plate regression splines that have optimal smooth
     approximation properties according to cite:Wood17.  The matrix
     $B(X)$ is specified through additive low rank isotropic smoothers
     of the individual tangible variables $x_k$.  The cost of this
     additional flexibility is the need to estimate jointly a
     smoothing parameter that controls the penalization of the
     superfluous wiggliness.  Accordingly, the complexity of the
     spline transformations are determined endogenously for a given
     maximum basis reduction for each variable through a quadratic
     penalty.  The minimization of the penalized deviance is done by
     penalized iterated weighted least square and the smoothing
     parameter is estimated using a separate criterion from restricted
     maximum likelihood framework.  The computational details are
     given in cite:WPSa16.  The complexity of the effect of a given
     variable or of the whole model can be assessed through the
     effective degree of freedom that accounts for the endogenous
     penalization of any given dimension reduction (citealp:Wood17,
     p.273).  The most sensible point is the estimation of the
     smoothing parameter which is source of additional uncertainty,
     while cite:WPSa16 provide some corrections for inference and
     traditional goodness of fit measures such as Akaike Information
     Criteria.  

     # In practice then, choice of basis dimension has to remain a part
     # of model specification. But it is important to note that all the
     # choice is doing is to set an upper limit on the flexibility of a
     # term: the actual flexibility is controlled by the smoothing
     # parameters. Hence, provided that we do not make the basis
     # dimension too restrictively small, its exact value should have
     # only a small effect on the fitted model. However, there is one
     # subtle caveat: a function space with basis dimension 20 will
     # contain a larger space of functions with EDF 5 than will a
     # function space of dimension 10 (the numbers being arbitrary), so
     # that model fit tends to retain some sensitivity to basis
     # dimension, even if the appropriate EDF for a term is well below
     # its basis dimension? To choose basis dimension, test of residuals
     # as we propose here.

**** Diagnostic procedure                    :noheading:

     Goodness of fit measures provide information about predictive
     abilities of estimated parameters but give little guidance about
     the identification of the individual effects of the RHS variables
     that are impacted by the degree of smoothing of geographical
     coordinates.  To determine the sufficient complexity that allow
     to control for unobserved spatial heterogeneity correlated with
     /commune/ delineations, we use the surrogate residuals recently
     defined by cite:LZha18 in an auxiliary regression that does not
     take into account /commune/ fixed effects.  Using residuals for
     specification purpose has a long history in econometrics,
     complemented by generalized residuals for non linear outcomes
     citep:PHal83,GMRT87,CIri87.  Define a surrogate variable $S\mid
     X, y \sim \lambda\,\big[\,B(X)^\top\beta- \alpha_{y}\mid
     y\,\big]$ that follows a truncated logistic distribution
     conditionally on $y$, the observed distribution of the vertical
     dimension of GIs.  The principle of using the observed values of
     $y$ to estimate the residuals is shared by generalized residuals,
     the originality of the surrogate approach is to draw randomly the
     realizations instead of computing them analytically.  This allows
     to estimate the full distribution of model errors instead of only
     their first moments and sensibly extend the potential
     applications in regression diagnostics citep:LZha18.  We obtain
     the residuals from $N$ random draws of the surrogate variable
     $S_i$:
#+begin_export latex
\begin{equation}
R_i= S_i-\mathbb{E}(S_i)= S_i+ \alpha_{y_i}- B(X_i)^\top\beta
\end{equation}
#+end_export
     and regress them on the /commune/ fixed effects.  This allows to
     test the presence of correlated residual patterns after
     accounting only for tangible variables in auxiliary regressions.
     By increasing the complexity of $B(X_i)$ through increasing
     spline bases dimension of the smooth functions of geographical
     coordinates, the joint significance of /commune/ fixed effect
     decreases as the unobserved spatial patterns are increasingly
     accounted for.  Failing to reject the null hypothesis of a Fisher
     test of joint significance of /commune/ fixed effects is expected
     to determine that the sufficient complexity is attained by the
     auxiliary model.  Then, we estimate jointly the effect of
     tangible and intangible GI determinants in a full OGAM for the
     given degree of spatial smoothing as in any parametric regression
     framework.  Note that the F-tests are bootstrapped to take into
     account the additional uncertainty attributable to the random
     draws of surrogate residuals.

** Results
   :PROPERTIES:
   :CUSTOM_ID: Sec:3
   :END:
*** Models of GI designation
**** Text 1                                  :noheading:

    The model ( 0 ) in the second column of \autoref{Tab:1}
    corresponds to a standard ordered logit model with additive
    quadratic effects for each topographic variables, third-order
    polynomials with full interactions for spatial coordinates,
    /commune/ and exposition fixed effects.  The $\chi^2$ statistics
    of joint significance are equivalent to a F-test for non linear
    models.  They indicate that all series of variables are
    significant at 1 % level, with an overall pseudo-R$^2$ of 28.8 %.
    The most significant series of variables is the set of 30
    /commune/ dummies that corresponds to the intangible determinants
    of GIs delineations, closely followed by the spatial coordinates.
    Elevation, solar radiation, exposition and slope variables follow
    in decreasing order of joint significance, for an overall
    significance of tangible variables higher than intangible
    variables.  The quadratic effects of tangible variables are
    reported in \autoref{Fig:A1} of Appendix.  Elevation and slope
    variables have inverted-U effects with the highest vineyard
    quality at about 250 meters and 15 degrees.  The effect of solar
    radiation is linearly increasing and the southern expositions
    provides the higher marginal probability of a high GI
    classification (see the Reproducibility Material, RM, from the
    link at the title page of the article).  Panel A of
    \autoref{Fig:A2} in Appendix shows the marginal effects of spatial
    coordinates on the expected vineyard quality.  The third-order
    parametric specification with interactions produces some
    ellipsoidal smooth patterns with two central kernels that
    describes a core-periphery structure.  The values of /communes/
    fixed effects are interpreted in the next subsection in terms of
    ordinal superiority.

**** Table                                   :noheading:

#+begin_export latex
\begin{table}
\caption{\textbf{Joint variable significance for ordered models of GI designations}}\singlespacing
\newcolumntype{Y}{>{\centering\arraybackslash}X}\label{Tab:1}
\begin{threeparttable}
\input{Tables/VarSign1.tex}
\begin{tablenotes}\footnotesize
\item Notes: $^{**}$ accounts for joint significance at 1\% from the
  reported Chi-square statistics, effective degrees of freedom are
  inside brackets.  Column ( 0 ) corresponds to an ordered logit model
  with quadratic effects for elevation, slope and solar radiation
  (edf$= 2$) with a full interaction between 3-orders polynomials for
  longitude and latitude (edf$= 3+3+3\times 3= 15$) and with
  respectively 7 and 31 dummy variables for exposition and
  \emph{communes} fixed effects.  Models ( I ) to ( V ) are OGAMs with
  elevation, slope and solar radiation additively specified with a
  maximum of 9 edf, shrinked endogenously by a quadratic penalization.
  Spatial coordinates are specified in an increasing order of
  complexity with the maximum edf of 100, 300, 500, 700 and 900.  The
  last row reports the bootstraped Fisher statistics for the joint
  nullity of \emph{communes} fixed effects on surrogate residuals from
  auxiliary regressions without \emph{commune} dummies.
\end{tablenotes}
\end{threeparttable}
\end{table}
#+end_export

**** Text 2                                  :noheading:

     Following models ( I ) to ( V ) in \autoref{Tab:1} are OGAMs with
     increasing complexity in the smoothing of spatial coordinates
     from the left to the right, as it appears from the corresponding
     row of effective degrees of freedom.  The semiparametric
     structure of these models allows to keep the same degrees of
     freedom for exposition and /commune/ dummies of respectively 7
     and 31.  Increasing the complexity of the spline series that
     transform spatial coordinates increases slightly the pseudo-R$^2$
     to 75 % and the percent of good predictions to 90 % in the most
     complex OGAM ( V ) of the last column of the Table.
     Simultaneously, the joint significance of spatial coordinates
     increases while the significance of other explanatory variables
     decreases, as the spatial pattern of GIs are increasingly grasped
     by spatial coordinates to the detriment of other RHS variables.
     In addition to goodness-of-fit measures, \autoref{Fig:A1} of
     Appendix shows the interest of OGAMs relatively to the parametric
     model ( 0 ).  Panel A shows that the high effect of elevation on
     the 0-300 meters range are not present in the parametric model.
     The same is true for high effect of slopes on the 0-5 degrees
     range.  This results are particularly stringent as these ranges
     concentrate the majority of vineyards.  In terms of spatial
     smooth effects reported in \autoref{Fig:A2} of Appendix, OGAMs
     produce more detailed spatial variations that the ellipsoid
     structure from the parametric model ( 0 ).  This suggests some
     fine-scale variations of vineyard qualities according to spatial
     determinants related to /terroir/.  Recall that geological and
     pedological no significant see RM.

*** Ordinal superiority of /communes/
**** Text 1                                  :noheading:

     The last row of \autoref{Tab:1} reports the bootstrapped F-tests
     about the joint significance of /communes/ dummies on surrogate
     residuals from auxiliary models.  \autoref{Fig:Xx} in Appendix
     presents in more details the relevance of smoothing spatial
     coordinates to control for unobserved /terroir/ variables.  It
     first appears that OGAMs provide some important progress compared
     to the parametric model ( 0 ).  Secondly, XXX effective degrees
     of freedom appears to be a sufficient complexity level to rule
     out correlated omitted spatial effects.  Above this complexity
     level /commune/ dummies stay highly significant, which indicates
     robust effect on GI designation schemes of still persistent
     intangible human-related characteristics from history.  Similar
     vineyard plots from one side or another of administrative
     delineations are shown to have significantly different
     probabilities of being in different vertical levels of GIs.  We
     use estimated /communes/ fixed effects from the OGAM of
     respectively 800, 900 and 1000 maximum edf for the smoothing of
     spatial coordinates to measure ordinal superiority reported in
     \autoref{Fig:2}.

**** Figure                                  :noheading:

#+begin_export latex
\begin{figure}[!t]
  \caption{\textbf{Ordinal superiorty measures for the \emph{communes}
      in actual GI designation scheme}\\[.1cm]
    \footnotesize Notes: For a given \emph{commune} $c$ on the y axis,
    ordinal superiority measures are computed from the difference
    between the estimated fixed effect $\mu_c$ and the average
    fixed effect $\overline{\mu}$ of all \emph{commune} according to:
    $\Delta_{c}= 2\times \Lambda[(\mu_{c}-\overline{\mu})/
    \sqrt{2}]-1$.  The horizontal bars represent the range of measures
    according to different OGAMs with varying complexity for the
    effects of spatial coordinates, black dots represent the average
    of these measures.  Relatively privilegied \emph{communes} appear
    at the top of the Figure, whereas relatively disadvantged
    \emph{communes} appear at the bottom.}\label{Fig:2}
  \centering\vspace*{-.75cm}\hspace*{-.5cm} \includegraphics[scale=
  .75]{./Figures/ComEff.pdf}
\end{figure}
#+end_export

**** Text 2                                  :noheading:

     Ordinal superiority measures are scaled to be between $-1$ and
     $1$ in a way that a negative value indicates an advantage
     relative to the average and a positive value indicates a
     disadvantage citep:AKat17.  /Communes/ from the /Côte de Nuits/
     at the North appear to be more advantaged on average with 10
     /communes/ among the 15 most advantaged (from the top to the
     bottom of the Figure).  The proximity to Dijon where trials take
     place between 1860 and 1936 is a potential explanation for this
     pattern.  The /communes/ that have a /syndicat/ (a group of
     producers) for collective action@@latex:\footnote{\cite{Jacq09}
     (p.189, 211) reports the \emph{communes} of
     \emph{Gevrey-Chambertin}, \emph{Ladoix-Serrigny},
     \emph{Santenay}, \emph{Vosne-Romanée}, \emph{Vougeot} as having
     experienced the first \emph{syndicats}, whereas there have been
     some internal conflicts in \emph{Santenay}.}@@ appear to be
     privileged while the separation is not clear-cut.  The hierarchy
     of advantaged and disadvantaged /communes/ does not follow
     strictly their past or actual reputations, as some advantaged
     /communes/ are not reputed@@latex:\footnote{We do not consider
     \emph{Marsannay-la-Côte}, \emph{Chenove} or \emph{Couchey} as
     advantaged \emph{communes} because this result seems attributable
     to border effects typical in semiparametric approaches.}@@
     (/Pernand-Vergeless/ and /Chorey-les-Beaune/) and some reputed
     /communes/ are disadvantaged (/Pommard/ and /Meursault/).  Nor
     the raw distribution of GIs see RM.

*** Informational content of GIs
**** Text 1                                  :noheading:
    
     \autoref{Tab:2} reports the decomposition from equations (5) to
     (8) with $q(X_i^*)$ predicted from OGAMs with increasing
     complexity order of spatial coordinates. Intangible /commune/
     fixed effect are set at their regional average as they are
     outside the signal of tangible vineyard quality.  The Total
     signal of the first row of \autoref{Tab:2} is increasing with the
     effective degree of freedom, which is not surprising as the
     models are increasingly complex.  As the variance of total noise
     is normalized in ordered models and the variance of $y^*$ from
     the data generating process is constant between models, this
     indicates an increase in the variance of vineyard quality
     predicted from tangible variables.  In contrast to this monotonic
     pattern between models, the other decomposition provide similar
     order of magnitude for the different terms without a monotonic
     relationship with the complexity of spatial effects.  

     Enxplain the number of the abstract

**** Table                                   :noheading:

#+begin_export latex
\begin{table}
\caption{\textbf{Signal decompositions from OGAM with spatial coordinates}}
\singlespacing\label{Tab:2} \vspace{-.5cm}
\begin{threeparttable}
\input{Tables/Decomp.tex}
\begin{tablenotes}\footnotesize
\item Notes: The effective degrees of freedom for spatial smoothing
  terms in parenthesis show that each decomposition corresponds to model ( I )
  to ( V ) from \autoref{Tab:1}.  Decomposition terms are expressed in
  percent of variance of the latent variable $y^{*}$ according to
  equations (5) to (8) in the text.  For each column, the sum of
  vertical signal and vertical residual equals the joint signal, as the
  sum of horizontal signal and vertical residual.  The vertical noise
  equals the sum of the vertical residual and the joint noise, as the
  horizontal noise equals the sum of horizontal residual and joint
  noise.
\end{tablenotes}
\end{threeparttable}
\end{table}
#+end_export

**** Text 2                                  :noheading:

     The joint signal of both vertical and horizontal dimension of GIs
     counts for about 77 % of the variance of the latent GI variable
     (the joint signal plus the total noise plus the joint noise equal
     100 % for every models).  The vertical signal alone counts for
     about 55 % of the variance and the horizontal signal for 25 %.
     The fourth column shows some deviations from other models while
     the order of magnitude are respected.

     Difference betwen bias and noise: private information is not
     fully reliable, so that the possibility of honest mistakes makes
     it very difficult to establish fraud conclusively. This clearly
     makes a crucial difference in insiders' ability to deceive the
     public repeatedly, hence in the profitability of market
     manipulation.

*** Alternative GI designation schemes
**** Text 1                                  :noheading:

    Les premiers crus n'existent pas, tout comme la distinction entre
    ordinaire et Bourgogne.

    On enlève les communes de "CHENOVE", "MARSANNAY-LA-COTE",
    "COUCHEY", "COMBLANCHIEN", "CORGOLOIN", "SAINT-ROMAIN" car il n'ya
    qu'un AOC présent là-dessus.

    for old model, omitted variable test and decomposition in RM

**** Table                                   :noheading:

#+begin_export latex
\begin{table}
\caption{\textbf{Signal decompositions from alternative GI designations}}\singlespacing
\singlespacing\label{Tab:3} \vspace{-.5cm}
\begin{threeparttable}
\input{Tables/Decoldmp.tex}
\begin{tablenotes}\footnotesize
\item Notes: Vineyard quality is predicted from model ( V ), which
  provides the best fit of actual GIs. The first column reports the
  informational content of 1936 GIs in terms of the predicted vineyard
  quality.  Scenario S.0 is a benchmark scenario with surrogate
  residuals to represent actual GIs.  S.I drops the random terms, S.II
  drops the intangible determinants through averaging \emph{commune}
  fixed effects and S.III drops random terms and intangible
  determinants.  Scenario S.IV, S.V and S.VI respectively add a
  vertical GI level on \emph{Bourgogne}, \emph{Village} and
  \emph{Premier Cru}, in increasing order in the hierarchy.
\end{tablenotes}
\end{threeparttable}
\end{table}
#+end_export

**** Text 2                                  :noheading:

     Knowing the continuous ranking of vineyard we can evaluate the
     informational content of alternative GI designation schemes.
     Verticality in particular (administrative is strange).  We
     consider 3 different dimensions of differentation.  First from
     history, second by changing the latent variable and third by
     adding a vertical level. Details

     The results show that dropping the intangible effects are the
     more important part to increase the informational content of the
     vertical dimension without impacting the horizontal part.
     Dropping the intangible is greater than adding a level but if we
     want we do not need to target the high level but the middle with
     more vineyard plot.  Maybe it is different from the value.  Then,
     additive cumulative gain of dropping random terms and intangible
     attributes.

** Conclusion
   :PROPERTIES:
   :CUSTOM_ID: Sec:4
   :END:
   
   An original framework disentangle, link with tangible
   caracteristics of plots.

   In other words, the Burgundy classification cation appears to be a
   good indicator of Burgundy wine quality, while Bordeaux ranking
   appears little representative of Bordeaux wine
   quality. (citealp:CLVi00, p.965)

   These two results suggest that the high informational content of
   GIs and their actual economic importance comes from their long
   history and their independent management.

   Our results about historical and potential improvement counter the
   idea that "only flexibility can keep the concept of terroir alive"
   cite:WWJo09,Ashe17.  Even conditions change, the consumer preference face
   to the GIs signal will change but the historical and independent
   certifiers. Face to cliamte change burgundy (harvest date), GIs are
   still very relevant markers for the value of wine and will probably
   continue.

   How to improve the signaling of quality through GIs or to imagine
   alternative sources of signaling. Les AOC ne sont pas immuables et
   il est important de voir qu'ils se sont améliorés, gestion
   pyublique des AOC en question, la littértaure sur la fourniture
   privée. Le financement de l'INAO

   Next step would be to look at consumer reaction to quality
   signaling (welfare implication) but difficult on GIs because of
   their stability.  Another difficulty would be the endogenous
   quality from viticultural practices in reaction to good
   classification and associated high prices.

   Value of information But also: Consumers may migrate toward higher
     quality (vertical sorting) of to wine whose product
     characteristics best meet their idiosynchratic needs
     (horizontal). Both can increase welfare. Numerous paper about
     vertical welfare imroving (DZJi10 p.952 for a review) Reputation
     should thus be relevant if prospective buyers believe that it
     predicts current quality in markets in which current quality is
     imperfectly observable (Shapiro, 1982, Landon and Smith 1998).

** Bibliography                              :noheading:
   
#+LATEX: \singlespacing

   bibliographystyle:../Softwares/latex/erae
   bibliography:Biblio.bib

#+LATEX: \clearpage\appendix
** Appendix
*** Table of summary statistics              :noheading:
    :PROPERTIES:
    :CUSTOM_ID: App:A
    :END:

#+begin_export latex
\begin{table}[h]
\caption{\textbf{Descriptive statistics for the variables used in the econometric analysis}}\singlespacing
\vspace{-.25cm}\centering\label{Tab:SD}
\begin{threeparttable}
\input{Tables/StatDes.tex}
\begin{tablenotes}\small
\item Notes: Topographic data are computed by Geographical Informatin
  System from a Digital Elevation Model of 5 m resolution.  Longitude
  and Latitude variables correspond to the centroid of each vineyard
  plot. Current GI are dummy variables that count for the vertical
  dimension in 2018 and Past GI comes from the map of 1860 mentioned
  in the main text.  Aspect is discretized according to radians range
  reported between brakets.
\end{tablenotes}
\end{threeparttable}
\end{table}\clearpage
#+end_export

*** Marginal effects in GI models            :noheading:

#+begin_export latex
\begin{figure}[!t]
  \caption{\textbf{Nonlinear effects of tangible variables on GI designations}\\[.1cm]
    \footnotesize Notes: Dotted lines represent the quadratic effects
    from model ( 0 ) of \autoref{Tab:1}, centered at zero with all
    other explanotory variables at their sample means.  Continuous
    lines represent the centered effects from 10 OGAMs with increasing
    darkened for increasing effective degrees of freedom of spatial
    smoothing terms.  Model ( I ) to ( V ) of \autoref{Tab:1} are a
    subset of these OGAMs with maximum effective degrees of freedom
    uniformly distributed between 100 and 1000.  The histograms at the
    bottom of each plots represent the marginal distributions of each
    explanatory variable in the region.}\label{Fig:A1}
  \centering
\includegraphics[scale= .85]{Figures/PltEff.pdf}
\end{figure}\clearpage
#+end_export

*** Spatial smooth surfaces                  :noheading:

#+begin_export latex
\begin{landscape}
\begin{figure}[b]
  \caption{\textbf{Spatial smoothed effects from ordered GI designation models}\\[.1cm]
    \footnotesize Notes: The smooth surfaces are predicted from
    spatial coordinates with others explanatory variables at their
    sample means, with a uniform normalization to be inside the unit
    interval.  Panel A displays the smooth prediction from parametric
    ordered logistic model ( 0 ) of \autoref{Tab:1}.  Panels B to F
    display the prediction from the OGAMs ( I ) to ( V ) with increasing
    effective degrees of freedom as reported at the top of each plot.}
  \centering\label{Fig:A2} \rotatebox[origin=c]{-90}{
    \includegraphics[scale=.7,angle=90]{Figures/SmoothMap.pdf} }
 \end{figure}
\end{landscape}
#+end_export

*** Omitted variable test                    :noheading:

#+begin_export latex
\begin{figure}[!t]
  \caption{\textbf{F-statistics for the diagnostic of correlated residual effects}\\[.1cm]
    \footnotesize Notes: log scale.}\label{Fig:A2a}
  \centering
\includegraphics[scale= .65]{Figures/SignifPlot.pdf}
\end{figure}\clearpage
#+end_export

*** Correlation between /communes/           :noheading:

#+begin_export latex
\begin{figure}[!t]
  \caption{\textbf{Correlation between ranking and ordinal superiority}\\[.1cm]
    \footnotesize Notes: more then average better GI and more than average privilegied.}\label{Fig:A2b}
  \centering
\includegraphics[scale= .65]{Figures/ComCor.pdf}
\end{figure}\clearpage
#+end_export

*** Significance for old GIs                 :noheading:

#+begin_export latex
\begin{table}
\caption{\textbf{Joint variable significance for ordered models of 1936 GI designations}}\singlespacing
\newcolumntype{Y}{>{\centering\arraybackslash}X}\label{Tab:1}
\begin{threeparttable}
\input{Tables/VarSign2.tex}
\begin{tablenotes}\footnotesize
\item Notes: $^{**}$ accounts for joint significance at 1\% from the
  reported Chi-square statistics, effective number of freedom are in
  brackets.  Column ( 0 ) corresponds to an ordered logit model with
  quadratic effects for elevation, slope and solar radiation
  (edf$= 2$) with a full interaction between 3-orders polynomials for
  longitude and latitude (edf$= 3+3+3\times 3= 15$) and with
  respectively 7 and 25 dummy variables for exposition and
  \emph{communes}.  5 \emph{communes} have been dropped because they
  contained only one GIs in 1860. Models ( I ) to ( V ) are OGAMs with
  elevation, slope and solar radiation additively specified with a
  maximum of 9 edf, shrinked endogenously by a quadratic penalization.
  Spatial coordinates are specified in an increasing order of
  complexity with the maximum edf of 100, 150, 200, 250 and 300.  The
  last row reports the average of bootstraped Fisher statistics for
  the joint nullity of \emph{communes} dummies on surrogate residuals
  in the auxiliary regressions presented in the main text.
\end{tablenotes}
\end{threeparttable}
\end{table}\clearpage
#+end_export

*** Marginal effects in old GI models        :noheading:

#+begin_export latex
\begin{figure}[!t]
  \caption{\textbf{Nonlinear effects of tangible variables on 1936 GI designations}\\[.1cm]
    \footnotesize Notes: Dotted lines represent the quadratic centered effects
    of model ( 0 ) presented in the main text.  Continuous lines
    represent the centered effects from OGAM models ( I ) to ( V ) with
    increasing darkened with increasing effective degrees of
    freedom.  The histograms at the bottom of the plots represent the 
    marginal distributions of each explanatory variable.}\label{Fig:A4}
  \centering
\includegraphics[scale= .85]{Figures/PltEffOld.pdf}
\end{figure}\clearpage
#+end_export

*** Spatial smooth surfaces for old GIs      :noheading:

#+begin_export latex
\begin{landscape}
\begin{figure}[b]
  \caption{\textbf{Spatial smoothed effects from 1936 GI designation models}\\[.1cm]
\label{Fig:A6}
    \footnotesize Notes: Smooth surfaces are normalized predictions of
    the latent variables from models ( 0 ) to ( V ) with all other covariates at their sample means.}
  \centering\label{Fig:A5} \rotatebox[origin=c]{-90}{
  \includegraphics[scale=.7,angle=90]{Figures/SmoothMapOld.pdf} 
  }
 \end{figure}
\end{landscape}
#+end_export

*** Ordinal superiority for old GI models    :noheading:

#+begin_export latex
\begin{figure}[!t]
  \caption{\textbf{Ordinal superiorty measures for the \emph{communes}
    in 1936 GI designation scheme}\\[.1cm]
    \footnotesize Notes: For a given \emph{commune} $c$, ordinal
    superiority measures are computed from the difference between the
    own estimated fixed effect $\mu_c$ and the average fixed effect
    $\overline{\mu}$ according to:
    $\Delta_{c}= 2\times \Lambda[(\mu_{c}-\overline{\mu})/
    \sqrt{2}]-1$ as in the main text.  The horizontal bars represent
    the range of measures according to different OGAMs with varying
    complexity for the effects of spatial coordinates, black dots
    represent the average of these measures.  Relatively privilegied
    \emph{communes} appear at the top of the Figure, whereas
    relatively disadvantged \emph{communes} appear at the
    bottom.}\label{Fig:A5}
  \centering\vspace*{-.75cm}\hspace*{-.5cm}
\includegraphics[scale= .75]{./Figures/ComEffOld.pdf}
\end{figure}\clearpage
#+end_export
    
*** Analytic bias from /terroir/ variables   :noexport:
    :PROPERTIES:
    :CUSTOM_ID: App:X
    :END:
**** Main text

     We propose to deal with this problem of unobserved spatial
     heterogeneity (met frequently in hedonic studies) by an original
     specification diagnostic and procedure based on the proxy
     variable approach of cite:Wool10 (p.67-72) and the computation of
     residuals in non-linear models citep:PHal83,GMRT87,CIri87,LZha18.
     The effect of unobserved /terroir/ variable is studied throught
     the definition of the linear projection of the unobserved quality
     grade on the observed tangible characteristics :
#+begin_export latex
\begin{equation}
q(X_i^*)= B(X_i)^\top\beta_{LP}+ \eta_i\label{Eq:LP1}
\end{equation}
#+end_export
    with the covariances between each columns of $B(X)$ and the
    residuals from the linear projection equal to zero by definition :
    $\mathbb{C}[b_\ell(x_{ki}), \eta_i]= 0$, $\forall \ell, k$
    citep:Wool10.  The concept of linear projection is of particular
    interest in regard to the indirect effects that are caught by
    tangible variables and the potential for geographical coordinates
    to control for unobserved /terroir/ variables.  On the first
    point, section 2.3 provides some intuitions about the indirect
    effects that tangible variables can have.  The residuals from
    linear projection $\eta$ represent the part of the climate that
    are not taken into account by topographic variables.  This is also
    true for the case of spatial coordinates of the center of the
    vineyard plots that constitutes a very precise information of the
    location (\autoref{Tab:SD}).  If we consider /terroir/ as a
    ecological process spatially smooth, it can allow to control
    through OGAM specification of the joint effect of longitude and
    latitude.

    The Appendix [[#App:A]] shows that the percent of bias on the
    /commune/ effects $\theta= (\hat{\mu}- \mu)/ \mu$ from the
    estimation of \autoref{Eq:Mod} relatively to the structural model
    is :
#+begin_export latex
\begin{equation}
\theta= \frac{\rho}{1- R^2}-1
\end{equation}
#+end_export
    where $\rho$... The intuition behind is as follows The first
    equality is the result of Wooldridge about proxy variable.  What
    is the $R^2$, variance, what is not observable.  The second add
    the term $\rho$ which is the correlation between a reduced from of
    $y^*_i$ on $b(X_i)$.  Increasing the dimension, particularly in
    the spatial coordinates allows to modify the $\theta$, allow th
    assess the potential bias.  Approximation for the variances.
    Specification (including link function) and Omitted long history
    of diagnostics based on residuals

**** Appendix

    Consider the additional linear projection for $i= 1,\dots,N$ of
    the quality grades $q(X^*_i)$ on the terms $B(X_i)^\top\beta_{LP}$
    and $C_i^\top\mu$ to define the scalars $\delta$, $\theta$ and the
    residuals $\epsilon_i$ such that :
#+begin_export latex
\begin{equation}
q(X_i^*)= \delta [B(X_i)^\top\beta_{LP}]+ \theta [C_i^\top\mu]+ \epsilon_i\label{Eq:LP2}
\end{equation}
#+end_export

    Substituting this linear projection in the structural model
    \autoref{Eq:STR} of the main text with the assumption of additive
    thresholds, we obtain :
#+begin_export latex
\begin{equation}
\mbox{Prob}(y_i=j\mid X_i, C_i)=
\mbox{Prob}\big\{\alpha_{j-1}< \delta [B(X_i)^\top\beta_{LP}]+ (1+ \theta) [C_i^\top\mu]+ \epsilon_i+ \xi_i^*<\alpha_j\big\}.\label{Eq:LT}
\end{equation}
#+end_export
    This equation indicates that the estimation of the reduced form
    (\ref{Eq:Mod}) of the main text will produce biased estimates with
    probability limits of $\widehat{\beta}= \beta_{LP}\delta$ and
    $\widehat{\mu}= \mu(1+\theta)$.  The reason is that controlling by
    $B(X_i)$ is not equivalent to controlling for $q(X_i^*)$ and some
    unobserved parts of the true long run quality are caught by the
    /commune/ dummies (unless $\theta=0$).

    By definition of the coefficients of a bivariate linear projection
    applied to (\ref{Eq:LP2}), we have :
#+begin_export latex
\begin{align}
\theta= &\,\frac{\mathbb{C}[q(X_i^*), C_i^\top\mu]\;\mathbb{V}[B(X_i)^\top\beta_{LP}]- 
                 \mathbb{C}[q(X_i^*), B(X_i)^\top\beta_{LP}]\;\mathbb{C}[C_i^\top\mu, B(X_i)^\top\beta_{LP}]}{
              \mathbb{V}[C_i^\top\mu]\;\mathbb{V}[B(X_i)^\top\beta_{LP}]- \mathbb{C}[C_i^\top\mu, B(X_i)^\top\beta_{LP}]^2}\label{Comp:1}\\
        =&\,\frac{\mathbb{V}[B(X_i)^\top\beta_{LP}]\big\{\mathbb{C}[B(X_i)^\top\beta_{LP}, C_i^\top\mu]+ \mathbb{C}[\eta_i, C_i^\top\mu]\big\}- 
                 \mathbb{V}[B(X_i)^\top\beta_{LP}]\;\mathbb{C}[C_i^\top\mu, B(X_i)^\top\beta_{LP}]}{
              \mathbb{V}[C_i^\top\mu]\;\mathbb{V}[B(X_i)^\top\beta_{LP}]- \mathbb{C}[C_i^\top\mu, B(X_i)^\top\beta_{LP}]^2}\label{Comp:2}\\
      = &\, \frac{\mathbb{C}(\eta_i, C_i^\top\mu)}{\mathbb{V}[C_i^\top\mu]\times(1-R^2)}\label{Comp:3}
\end{align}
#+end_export
    \autoref{Comp:2} is obtained by substituting $q(X^*)$ by the
    linear projection of \autoref{Eq:LP1} of the main text and
    \autoref{Comp:3} comes from the definition of the R$^2$ from the
    regression of $C_i^\top\mu$ on $B(X_i)^\top\beta_{LP}$, that is :
    $R^2=\mathbb{C}[C_i^\top\mu, B(X_i)^\top\beta_{LP}]^2/
    \big\{\mathbb{V}[C_i^\top\mu]\mathbb{V}[B(X_i)^\top\beta_{LP}]\big\}$.
    We use the fact that $\mathbb{C}[\xi_i^*, b_\ell(x_k)]= 0$ for all
    $k,\ell$ from the structural assumption that $\mathbb{E}(\xi^*\mid
    X^*, C_i)= 0$ with $X\subset X^*$ (law of iterated expectations).
    The last expression is the standard formula for the omitted
    variable bias when using $B(X_i)$ as a proxy for $q(X_i^*)$. It
    shows in particular the necessary condition for an absence of bias
    is that the proxy is closely enough related to the omitted
    variable so that once included, $C_i^\top\mu$ is not partially
    correlated with $q(X^*_i)$ (citealp:Wool10, p.68).  This reads as
    $\mathbb{C}(\eta_i, C_i^\top\mu)= 0$ $\Rightarrow$ $\theta=0$.  We
    found another result from the literature about the importance of
    reporting the R$^2$, Oster XX.  As regression XX and XX are
    hypothetical, the last \autoref{Comp:3} does not have any testable
    implications.
 
    Hence consider the auxiliary regression of the latent variable
    from \autoref{eq:LT} on only the tangible variable $B(X_i)$,
    voluntary omitting the /commune/ fixed effects. This would
    provide :
#+begin_export latex
\begin{equation}
\widetilde{y}_i^*= \tau B(X_i)^\top\beta_{LP}+ \varepsilon_i \;\;\mbox{ with }\;\; 
\tau=\mathbb{C}[B(X_i)^\top\beta_{LP}, \widetilde{y}_i^*]/\mathbb{V}[B(X_i)^\top\beta_{LP}]
\end{equation} 
#+end_export
     Assume that this regression could be run with observations of
     $\widetilde{y}_i^*$, we are interested by the estimated residuals
     and their correlation with $C_i^\top\mu$. In effect, intuition. We
     substitute to obtain :
#+begin_export latex
\begin{align}
\mathbb{C}(\widehat{\varepsilon}_i, C_i^\top\mu)=& \, \mathbb{C}(\widetilde{y}_i^*,C_i^\top\mu)-\frac{\mathbb{C}[\widetilde{y}_i^*, b(X_i)^\top\beta_{LP}]}{\mathbb{V}[b(X_i)^\top\beta_{LP}]}\mathbb{C}[b(X_i)^\top\beta_{LP}, C_i^\top\mu]\\ 
=& \, \mathbb{C}[q(X^*),C_i^\top\mu]+\mathbb{V}(C_i^\top\mu)-\frac{\mathbb{C}[b(X_i)^\top\beta_{LP}, C_i^\top\mu]}{\mathbb{V}[b(X_i)^\top\beta_{LP}]}\Big\{\mathbb{C}[q(X^*), b(X_i)^\top\beta_{LP}]+ \mathbb{C}[C_i^\top\mu, b(X_i)^\top\beta_{LP}]\Big\}\nonumber\\
=& \, \mathbb{C}[b(X_i)^\top\beta_{LP},C_i^\top\mu]+ \mathbb{C}[\eta_i,C_i^\top\mu] +\mathbb{V}(C_i^\top\mu)-\frac{\mathbb{C}[b(X_i)^\top\beta_{LP}, C_i^\top\mu]}{\mathbb{V}[b(X_i)^\top\beta_{LP}]}\Big\{\mathbb{V}[b(X_i)\beta_{LP}]+ \mathbb{C}[C_i^\top\mu, B(X_i)^\top\beta_{LP}]\Big\}\nonumber\\
=& \, \mathbb{C}[\eta_i,C_i^\top\mu] +\mathbb{V}(C_i^\top\mu)-\frac{\mathbb{C}[b(X_i)^\top\beta_{LP}, C_i^\top\mu]^2}{\mathbb{V}[b(X_i)^\top\beta_{LP}]}\\
=& \, \mathbb{C}[\eta_i,C_i^\top\mu]+ \mathbb{V}(C_i^\top\mu)\times (1-R^2)
\end{align}
#+end_export

     The last term could be substituted in the \autoref{Comp:3} to
     obtain the formula reported in the main text by noting $\rho$
     (for a variance of $\widehat{\varepsilon}_i$ normalized to one,
     which is standard in ordered models) :
#+begin_export latex
\begin{equation}
\theta= \frac{\mathbb{C}(\widehat{\varepsilon}_i, C_i^\top\mu)-\mathbb{V}(C_i^\top\mu)\times (1-R^2)}{\mathbb{V}(C_i^\top\mu)(1- R^2)}= \frac{\rho}{1- R^2}-1
\end{equation}
#+end_export

* Presentation                               :noexport:
  :PROPERTIES:
  :EXPORT_FILE_NAME:     Presentation
  :EXPORT_LATEX_CLASS:   PresSemin
  :EXPORT_LATEX_HEADER:  \renewcommand{\texttt}{\textcolor{beamer@blendedblue}} \renewcommand{\footnotesize}{\scriptsize} \addbibresource{Perso.bib} \renewcommand*{\bibfont}{\scriptsize}
  :EXPORT_BEAMER_HEADER: \usepackage{bm, adjustbox, amsmath, dsfont, dcolumn, import, rotfloat} \newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}
  :EXPORT_LATEX_HEADER:  \usepackage{handoutWithNotes} \pgfpagesuselayout{3 on 1 with notes}[a4paper,border shrink=10mm]
  :EXPORT_OPTIONS:       TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc toc:nil H:2 author:t
  :EXPORT_TITLE:         @@latex: The Informational Content of \\ Geographical Indications @@
  :EXPORT_AUTHOR:        @@latex: \large jean-sauveur ay\\ inra cesaer\\ @@  
  :EXPORT_DATE:          Vendredi 10 mai
  :END:
** 1 -- Introduction
*** The signal of quality

# Je vais vous parler de vin sans vous en proposer pour accompagner
# vos sandwichs mais bon parler gastromie en mangeant c'est bien
# français il me semble

# AOC, une mauvaise habitude de certains pays à indiquer la provenance
# géographique des leurs productions agricoles pour signaler la
# qualité

#+BEGIN_CENTER
\vspace{-.5cm}
\includegraphics[trim=0cm 0cm 0cm 0cm, clip=true, scale= .9]{./Figures/labelDRC}
#+END_CENTER

*** Quality of the signal

# Il ne suffit pas de renseigner un lieu pour signaler la qualité et
# je parler du contenu informationel qui transite par la référence au
# lieu

#+BEGIN_CENTER
\vspace{-.5cm}
\includegraphics[trim= 2.5cm 1.5cm 2.5cm 2cm, clip=true, scale= .55]{./Figures/labelVDP}
#+END_CENTER

*** Relevant signal ?

# Derrière se joue la question de la pertinence de la référence au
# lieu par rapport au modèle dominant de la marque, qui est souvent
# source de conflit dans les négociations commerciales.

#+BEGIN_CENTER
\vspace{-.5cm}
\includegraphics[trim=0cm 0cm 0cm 0cm, clip=true, scale= .35]{./Figures/labelFAT}
#+END_CENTER

*** Literature                               :noexport:

    =Strong effect of Geographical Indications= in all studies

#+LaTeX: \vspace{.5cm}

    @@latex: \texttt{Insignificant effect of soil \emph{terroir}}@@
    - Gergaud and Ginsburgh (EJ 2008), Bordeaux wines
    - Cross et al. (AER 2011), Oregon vineyards 

#+LaTeX: \vspace{.5cm}

    @@latex: \texttt{Strong effect of climate \emph{terroir}}@@
    - Ashenfelter et al. (Chance 1995), Bordeaux wines
    - Ashenfelter and Storchmann (RES 2010), Mosell vineyards
 
** 2 -- Data
*** GIs of the /Côte d'Or/ region
**** Image 1 							      :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:
     
#+BEGIN_CENTER
\vspace*{-1cm}
\includegraphics[scale= .3]{./Figures/MapCom1}
#+END_CENTER     

**** Image 2 							      :BMCOL:
    :PROPERTIES:
    :BEAMER_col: 0.5
    :END:

#+BEGIN_CENTER
\vspace*{-1cm}
\includegraphics[scale= .3]{./Figures/MapCom2}
#+END_CENTER     

*** \null

#+begin_quote
    "la difficulté de leur classement en une seule série est presque
    insurmontable. [...] Ces considérations m'ont déterminé à étudier
    séparément les vins de chaque commune suivant l'ordre
    géographique."
#+end_quote

#+Latex: {\small
    Jules Lavalle 1855 (p.78)

    Histoire et statistique de la vigne et des grands vins de la Côte
    d'Or. 
#+Latex:}

*** \null

#+begin_quote
    "Plus l'appellation requise se calque sur le syndicat [de la
    commune] qui la défend, plus elle a de chance d'émerger et d'être
    délimitée strictement."
#+end_quote

#+Latex: {\small
    Olivier Jacquet 2009 (p.193)

    Un siècle de construction du vignoble bourguignon.
#+Latex: }

*** Truc de fou

    - des communes portent le nom de grands crus
    - des grands crus sont à cheval sur plusieurs communes
    - des communes qui partagent un grand cru

# Franchement, il y en a qui pensent que la profusion et la complexité
# des labels créent de la confusion chez le consommateur, ce n'est
# clairement pas le cas en Bourgogne.

*** GI information

# On va prendre pour exemple la Côte d'Or, ce n'est pas le plus facile
# ni le plus représentatif (vin) mais ce n'est pas loin. Non sinon,
# c'est une vrai success story des GIs, la première étiquette que je
# vous ai montré c'est le vin le plus cher du monde.

#+BEGIN_CENTER
\vspace{-.5cm}
\includegraphics[trim=0cm 0cm 0cm 0cm, clip=true, scale= .5]{./Figures/labelPCRU}
#+END_CENTER

** 3 -- Model
*** Latent structure

#+begin_export latex
\begin{flalign*}
y_i^*= q\left(X_i; \beta\right)+ \xi_i \;\;\mbox{ with }\;\; \mathbb{E}(\xi \mid X)= 0&&\nonumber
\end{flalign*}\pause
#+end_export

# Composante non observée, note de qualité SELON LE DESIGNATEUR Il ne
# s'agit pas de savoir si c'est pertinent pour le consommateur

# Il s'agit de décomposer entre ce qui est tangible X de ce qui est
# idiosyncratique (hypothèse les deux sont indépendants)

#+begin_export latex
\vspace{-1cm}
\begin{flalign*}
&\mbox{ Define } y_{ij}= 1 \mbox{ if } \alpha_{j-1}< y_i^* \leqslant \alpha_{j+1} \mbox{ and } y_{ij}= 0 \mbox{ otherwise } \nonumber\\
& j= \mbox{\small Côteaux Bourguignons, Bourgogne, Village, Premier Cru, Grand Cru}\nonumber
\end{flalign*}\pause
#+end_export

# Cette simplification hiérarchisée de l'information permet de réduire
# en 5 niveaux une information continue.

# La structure ordinale (verticale) s'éloigne d'une mesure cardinal
# (un score de 40 c'est 2 fois mieux qu'un score de 20), ça permet de
# s'afranchir d'une échelle qui est souvent problématique sur les
# notes (école des fans, Parker). Et ça permet une certaine
# horizontalité, ça laisse une place aux goûts

#+begin_export latex
\vspace{-1cm}
\begin{flalign*}
&\mbox{ Define } c_{ik}= 1 \mbox{ if } i \in \mathbb{C}_k \mbox{ and } c_{ik}= 0 \mbox{ otherwise } \nonumber\\
& k= \mbox{\small Gevrey-Chambertin, Chassagne-Montrachet, Beaune, Vougeot, etc.}\nonumber
\end{flalign*}\pause
#+end_export

# La structure horizontale est également présente dans l'information
# transmise aux consommateurs à travers la commune
# d'appartenance. L'information communale est un découpage
# administratif qui préexiste aux appellations d'origine. 1789 en
# fonction des paroisses, localisation des églises (IXe-XIIe
# siècles). Le but n'était de signaler la qualité des vignes

#+begin_export latex
\vspace{-.75cm}
\begin{flalign*}
\;\;\overrightarrow{\alpha_j}= \alpha_j- \sum\nolimits_k \theta_k\cdot C_k \;\; \mbox{ with $\theta_k$ the bias}&&\nonumber
\end{flalign*}
\vspace{.5cm}
#+end_export

# Par contre, les communes ont joué un rôle important, à travers les
# regroupements de producteurs dans la mise en oeuvre des AOC, ils ont
# fait preuve d'influence et leur réputation a joué: Olivier Jacquet,
# Gilles. On a donc un double effet des communes qui sont unité
# spatialement contigu mais dont l'histoire est une source
# additionnelle de brouillage de l'information qualité contenu dans les
# AOC.

# quand aux vignerons d'aujourd'hui ont peu dire qu'ils n'ont peu
# d'effet à moins de supposer des déterminismes génétiques sur 2
# siècles.

# Ordinal superiority as an objective mesure of reputation

*** Decomposition I
#+LATEX: \small

#+begin_export latex
\begin{flalign*}
\mathbb{Var}(y^*)= \underbrace{\mbox{Var}\left[q\left(X_i; \beta\right)\right]}_{\mbox{signal}}+ \underbrace{\mbox{Var}\left(\xi_i\right)}_{\mbox{noise}}&& [D1]\nonumber
\end{flalign*}\pause
#+end_export

# Avec des informations sur X et un modèle ordonné, du type probit ou
# logit on peut obtenir cette décomposition qui ressemble au R2 si on
# normalise par la variance de y^* (bien qu'il soit inobservable,
# c'est magique!) Mais on ne sait pas comment ça agit sur le
# consommateur car lui à part tout connaître (100000 parcelles) il ne
# connaît pas y

# On va donc décomposer le signal selon l'accesibilité qu'il a pour le
# consommateur: loi de la variance totale

#+begin_export latex
\vspace{-1cm}
\begin{flalign*}
  \mbox{Var}\left[s\left(X_i; \beta\right)\right]=
    \underbrace{\mbox{Var}\left\{\mathbb{E}\left[s\left(X_i;
            \beta\right)\mid Y\right]\right\}}_{\mbox{ranking signal}}+
    \underbrace{\mathbb{E}\left\{\mbox{Var}\left[s\left(X_i;
            \beta\right)\mid Y\right]\right\}}_{\mbox{ranking noise}}&& [D2]
\end{flalign*}\pause
#+end_export

#+begin_export latex
\vspace{-1cm}
\begin{flalign*}
  \mbox{Var}\left[s\left(X_i; \beta\right)\right]=
    \underbrace{\mbox{Var}\left\{\mathbb{E}\left[s\left(X_i;
            \beta\right)\mid C\right]\right\}}_{\mbox{commune signal}}+
    \underbrace{\mathbb{E}\left\{\mbox{Var}\left[s\left(X_i;
            \beta\right)\mid C\right]\right\}}_{\mbox{commune noise}}&& [D3]
\end{flalign*}\pause
#+end_export

#+begin_export latex
\vspace{-1cm}
\begin{flalign*}
  \mbox{Var}\left[s\left(X_i; \beta\right)\right]=
    \underbrace{\mbox{Var}\left\{\mathbb{E}\left[s\left(X_i;
            \beta\right)\mid Y, C\right]\right\}}_{\mbox{joint signal}}+
    \underbrace{\mathbb{E}\left\{\mbox{Var}\left[s\left(X_i;
            \beta\right)\mid Y, C\right]\right\}}_{\mbox{joint noise}}&& [D4]
\end{flalign*}
#+end_export

# Intuitions derrière les termes de la décomposition, c'est également
# un R^2

# Certaine redondance entre les niveaux et les communes

*** Decomposition II
#+LATEX: \small

#+begin_export latex
\vspace{-1cm}
\begin{flalign*}
   \mbox{Var}\left[s\left(X_i; \beta\right)\right]&\,= 
  \mbox{Var}\left\{\mathbb{E}\left[s\left(X_i; \beta\right)\mid Y\right]\right\} \;\;\;\Rightarrow\;\;\; \mbox{ranking signal}  & [D5] \\
  +& \underbrace{\mathbb{E}\mbox{Var}\left\{\mathbb{E}\left[s\left(X_i; \beta\right)\mid Y, C \right]\mid Y\right\}}_{\mbox{residual commune signal}} +
  \underbrace{\mathbb{E}\left\{\mbox{Var}\left[s\left(X_i; \beta\right)\mid Y, C\right]\right\}}_{\mbox{joint noise}}&\nonumber
\end{flalign*}\pause
#+end_export

#+begin_export latex
\vspace{-1cm}
\begin{flalign*}
  \mbox{Var}\left[s\left(X_i; \beta\right)\right]&\;=  
  \mbox{Var}\left\{\mathbb{E}\left[s\left(X_i; \beta\right)\mid C\right]\right\}   \;\;\;\Rightarrow\;\;\; \mbox{commune signal}& [D6]\\
    + & \underbrace{\mathbb{E}\mbox{Var}\left\{\mathbb{E}\left[s\left(X_i; \beta\right)\mid Y, C\right]\mid C\right\}}_{\mbox{residual ranking signal}}+
    \underbrace{\mathbb{E}\left\{\mbox{Var}\left[s\left(X_i; \beta\right)\mid Y, C\right]\right\}}_{\mbox{joint noise}} &\nonumber
\end{flalign*}
#+end_export

# Certaine redondance entre les niveaux et les communes

** 4 -- Result
*** Specifications

    Variables, 5 specifications, pc of good predictions.

*** Marginal effects
*** Decompositions
** 5 -- Conclusion
*** Results

    Importance of history

    Importance of INAO

*** Other rankings
*** Bibliography

#+LaTeX: \null\vspace{-.5cm}{\small

=Ashenfelter, O., D. Ashmore and R. Lalonde (1995)=. Bordeaux wine
vintage quality and the weather.  /Chance/ 8.

#+LaTeX: \vspace{.5cm}

=Ashenfelter, O. and K. Storchmann (2010)=. Using hedonic models of
solar radiation and weather to assess the economic effect of climate
change: The case of Mosel Valley vineyards. /Review of Economics and
Statistics/ 92.

#+LaTeX: \vspace{.5cm}

=Cross, R., A. J. Plantinga and R. N. Stavins (2011)=. What is the
value of terroir? /American Economic Review/ 101: 152.

#+LaTeX: \vspace{.5cm}

=Gergaud, O. and V. Ginsburgh (2008)=. Natural endowments, production
technologies and the quality of wines in Bordeaux. Does terroir
matter? /Economic Journal/ 118.

#+LaTeX: }

